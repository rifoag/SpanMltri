{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675baafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import read_examples_from_file, ReviewDataset\n",
    "\n",
    "from BaseEncoder import BaseEncoder\n",
    "from SpanGenerator import SpanGenerator\n",
    "\n",
    "from SpanMltriLite import SpanMltriLite\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d00862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100dde94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = \"dataset/train.tsv\"\n",
    "DEV_FILE_PATH = \"dataset/dev.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41467c0",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefafb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = \"indolem/indobert-base-uncased\"\n",
    "BATCH_SIZE = 32\n",
    "MAX_SPAN_LENGTH = 8\n",
    "MAX_SENTENCE_LENGTH = 40\n",
    "\n",
    "NUM_OF_TE_LABELS = 3\n",
    "NUM_OF_PAOTE_LABELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238811f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ReviewDataset(TRAIN_FILE_PATH, max_sentence_length=MAX_SENTENCE_LENGTH)\n",
    "dev_data = ReviewDataset(DEV_FILE_PATH, max_sentence_length=MAX_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5b2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dev_dataloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "base_encoder = BaseEncoder(MODEL_NAME_OR_PATH).to(device)\n",
    "span_generator = SpanGenerator(MAX_SPAN_LENGTH).to(device)\n",
    "model = SpanMltriLite(d_hidden=768, max_sentence_length=MAX_SENTENCE_LENGTH, num_of_te_class=3).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "lambda_t = 0.5\n",
    "lambda_r = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc93a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, train_data, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        X_tokenized = X.to(device)\n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        current_te_label_dict = train_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = train_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "\n",
    "        # Term Scorer\n",
    "        y_te_true = []\n",
    "        for i in range(CURRENT_BATCH_SIZE):\n",
    "            y_ = []\n",
    "            for span_range in span_ranges:\n",
    "                if span_range in current_te_label_dict[i]:\n",
    "                    label = current_te_label_dict[i][span_range]\n",
    "                    if label == 'ASPECT':\n",
    "                        y_.append(1)\n",
    "                    elif label == 'SENTIMENT':\n",
    "                        y_.append(2)\n",
    "                else: # label is O\n",
    "                    y_.append(0)        \n",
    "            y_te_true.append(torch.Tensor(y_))\n",
    "        y_te_true = torch.stack(y_te_true)\n",
    "        y_te_true = y_te_true.to(torch.long).to(device)\n",
    "        \n",
    "        # Relation Scorer\n",
    "        y_paote_true = []\n",
    "        CURRENT_BATCH_SIZE = min(len(current_relation_dict), BATCH_SIZE)\n",
    "        for i in range(CURRENT_BATCH_SIZE):\n",
    "            y_ = []\n",
    "            for span_pair_range in span_pair_ranges[i]:\n",
    "                if span_pair_range not in current_relation_dict[i]:\n",
    "                    y_.append(0)\n",
    "                else:\n",
    "                    label = current_relation_dict[i][span_pair_range]\n",
    "                    if label == 'PO':\n",
    "                        y_.append(1)\n",
    "                    elif label == 'NG':\n",
    "                        y_.append(2)\n",
    "                    elif label == 'NT':\n",
    "                        y_.append(3)\n",
    "            if len(y_) == 12995:\n",
    "                print(sentences[i])\n",
    "                print(i)\n",
    "            y_paote_true.append(torch.Tensor(y_))\n",
    "        y_paote_true = torch.stack(y_paote_true)\n",
    "        y_paote_true = y_paote_true.to(torch.long).to(device)\n",
    "                \n",
    "        te_loss = loss_fn(logits_term_scorer.view(-1, NUM_OF_TE_LABELS), y_te_true.view(-1))  \n",
    "        paote_loss = loss_fn(logits_relation_scorer.view(-1, NUM_OF_PAOTE_LABELS), y_paote_true.view(-1))\n",
    "        total_loss = lambda_t*te_loss + lambda_r*paote_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            total_loss, current = total_loss.item(), batch * len(X)\n",
    "            print(f\"loss: {te_loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf2811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dev_dataloader, model):\n",
    "    size = len(dev_dataloader.dataset)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, X in enumerate(dev_dataloader):\n",
    "            X_tokenized = X.to(device)\n",
    "            CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "            X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "\n",
    "            current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "\n",
    "            logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "\n",
    "            y_te_true = []\n",
    "            for i in range(CURRENT_BATCH_SIZE):\n",
    "                y_ = []\n",
    "                for span_range in span_ranges:\n",
    "                    if span_range in current_te_label_dict[i]:\n",
    "                        label = current_te_label_dict[i][span_range]\n",
    "                        if label == 'ASPECT':\n",
    "                            y_.append(1)\n",
    "                        elif label == 'SENTIMENT':\n",
    "                            y_.append(2)\n",
    "                    else: # label is O\n",
    "                        y_.append(0)        \n",
    "                y_te_true.append(torch.Tensor(y_))\n",
    "            y_te_true = torch.stack(y_te_true)\n",
    "            y_te_true = y_te_true.to(torch.long)\n",
    "\n",
    "            te_loss = loss_fn(logits_term_scorer.view(-1), y_te_true.view(-1))\n",
    "\n",
    "            y_paote_true = []\n",
    "            CURRENT_BATCH_SIZE = min(len(current_relation_dict), BATCH_SIZE)\n",
    "            for i in range(CURRENT_BATCH_SIZE):\n",
    "                y_ = []\n",
    "                for span_pair_range in span_pair_ranges[i]:\n",
    "                    if span_pair_range not in current_relation_dict[i]:\n",
    "                        y_.append(0)\n",
    "                    else:\n",
    "                        label = current_relation_dict[i][span_pair_range]\n",
    "                        if label == 'PO':\n",
    "                            y_.append(1)\n",
    "                        elif label == 'NG':\n",
    "                            y_.append(2)\n",
    "                        elif label == 'NT':\n",
    "                            y_.append(3)\n",
    "                y_paote_true.append(torch.Tensor(y_))\n",
    "            y_paote_true = torch.stack(y_paote_true)\n",
    "            y_paote_true = y_paote_true.to(torch.long)\n",
    "\n",
    "            paote_loss = loss_fn(logits_relation_scorer.view(-1, 4), y_paote_true.view(-1))\n",
    "            total_loss += lambda_t*te_loss.item() + lambda_r*paote_loss.item()\n",
    "\n",
    "    total_loss /= batch\n",
    "    print(f\"Test Error: \\n Avg loss: {total_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c0dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.893322  [    0/ 3000]\n",
      "loss: 0.955730  [   64/ 3000]\n",
      "loss: 1.010346  [  128/ 3000]\n",
      "loss: 0.762366  [  192/ 3000]\n",
      "loss: 0.866403  [  256/ 3000]\n",
      "loss: 0.742545  [  320/ 3000]\n",
      "loss: 0.754140  [  384/ 3000]\n",
      "loss: 0.772195  [  448/ 3000]\n",
      "loss: 0.853727  [  512/ 3000]\n",
      "loss: 0.699944  [  576/ 3000]\n",
      "loss: 0.834684  [  640/ 3000]\n",
      "loss: 0.434484  [  704/ 3000]\n",
      "loss: 0.584678  [  768/ 3000]\n",
      "loss: 0.627223  [  832/ 3000]\n",
      "loss: 0.605031  [  896/ 3000]\n",
      "loss: 0.642448  [  960/ 3000]\n",
      "loss: 0.528821  [ 1024/ 3000]\n",
      "loss: 0.428929  [ 1088/ 3000]\n",
      "loss: 0.471235  [ 1152/ 3000]\n",
      "loss: 0.348709  [ 1216/ 3000]\n",
      "loss: 0.411387  [ 1280/ 3000]\n",
      "loss: 0.460095  [ 1344/ 3000]\n",
      "loss: 0.445073  [ 1408/ 3000]\n",
      "loss: 0.371337  [ 1472/ 3000]\n",
      "loss: 0.603436  [ 1536/ 3000]\n",
      "loss: 0.342959  [ 1600/ 3000]\n",
      "loss: 0.318633  [ 1664/ 3000]\n",
      "loss: 0.287195  [ 1728/ 3000]\n",
      "loss: 0.393272  [ 1792/ 3000]\n",
      "loss: 0.487518  [ 1856/ 3000]\n",
      "loss: 0.454249  [ 1920/ 3000]\n",
      "loss: 0.338928  [ 1984/ 3000]\n",
      "loss: 0.438469  [ 2048/ 3000]\n",
      "loss: 0.284263  [ 2112/ 3000]\n",
      "loss: 0.332157  [ 2176/ 3000]\n",
      "loss: 0.275774  [ 2240/ 3000]\n",
      "loss: 0.365926  [ 2304/ 3000]\n",
      "loss: 0.550870  [ 2368/ 3000]\n",
      "loss: 0.356601  [ 2432/ 3000]\n",
      "loss: 0.257922  [ 2496/ 3000]\n",
      "loss: 0.247507  [ 2560/ 3000]\n",
      "loss: 0.208036  [ 2624/ 3000]\n",
      "loss: 0.362256  [ 2688/ 3000]\n",
      "loss: 0.212022  [ 2752/ 3000]\n",
      "loss: 0.231592  [ 2816/ 3000]\n",
      "loss: 0.287757  [ 2880/ 3000]\n",
      "loss: 0.216319  [ 2944/ 3000]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 40]' is invalid for input of size 960",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5d2bb392a80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8a927613c93c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, train_data, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mX_tokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mX_tokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mcurrent_te_label_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mte_label_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mcurrent_relation_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelation_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[32, 40]' is invalid for input of size 960"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, train_data, model, loss_fn, optimizer)\n",
    "    test(dev_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(dev_dataloader):\n",
    "        X_tokenized = X.to(device)\n",
    "        X_tokenized = X_tokenized.reshape(BATCH_SIZE, X_tokenized.shape[-1])\n",
    "\n",
    "        current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        \n",
    "        X_encoded = base_encoder(X_tokenized)\n",
    "        X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "        \n",
    "        print(sentences[:5])\n",
    "        print(logits_term_scorer[:5].argmax(dim=-1))\n",
    "        print(logits_relation_scorer[:5].argmax(dim=-1))\n",
    "        print(span_ranges)\n",
    "        print(span_pair_ranges[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4649c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
