{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8475efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import ReviewDataset\n",
    "\n",
    "from BaseEncoder import BaseEncoder\n",
    "from SpanGenerator import SpanGenerator\n",
    "\n",
    "from SpanMltriLite import SpanMltriLite\n",
    "from SpanMltri import SpanMltri\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d95276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26ab426f110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f654701",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = \"dataset/train.tsv\"\n",
    "DEV_FILE_PATH = \"dataset/dev.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580596b0",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9de600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_prediction_to_iob(prediction, tokens):\n",
    "    pred_iob = ['O'] * len(tokens)\n",
    "    current_te_label_dict = {}\n",
    "    # get all non O predicted span ranges\n",
    "    for idx, pred_class_id in enumerate(prediction):\n",
    "        if pred_class_id != 0:\n",
    "            key = span_ranges[idx]\n",
    "            current_te_label_dict[key] = label_map[pred_class_id]\n",
    "            \n",
    "    for key in current_te_label_dict:\n",
    "        offsets = [int(offset) for offset in key.split('-')]\n",
    "        start_offset, end_offset = offsets\n",
    "        label = current_te_label_dict[key]\n",
    "        for i in range(start_offset, end_offset+1):\n",
    "            if i < len(tokens):\n",
    "                if i == start_offset:\n",
    "                    pred_iob[i] = f\"B-{label}\"\n",
    "                else:\n",
    "                    pred_iob[i] = f\"I-{label}\"\n",
    "    return pred_iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608db76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_label_to_iob(current_te_label_dict, tokens):\n",
    "    pred_iob = ['O'] * len(tokens)\n",
    "    for key in current_te_label_dict:\n",
    "        offsets = [int(offset) for offset in key.split('-')]\n",
    "        start_offset, end_offset = offsets\n",
    "        label = current_te_label_dict[key]\n",
    "        for i in range(start_offset, end_offset+1):\n",
    "            if i < len(tokens):\n",
    "                if i == start_offset:\n",
    "                    pred_iob[i] = f\"B-{label}\"\n",
    "                else:\n",
    "                    pred_iob[i] = f\"I-{label}\"\n",
    "        \n",
    "    return pred_iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e12852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "        0: 'O',\n",
    "        1: 'ASPECT',\n",
    "        2: 'SENTIMENT'\n",
    "    }\n",
    "\n",
    "def print_prediction(sentence, class_ids, te_label_dict, span_ranges):\n",
    "    print(sentence)\n",
    "    print(\"Predicted\")\n",
    "    for idx, class_id in enumerate(class_ids):\n",
    "        if class_id != 0:\n",
    "            start_offset, end_offset = span_ranges[idx].split('-')\n",
    "            start_offset, end_offset = int(start_offset), int(end_offset)\n",
    "            print(sentence[start_offset:end_offset+1], label_map[class_id])\n",
    "    print()\n",
    "    print(\"True\")\n",
    "    for key in te_label_dict.keys():\n",
    "        start_offset, end_offset = key.split('-')\n",
    "        start_offset, end_offset = int(start_offset), int(end_offset)\n",
    "        print(sentence[start_offset:end_offset+1], te_label_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddead551",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 40\n",
    "\n",
    "NUM_OF_TE_LABELS = 3\n",
    "NUM_OF_PAOTE_LABELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdcd3683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_data = ReviewDataset(TRAIN_FILE_PATH, max_sentence_length=MAX_SENTENCE_LENGTH)\n",
    "dev_data = ReviewDataset(DEV_FILE_PATH, max_sentence_length=MAX_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14bdf7",
   "metadata": {},
   "source": [
    "# Full Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0067d",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f941347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME_OR_PATH = \"indolem/indobert-base-uncased\"\n",
    "MODEL_NAME_OR_PATH = 'checkpoint-31641'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "MAX_SPAN_LENGTH = 4\n",
    "K_CANDIDATE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a41d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dev_dataloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "base_encoder = BaseEncoder(MODEL_NAME_OR_PATH).to(device)\n",
    "span_generator = SpanGenerator(MAX_SPAN_LENGTH).to(device)\n",
    "model = SpanMltri(d_hidden=768, max_span_length=MAX_SPAN_LENGTH, max_sentence_length=MAX_SENTENCE_LENGTH, num_of_te_class=3, k=K_CANDIDATE).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "lambda_t = 0.5\n",
    "lambda_r = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ece96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, train_data, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        X_tokenized = X.to(device)\n",
    "        \n",
    "        current_te_label_dict = train_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = train_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        \n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        with torch.no_grad():\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "\n",
    "        # Term Scorer\n",
    "        y_te_true = []\n",
    "        for i in range(CURRENT_BATCH_SIZE):\n",
    "            y_ = []\n",
    "            for span_range in span_ranges:\n",
    "                if span_range in current_te_label_dict[i]:\n",
    "                    label = current_te_label_dict[i][span_range]\n",
    "                    if label == 'ASPECT':\n",
    "                        y_.append(1)\n",
    "                    elif label == 'SENTIMENT':\n",
    "                        y_.append(2)\n",
    "                else: # label is O\n",
    "                    y_.append(0)        \n",
    "            y_te_true.append(torch.Tensor(y_))\n",
    "        y_te_true = torch.stack(y_te_true)\n",
    "        y_te_true = y_te_true.to(torch.long).to(device)\n",
    "        \n",
    "        # Relation Scorer\n",
    "        y_paote_true = []\n",
    "        for i in range(CURRENT_BATCH_SIZE):\n",
    "            y_ = []\n",
    "            for span_pair_range in span_pair_ranges[i]:\n",
    "                if span_pair_range not in current_relation_dict[i]:\n",
    "                    y_.append(0)\n",
    "                else:\n",
    "                    label = current_relation_dict[i][span_pair_range]\n",
    "                    if label == 'PO':\n",
    "                        y_.append(1)\n",
    "                    elif label == 'NG':\n",
    "                        y_.append(2)\n",
    "                    elif label == 'NT':\n",
    "                        y_.append(3)\n",
    "\n",
    "            y_paote_true.append(torch.Tensor(y_))\n",
    "        y_paote_true = torch.stack(y_paote_true)\n",
    "        y_paote_true = y_paote_true.to(torch.long).to(device)\n",
    "                \n",
    "        te_loss = loss_fn(logits_term_scorer.view(-1, NUM_OF_TE_LABELS), y_te_true.view(-1))  \n",
    "        paote_loss = loss_fn(logits_relation_scorer.view(-1, NUM_OF_PAOTE_LABELS), y_paote_true.view(-1))\n",
    "        total_loss = lambda_t*te_loss + lambda_r*paote_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            total_loss, current = total_loss.item(), batch * len(X)\n",
    "            print(f\"loss: {te_loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dev_dataloader, model):\n",
    "    size = len(dev_dataloader.dataset)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, X in enumerate(dev_dataloader):\n",
    "            X_tokenized = X.to(device)\n",
    "\n",
    "            current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "            \n",
    "            X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "\n",
    "            logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "\n",
    "            y_te_true = []\n",
    "            for i in range(CURRENT_BATCH_SIZE):\n",
    "                y_ = []\n",
    "                for span_range in span_ranges:\n",
    "                    if span_range in current_te_label_dict[i]:\n",
    "                        label = current_te_label_dict[i][span_range]\n",
    "                        if label == 'ASPECT':\n",
    "                            y_.append(1)\n",
    "                        elif label == 'SENTIMENT':\n",
    "                            y_.append(2)\n",
    "                    else: # label is O\n",
    "                        y_.append(0)        \n",
    "                y_te_true.append(torch.Tensor(y_))\n",
    "            y_te_true = torch.stack(y_te_true)\n",
    "            y_te_true = y_te_true.to(torch.long).to(device)\n",
    "\n",
    "            te_loss = loss_fn(logits_term_scorer.view(-1, NUM_OF_TE_LABELS), y_te_true.view(-1))\n",
    "\n",
    "            y_paote_true = []\n",
    "            for i in range(CURRENT_BATCH_SIZE):\n",
    "                y_ = []\n",
    "                for span_pair_range in span_pair_ranges[i]:\n",
    "                    if span_pair_range not in current_relation_dict[i]:\n",
    "                        y_.append(0)\n",
    "                    else:\n",
    "                        label = current_relation_dict[i][span_pair_range]\n",
    "                        if label == 'PO':\n",
    "                            y_.append(1)\n",
    "                        elif label == 'NG':\n",
    "                            y_.append(2)\n",
    "                        elif label == 'NT':\n",
    "                            y_.append(3)\n",
    "                y_paote_true.append(torch.Tensor(y_))\n",
    "            y_paote_true = torch.stack(y_paote_true)\n",
    "            y_paote_true = y_paote_true.to(torch.long).to(device)\n",
    "\n",
    "            paote_loss = loss_fn(logits_relation_scorer.view(-1, NUM_OF_PAOTE_LABELS), y_paote_true.view(-1))\n",
    "            total_loss += lambda_t*te_loss.item() + lambda_r*paote_loss.item()\n",
    "\n",
    "    total_loss /= batch\n",
    "    print(f\"Test Error: \\n Avg loss: {total_loss:>8f} \\n\")\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8aac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "patience = 5\n",
    "epoch_no_improve = 0\n",
    "early_stop = False\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, train_data, model, loss_fn, optimizer)\n",
    "    val_loss = test(dev_dataloader, model)\n",
    "    if val_loss < min_val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = val_loss\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve == patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2bad5e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(dev_dataloader):\n",
    "        current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_sentences = dev_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        \n",
    "        X_tokenized = X.to(device)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        X_encoded = base_encoder(X_tokenized)\n",
    "        X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "        \n",
    "        for idx in range(CURRENT_BATCH_SIZE):\n",
    "            prediction = logits_term_scorer[idx].argmax(-1).tolist()\n",
    "            y_pred.append(te_prediction_to_iob(prediction, current_sentences[idx]))\n",
    "            y_true.append(te_label_to_iob(current_te_label_dict[idx], current_sentences[idx]))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81079129",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        current_te_label_dict = train_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = train_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        \n",
    "        X_tokenized = X.to(device)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        X_encoded = base_encoder(X_tokenized)\n",
    "        X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer, logits_relation_scorer, span_pair_ranges = model(X_spans, span_ranges)\n",
    "        \n",
    "        for idx in range(CURRENT_BATCH_SIZE):\n",
    "            prediction = logits_term_scorer[idx].argmax(-1).tolist()\n",
    "            y_pred.append(te_prediction_to_iob(prediction, current_sentences[idx]))\n",
    "            y_true.append(te_label_to_iob(current_te_label_dict[idx], current_sentences[idx]))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a209de",
   "metadata": {},
   "source": [
    "# Lite Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c5277",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d682544",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = \"indolem/indobert-base-uncased\"\n",
    "# MODEL_NAME_OR_PATH = 'checkpoint-31641'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "MAX_SPAN_LENGTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ddcab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dev_dataloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "base_encoder = BaseEncoder(MODEL_NAME_OR_PATH).to(device)\n",
    "span_generator = SpanGenerator(MAX_SPAN_LENGTH).to(device)\n",
    "model = SpanMltriLite(d_hidden=768, max_span_length=MAX_SPAN_LENGTH, max_sentence_length=MAX_SENTENCE_LENGTH, num_of_te_class=3).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "lambda_t = 1\n",
    "lambda_r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547d4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, train_data, model, loss_fn, optimizer):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        X_tokenized = X.to(device)\n",
    "        \n",
    "        current_te_label_dict = train_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = train_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        \n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        with torch.no_grad():\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer = model(X_spans, span_ranges)\n",
    "\n",
    "        # Term Scorer\n",
    "        y_te_true = []\n",
    "        for i in range(CURRENT_BATCH_SIZE):\n",
    "            y_ = []\n",
    "            for span_range in span_ranges:\n",
    "                if span_range in current_te_label_dict[i]:\n",
    "                    label = current_te_label_dict[i][span_range]\n",
    "                    if label == 'ASPECT':\n",
    "                        y_.append(1)\n",
    "                    elif label == 'SENTIMENT':\n",
    "                        y_.append(2)\n",
    "                else: # label is O\n",
    "                    y_.append(0)        \n",
    "            y_te_true.append(torch.Tensor(y_))\n",
    "        y_te_true = torch.stack(y_te_true)\n",
    "        y_te_true = y_te_true.to(torch.long).to(device)\n",
    "                \n",
    "        te_loss = loss_fn(logits_term_scorer.view(-1, NUM_OF_TE_LABELS), y_te_true.view(-1))  \n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        te_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            te_loss, current = te_loss.item(), batch * len(X)\n",
    "            print(f\"loss: {te_loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e225775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dev_dataloader, model):\n",
    "    size = len(dev_dataloader.dataset)\n",
    "    model.eval()\n",
    "    te_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, X in enumerate(dev_dataloader):\n",
    "            X_tokenized = X.to(device)\n",
    "            current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "            \n",
    "            X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "            X_encoded = base_encoder(X_tokenized)\n",
    "            X_spans, span_ranges = span_generator(X_encoded)\n",
    "\n",
    "            logits_term_scorer = model(X_spans, span_ranges)\n",
    "\n",
    "            y_te_true = []\n",
    "            for i in range(CURRENT_BATCH_SIZE):\n",
    "                y_ = []\n",
    "                for span_range in span_ranges:\n",
    "                    if span_range in current_te_label_dict[i]:\n",
    "                        label = current_te_label_dict[i][span_range]\n",
    "                        if label == 'ASPECT':\n",
    "                            y_.append(1)\n",
    "                        elif label == 'SENTIMENT':\n",
    "                            y_.append(2)\n",
    "                    else: # label is O\n",
    "                        y_.append(0)        \n",
    "                y_te_true.append(torch.Tensor(y_))\n",
    "            y_te_true = torch.stack(y_te_true)\n",
    "            y_te_true = y_te_true.to(torch.long).to(device)\n",
    "\n",
    "            te_loss += loss_fn(logits_term_scorer.view(-1, NUM_OF_TE_LABELS), y_te_true.view(-1))\n",
    "\n",
    "    te_loss /= batch\n",
    "    print(f\"Test Error: \\n Avg loss: {te_loss:>8f} \\n\")\n",
    "    return te_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dbf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.194126  [    0/ 3000]\n",
      "loss: 1.096619  [    8/ 3000]\n",
      "loss: 1.012350  [   16/ 3000]\n",
      "loss: 0.914243  [   24/ 3000]\n",
      "loss: 1.021622  [   32/ 3000]\n",
      "loss: 0.856235  [   40/ 3000]\n",
      "loss: 0.728925  [   48/ 3000]\n",
      "loss: 0.751521  [   56/ 3000]\n",
      "loss: 0.708204  [   64/ 3000]\n",
      "loss: 0.649737  [   72/ 3000]\n",
      "loss: 0.672062  [   80/ 3000]\n",
      "loss: 0.561165  [   88/ 3000]\n",
      "loss: 0.638634  [   96/ 3000]\n",
      "loss: 0.499108  [  104/ 3000]\n",
      "loss: 0.517019  [  112/ 3000]\n",
      "loss: 0.419730  [  120/ 3000]\n",
      "loss: 0.353486  [  128/ 3000]\n",
      "loss: 0.475609  [  136/ 3000]\n",
      "loss: 0.469111  [  144/ 3000]\n",
      "loss: 0.365101  [  152/ 3000]\n",
      "loss: 0.358242  [  160/ 3000]\n",
      "loss: 0.295200  [  168/ 3000]\n",
      "loss: 0.301968  [  176/ 3000]\n",
      "loss: 0.359490  [  184/ 3000]\n",
      "loss: 0.311110  [  192/ 3000]\n",
      "loss: 0.250811  [  200/ 3000]\n",
      "loss: 0.294973  [  208/ 3000]\n",
      "loss: 0.293733  [  216/ 3000]\n",
      "loss: 0.263731  [  224/ 3000]\n",
      "loss: 0.343708  [  232/ 3000]\n",
      "loss: 0.279297  [  240/ 3000]\n",
      "loss: 0.258930  [  248/ 3000]\n",
      "loss: 0.191671  [  256/ 3000]\n",
      "loss: 0.274614  [  264/ 3000]\n",
      "loss: 0.234139  [  272/ 3000]\n",
      "loss: 0.309323  [  280/ 3000]\n",
      "loss: 0.228561  [  288/ 3000]\n",
      "loss: 0.236871  [  296/ 3000]\n",
      "loss: 0.221081  [  304/ 3000]\n",
      "loss: 0.229102  [  312/ 3000]\n",
      "loss: 0.205571  [  320/ 3000]\n",
      "loss: 0.314485  [  328/ 3000]\n",
      "loss: 0.186743  [  336/ 3000]\n",
      "loss: 0.213091  [  344/ 3000]\n",
      "loss: 0.192600  [  352/ 3000]\n",
      "loss: 0.177122  [  360/ 3000]\n",
      "loss: 0.257784  [  368/ 3000]\n",
      "loss: 0.140434  [  376/ 3000]\n",
      "loss: 0.261624  [  384/ 3000]\n",
      "loss: 0.190222  [  392/ 3000]\n",
      "loss: 0.274016  [  400/ 3000]\n",
      "loss: 0.190447  [  408/ 3000]\n",
      "loss: 0.222147  [  416/ 3000]\n",
      "loss: 0.196083  [  424/ 3000]\n",
      "loss: 0.287787  [  432/ 3000]\n",
      "loss: 0.139796  [  440/ 3000]\n",
      "loss: 0.206944  [  448/ 3000]\n",
      "loss: 0.188969  [  456/ 3000]\n",
      "loss: 0.269878  [  464/ 3000]\n",
      "loss: 0.162260  [  472/ 3000]\n",
      "loss: 0.130008  [  480/ 3000]\n",
      "loss: 0.237676  [  488/ 3000]\n",
      "loss: 0.183154  [  496/ 3000]\n",
      "loss: 0.174311  [  504/ 3000]\n",
      "loss: 0.200419  [  512/ 3000]\n",
      "loss: 0.115135  [  520/ 3000]\n",
      "loss: 0.331070  [  528/ 3000]\n",
      "loss: 0.244401  [  536/ 3000]\n",
      "loss: 0.219909  [  544/ 3000]\n",
      "loss: 0.183977  [  552/ 3000]\n",
      "loss: 0.174223  [  560/ 3000]\n",
      "loss: 0.205212  [  568/ 3000]\n",
      "loss: 0.207202  [  576/ 3000]\n",
      "loss: 0.216590  [  584/ 3000]\n",
      "loss: 0.160577  [  592/ 3000]\n",
      "loss: 0.244331  [  600/ 3000]\n",
      "loss: 0.120891  [  608/ 3000]\n",
      "loss: 0.252420  [  616/ 3000]\n",
      "loss: 0.227497  [  624/ 3000]\n",
      "loss: 0.286858  [  632/ 3000]\n",
      "loss: 0.131669  [  640/ 3000]\n",
      "loss: 0.227958  [  648/ 3000]\n",
      "loss: 0.282831  [  656/ 3000]\n",
      "loss: 0.255935  [  664/ 3000]\n",
      "loss: 0.192786  [  672/ 3000]\n",
      "loss: 0.146789  [  680/ 3000]\n",
      "loss: 0.163636  [  688/ 3000]\n",
      "loss: 0.292920  [  696/ 3000]\n",
      "loss: 0.173962  [  704/ 3000]\n",
      "loss: 0.157975  [  712/ 3000]\n",
      "loss: 0.176225  [  720/ 3000]\n",
      "loss: 0.151893  [  728/ 3000]\n",
      "loss: 0.170907  [  736/ 3000]\n",
      "loss: 0.181904  [  744/ 3000]\n",
      "loss: 0.268285  [  752/ 3000]\n",
      "loss: 0.180277  [  760/ 3000]\n",
      "loss: 0.219288  [  768/ 3000]\n",
      "loss: 0.179840  [  776/ 3000]\n",
      "loss: 0.288025  [  784/ 3000]\n",
      "loss: 0.210852  [  792/ 3000]\n",
      "loss: 0.256301  [  800/ 3000]\n",
      "loss: 0.196823  [  808/ 3000]\n",
      "loss: 0.146308  [  816/ 3000]\n",
      "loss: 0.138832  [  824/ 3000]\n",
      "loss: 0.165909  [  832/ 3000]\n",
      "loss: 0.150062  [  840/ 3000]\n",
      "loss: 0.171436  [  848/ 3000]\n",
      "loss: 0.141158  [  856/ 3000]\n",
      "loss: 0.203774  [  864/ 3000]\n",
      "loss: 0.163303  [  872/ 3000]\n",
      "loss: 0.133528  [  880/ 3000]\n",
      "loss: 0.274468  [  888/ 3000]\n",
      "loss: 0.135897  [  896/ 3000]\n",
      "loss: 0.287809  [  904/ 3000]\n",
      "loss: 0.183218  [  912/ 3000]\n",
      "loss: 0.126127  [  920/ 3000]\n",
      "loss: 0.187048  [  928/ 3000]\n",
      "loss: 0.143195  [  936/ 3000]\n",
      "loss: 0.263857  [  944/ 3000]\n",
      "loss: 0.119053  [  952/ 3000]\n",
      "loss: 0.171384  [  960/ 3000]\n",
      "loss: 0.139997  [  968/ 3000]\n",
      "loss: 0.128714  [  976/ 3000]\n",
      "loss: 0.157124  [  984/ 3000]\n",
      "loss: 0.288481  [  992/ 3000]\n",
      "loss: 0.198970  [ 1000/ 3000]\n",
      "loss: 0.153320  [ 1008/ 3000]\n",
      "loss: 0.213590  [ 1016/ 3000]\n",
      "loss: 0.155310  [ 1024/ 3000]\n",
      "loss: 0.222992  [ 1032/ 3000]\n",
      "loss: 0.079171  [ 1040/ 3000]\n",
      "loss: 0.123992  [ 1048/ 3000]\n",
      "loss: 0.098571  [ 1056/ 3000]\n",
      "loss: 0.159484  [ 1064/ 3000]\n",
      "loss: 0.167240  [ 1072/ 3000]\n",
      "loss: 0.136166  [ 1080/ 3000]\n",
      "loss: 0.228265  [ 1088/ 3000]\n",
      "loss: 0.159033  [ 1096/ 3000]\n",
      "loss: 0.123246  [ 1104/ 3000]\n",
      "loss: 0.240279  [ 1112/ 3000]\n",
      "loss: 0.108768  [ 1120/ 3000]\n",
      "loss: 0.134686  [ 1128/ 3000]\n",
      "loss: 0.151711  [ 1136/ 3000]\n",
      "loss: 0.226109  [ 1144/ 3000]\n",
      "loss: 0.133113  [ 1152/ 3000]\n",
      "loss: 0.104294  [ 1160/ 3000]\n",
      "loss: 0.144152  [ 1168/ 3000]\n",
      "loss: 0.131334  [ 1176/ 3000]\n",
      "loss: 0.240177  [ 1184/ 3000]\n",
      "loss: 0.158297  [ 1192/ 3000]\n",
      "loss: 0.163891  [ 1200/ 3000]\n",
      "loss: 0.175083  [ 1208/ 3000]\n",
      "loss: 0.154740  [ 1216/ 3000]\n",
      "loss: 0.173600  [ 1224/ 3000]\n",
      "loss: 0.183263  [ 1232/ 3000]\n",
      "loss: 0.174701  [ 1240/ 3000]\n",
      "loss: 0.203184  [ 1248/ 3000]\n",
      "loss: 0.085707  [ 1256/ 3000]\n",
      "loss: 0.118026  [ 1264/ 3000]\n",
      "loss: 0.105238  [ 1272/ 3000]\n",
      "loss: 0.171250  [ 1280/ 3000]\n",
      "loss: 0.259385  [ 1288/ 3000]\n",
      "loss: 0.121074  [ 1296/ 3000]\n",
      "loss: 0.097224  [ 1304/ 3000]\n",
      "loss: 0.184209  [ 1312/ 3000]\n",
      "loss: 0.331047  [ 1320/ 3000]\n",
      "loss: 0.205284  [ 1328/ 3000]\n",
      "loss: 0.183807  [ 1336/ 3000]\n",
      "loss: 0.232626  [ 1344/ 3000]\n",
      "loss: 0.145951  [ 1352/ 3000]\n",
      "loss: 0.141914  [ 1360/ 3000]\n",
      "loss: 0.204952  [ 1368/ 3000]\n",
      "loss: 0.245352  [ 1376/ 3000]\n",
      "loss: 0.222542  [ 1384/ 3000]\n",
      "loss: 0.137036  [ 1392/ 3000]\n",
      "loss: 0.200057  [ 1400/ 3000]\n",
      "loss: 0.141577  [ 1408/ 3000]\n",
      "loss: 0.180554  [ 1416/ 3000]\n",
      "loss: 0.237506  [ 1424/ 3000]\n",
      "loss: 0.185228  [ 1432/ 3000]\n",
      "loss: 0.100531  [ 1440/ 3000]\n",
      "loss: 0.153372  [ 1448/ 3000]\n",
      "loss: 0.185351  [ 1456/ 3000]\n",
      "loss: 0.078284  [ 1464/ 3000]\n",
      "loss: 0.129559  [ 1472/ 3000]\n",
      "loss: 0.109708  [ 1480/ 3000]\n",
      "loss: 0.194260  [ 1488/ 3000]\n",
      "loss: 0.141484  [ 1496/ 3000]\n",
      "loss: 0.157695  [ 1504/ 3000]\n",
      "loss: 0.145229  [ 1512/ 3000]\n",
      "loss: 0.146350  [ 1520/ 3000]\n",
      "loss: 0.145855  [ 1528/ 3000]\n",
      "loss: 0.166011  [ 1536/ 3000]\n",
      "loss: 0.119171  [ 1544/ 3000]\n",
      "loss: 0.201637  [ 1552/ 3000]\n",
      "loss: 0.112090  [ 1560/ 3000]\n",
      "loss: 0.111533  [ 1568/ 3000]\n",
      "loss: 0.137303  [ 1576/ 3000]\n",
      "loss: 0.173496  [ 1584/ 3000]\n",
      "loss: 0.110609  [ 1592/ 3000]\n",
      "loss: 0.195656  [ 1600/ 3000]\n",
      "loss: 0.130593  [ 1608/ 3000]\n",
      "loss: 0.210696  [ 1616/ 3000]\n",
      "loss: 0.201915  [ 1624/ 3000]\n",
      "loss: 0.128375  [ 1632/ 3000]\n",
      "loss: 0.135667  [ 1640/ 3000]\n",
      "loss: 0.157426  [ 1648/ 3000]\n",
      "loss: 0.097096  [ 1656/ 3000]\n",
      "loss: 0.264569  [ 1664/ 3000]\n",
      "loss: 0.126437  [ 1672/ 3000]\n",
      "loss: 0.105743  [ 1680/ 3000]\n",
      "loss: 0.151861  [ 1688/ 3000]\n",
      "loss: 0.208424  [ 1696/ 3000]\n",
      "loss: 0.133315  [ 1704/ 3000]\n",
      "loss: 0.104070  [ 1712/ 3000]\n",
      "loss: 0.131592  [ 1720/ 3000]\n",
      "loss: 0.185098  [ 1728/ 3000]\n",
      "loss: 0.139480  [ 1736/ 3000]\n",
      "loss: 0.168591  [ 1744/ 3000]\n",
      "loss: 0.094882  [ 1752/ 3000]\n",
      "loss: 0.070455  [ 1760/ 3000]\n",
      "loss: 0.251466  [ 1768/ 3000]\n",
      "loss: 0.142001  [ 1776/ 3000]\n",
      "loss: 0.106010  [ 1784/ 3000]\n",
      "loss: 0.131646  [ 1792/ 3000]\n",
      "loss: 0.185306  [ 1800/ 3000]\n",
      "loss: 0.215720  [ 1808/ 3000]\n",
      "loss: 0.101693  [ 1816/ 3000]\n",
      "loss: 0.168833  [ 1824/ 3000]\n",
      "loss: 0.091795  [ 1832/ 3000]\n",
      "loss: 0.046762  [ 1840/ 3000]\n",
      "loss: 0.139677  [ 1848/ 3000]\n",
      "loss: 0.128150  [ 1856/ 3000]\n",
      "loss: 0.168766  [ 1864/ 3000]\n",
      "loss: 0.159506  [ 1872/ 3000]\n",
      "loss: 0.085971  [ 1880/ 3000]\n",
      "loss: 0.114299  [ 1888/ 3000]\n",
      "loss: 0.146092  [ 1896/ 3000]\n",
      "loss: 0.083881  [ 1904/ 3000]\n",
      "loss: 0.134513  [ 1912/ 3000]\n",
      "loss: 0.185379  [ 1920/ 3000]\n",
      "loss: 0.161241  [ 1928/ 3000]\n",
      "loss: 0.178639  [ 1936/ 3000]\n",
      "loss: 0.101845  [ 1944/ 3000]\n",
      "loss: 0.180962  [ 1952/ 3000]\n",
      "loss: 0.090355  [ 1960/ 3000]\n",
      "loss: 0.175028  [ 1968/ 3000]\n",
      "loss: 0.112852  [ 1976/ 3000]\n",
      "loss: 0.227486  [ 1984/ 3000]\n",
      "loss: 0.191392  [ 1992/ 3000]\n",
      "loss: 0.159746  [ 2000/ 3000]\n",
      "loss: 0.187117  [ 2008/ 3000]\n",
      "loss: 0.150089  [ 2016/ 3000]\n",
      "loss: 0.133621  [ 2024/ 3000]\n",
      "loss: 0.174604  [ 2032/ 3000]\n",
      "loss: 0.151776  [ 2040/ 3000]\n",
      "loss: 0.111026  [ 2048/ 3000]\n",
      "loss: 0.126173  [ 2056/ 3000]\n",
      "loss: 0.087228  [ 2064/ 3000]\n",
      "loss: 0.252937  [ 2072/ 3000]\n",
      "loss: 0.112109  [ 2080/ 3000]\n",
      "loss: 0.212897  [ 2088/ 3000]\n",
      "loss: 0.150766  [ 2096/ 3000]\n",
      "loss: 0.070819  [ 2104/ 3000]\n",
      "loss: 0.088543  [ 2112/ 3000]\n",
      "loss: 0.099370  [ 2120/ 3000]\n",
      "loss: 0.100989  [ 2128/ 3000]\n",
      "loss: 0.137640  [ 2136/ 3000]\n",
      "loss: 0.172513  [ 2144/ 3000]\n",
      "loss: 0.207972  [ 2152/ 3000]\n",
      "loss: 0.069833  [ 2160/ 3000]\n",
      "loss: 0.130594  [ 2168/ 3000]\n",
      "loss: 0.099309  [ 2176/ 3000]\n",
      "loss: 0.173153  [ 2184/ 3000]\n",
      "loss: 0.147390  [ 2192/ 3000]\n",
      "loss: 0.073722  [ 2200/ 3000]\n",
      "loss: 0.073366  [ 2208/ 3000]\n",
      "loss: 0.117412  [ 2216/ 3000]\n",
      "loss: 0.190963  [ 2224/ 3000]\n",
      "loss: 0.122356  [ 2232/ 3000]\n",
      "loss: 0.201725  [ 2240/ 3000]\n",
      "loss: 0.085516  [ 2248/ 3000]\n",
      "loss: 0.148588  [ 2256/ 3000]\n",
      "loss: 0.080101  [ 2264/ 3000]\n",
      "loss: 0.165666  [ 2272/ 3000]\n",
      "loss: 0.114335  [ 2280/ 3000]\n",
      "loss: 0.199329  [ 2288/ 3000]\n",
      "loss: 0.120744  [ 2296/ 3000]\n",
      "loss: 0.077390  [ 2304/ 3000]\n",
      "loss: 0.059542  [ 2312/ 3000]\n",
      "loss: 0.087264  [ 2320/ 3000]\n",
      "loss: 0.149160  [ 2328/ 3000]\n",
      "loss: 0.088397  [ 2336/ 3000]\n",
      "loss: 0.150980  [ 2344/ 3000]\n",
      "loss: 0.216831  [ 2352/ 3000]\n",
      "loss: 0.139721  [ 2360/ 3000]\n",
      "loss: 0.126654  [ 2368/ 3000]\n",
      "loss: 0.097693  [ 2376/ 3000]\n",
      "loss: 0.102772  [ 2384/ 3000]\n",
      "loss: 0.110424  [ 2392/ 3000]\n",
      "loss: 0.082251  [ 2400/ 3000]\n",
      "loss: 0.196857  [ 2408/ 3000]\n",
      "loss: 0.144009  [ 2416/ 3000]\n",
      "loss: 0.134159  [ 2424/ 3000]\n",
      "loss: 0.165304  [ 2432/ 3000]\n",
      "loss: 0.105758  [ 2440/ 3000]\n",
      "loss: 0.155928  [ 2448/ 3000]\n",
      "loss: 0.188596  [ 2456/ 3000]\n",
      "loss: 0.114583  [ 2464/ 3000]\n",
      "loss: 0.275868  [ 2472/ 3000]\n",
      "loss: 0.067281  [ 2480/ 3000]\n",
      "loss: 0.140140  [ 2488/ 3000]\n",
      "loss: 0.073721  [ 2496/ 3000]\n",
      "loss: 0.092652  [ 2504/ 3000]\n",
      "loss: 0.221429  [ 2512/ 3000]\n",
      "loss: 0.265683  [ 2520/ 3000]\n",
      "loss: 0.105716  [ 2528/ 3000]\n",
      "loss: 0.138449  [ 2536/ 3000]\n",
      "loss: 0.097105  [ 2544/ 3000]\n",
      "loss: 0.166279  [ 2552/ 3000]\n",
      "loss: 0.141901  [ 2560/ 3000]\n",
      "loss: 0.202934  [ 2568/ 3000]\n",
      "loss: 0.166473  [ 2576/ 3000]\n",
      "loss: 0.170348  [ 2584/ 3000]\n",
      "loss: 0.109411  [ 2592/ 3000]\n",
      "loss: 0.104032  [ 2600/ 3000]\n",
      "loss: 0.144882  [ 2608/ 3000]\n",
      "loss: 0.089310  [ 2616/ 3000]\n",
      "loss: 0.099033  [ 2624/ 3000]\n",
      "loss: 0.169345  [ 2632/ 3000]\n",
      "loss: 0.201284  [ 2640/ 3000]\n",
      "loss: 0.145480  [ 2648/ 3000]\n",
      "loss: 0.169684  [ 2656/ 3000]\n",
      "loss: 0.128927  [ 2664/ 3000]\n",
      "loss: 0.178806  [ 2672/ 3000]\n",
      "loss: 0.197391  [ 2680/ 3000]\n",
      "loss: 0.139645  [ 2688/ 3000]\n",
      "loss: 0.112980  [ 2696/ 3000]\n",
      "loss: 0.136807  [ 2704/ 3000]\n",
      "loss: 0.183313  [ 2712/ 3000]\n",
      "loss: 0.128458  [ 2720/ 3000]\n",
      "loss: 0.189080  [ 2728/ 3000]\n",
      "loss: 0.080604  [ 2736/ 3000]\n",
      "loss: 0.148061  [ 2744/ 3000]\n",
      "loss: 0.150681  [ 2752/ 3000]\n",
      "loss: 0.110570  [ 2760/ 3000]\n",
      "loss: 0.076806  [ 2768/ 3000]\n",
      "loss: 0.204117  [ 2776/ 3000]\n",
      "loss: 0.126085  [ 2784/ 3000]\n",
      "loss: 0.116429  [ 2792/ 3000]\n",
      "loss: 0.224717  [ 2800/ 3000]\n",
      "loss: 0.218515  [ 2808/ 3000]\n",
      "loss: 0.141818  [ 2816/ 3000]\n",
      "loss: 0.153639  [ 2824/ 3000]\n",
      "loss: 0.154608  [ 2832/ 3000]\n",
      "loss: 0.137256  [ 2840/ 3000]\n",
      "loss: 0.118095  [ 2848/ 3000]\n",
      "loss: 0.148273  [ 2856/ 3000]\n",
      "loss: 0.098291  [ 2864/ 3000]\n",
      "loss: 0.159702  [ 2872/ 3000]\n",
      "loss: 0.180323  [ 2880/ 3000]\n",
      "loss: 0.088054  [ 2888/ 3000]\n",
      "loss: 0.058376  [ 2896/ 3000]\n",
      "loss: 0.162538  [ 2904/ 3000]\n",
      "loss: 0.148076  [ 2912/ 3000]\n",
      "loss: 0.121509  [ 2920/ 3000]\n",
      "loss: 0.206240  [ 2928/ 3000]\n",
      "loss: 0.257637  [ 2936/ 3000]\n",
      "loss: 0.080989  [ 2944/ 3000]\n",
      "loss: 0.041530  [ 2952/ 3000]\n",
      "loss: 0.080325  [ 2960/ 3000]\n",
      "loss: 0.085743  [ 2968/ 3000]\n",
      "loss: 0.095426  [ 2976/ 3000]\n",
      "loss: 0.129481  [ 2984/ 3000]\n",
      "loss: 0.057746  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.129970 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.092172  [    0/ 3000]\n",
      "loss: 0.149401  [    8/ 3000]\n",
      "loss: 0.082731  [   16/ 3000]\n",
      "loss: 0.085732  [   24/ 3000]\n",
      "loss: 0.211930  [   32/ 3000]\n",
      "loss: 0.084743  [   40/ 3000]\n",
      "loss: 0.069044  [   48/ 3000]\n",
      "loss: 0.122434  [   56/ 3000]\n",
      "loss: 0.209738  [   64/ 3000]\n",
      "loss: 0.071842  [   72/ 3000]\n",
      "loss: 0.207996  [   80/ 3000]\n",
      "loss: 0.168771  [   88/ 3000]\n",
      "loss: 0.194717  [   96/ 3000]\n",
      "loss: 0.111227  [  104/ 3000]\n",
      "loss: 0.225344  [  112/ 3000]\n",
      "loss: 0.095140  [  120/ 3000]\n",
      "loss: 0.077038  [  128/ 3000]\n",
      "loss: 0.184444  [  136/ 3000]\n",
      "loss: 0.179203  [  144/ 3000]\n",
      "loss: 0.099100  [  152/ 3000]\n",
      "loss: 0.079654  [  160/ 3000]\n",
      "loss: 0.054636  [  168/ 3000]\n",
      "loss: 0.086271  [  176/ 3000]\n",
      "loss: 0.160471  [  184/ 3000]\n",
      "loss: 0.120494  [  192/ 3000]\n",
      "loss: 0.095091  [  200/ 3000]\n",
      "loss: 0.203660  [  208/ 3000]\n",
      "loss: 0.107518  [  216/ 3000]\n",
      "loss: 0.108103  [  224/ 3000]\n",
      "loss: 0.227073  [  232/ 3000]\n",
      "loss: 0.139152  [  240/ 3000]\n",
      "loss: 0.108586  [  248/ 3000]\n",
      "loss: 0.072898  [  256/ 3000]\n",
      "loss: 0.155248  [  264/ 3000]\n",
      "loss: 0.105431  [  272/ 3000]\n",
      "loss: 0.210901  [  280/ 3000]\n",
      "loss: 0.074183  [  288/ 3000]\n",
      "loss: 0.108380  [  296/ 3000]\n",
      "loss: 0.097854  [  304/ 3000]\n",
      "loss: 0.157277  [  312/ 3000]\n",
      "loss: 0.120302  [  320/ 3000]\n",
      "loss: 0.247148  [  328/ 3000]\n",
      "loss: 0.102752  [  336/ 3000]\n",
      "loss: 0.126147  [  344/ 3000]\n",
      "loss: 0.068013  [  352/ 3000]\n",
      "loss: 0.067761  [  360/ 3000]\n",
      "loss: 0.181324  [  368/ 3000]\n",
      "loss: 0.055799  [  376/ 3000]\n",
      "loss: 0.168042  [  384/ 3000]\n",
      "loss: 0.105156  [  392/ 3000]\n",
      "loss: 0.189516  [  400/ 3000]\n",
      "loss: 0.092920  [  408/ 3000]\n",
      "loss: 0.161389  [  416/ 3000]\n",
      "loss: 0.104108  [  424/ 3000]\n",
      "loss: 0.221816  [  432/ 3000]\n",
      "loss: 0.089685  [  440/ 3000]\n",
      "loss: 0.142023  [  448/ 3000]\n",
      "loss: 0.098721  [  456/ 3000]\n",
      "loss: 0.198521  [  464/ 3000]\n",
      "loss: 0.102461  [  472/ 3000]\n",
      "loss: 0.054909  [  480/ 3000]\n",
      "loss: 0.177976  [  488/ 3000]\n",
      "loss: 0.125934  [  496/ 3000]\n",
      "loss: 0.088177  [  504/ 3000]\n",
      "loss: 0.137317  [  512/ 3000]\n",
      "loss: 0.066755  [  520/ 3000]\n",
      "loss: 0.297141  [  528/ 3000]\n",
      "loss: 0.180770  [  536/ 3000]\n",
      "loss: 0.157933  [  544/ 3000]\n",
      "loss: 0.108215  [  552/ 3000]\n",
      "loss: 0.097706  [  560/ 3000]\n",
      "loss: 0.152380  [  568/ 3000]\n",
      "loss: 0.140381  [  576/ 3000]\n",
      "loss: 0.154204  [  584/ 3000]\n",
      "loss: 0.096362  [  592/ 3000]\n",
      "loss: 0.229595  [  600/ 3000]\n",
      "loss: 0.062689  [  608/ 3000]\n",
      "loss: 0.172714  [  616/ 3000]\n",
      "loss: 0.135706  [  624/ 3000]\n",
      "loss: 0.239459  [  632/ 3000]\n",
      "loss: 0.073772  [  640/ 3000]\n",
      "loss: 0.189076  [  648/ 3000]\n",
      "loss: 0.272677  [  656/ 3000]\n",
      "loss: 0.232832  [  664/ 3000]\n",
      "loss: 0.125274  [  672/ 3000]\n",
      "loss: 0.115889  [  680/ 3000]\n",
      "loss: 0.107682  [  688/ 3000]\n",
      "loss: 0.258464  [  696/ 3000]\n",
      "loss: 0.114175  [  704/ 3000]\n",
      "loss: 0.096187  [  712/ 3000]\n",
      "loss: 0.106712  [  720/ 3000]\n",
      "loss: 0.078065  [  728/ 3000]\n",
      "loss: 0.114617  [  736/ 3000]\n",
      "loss: 0.099168  [  744/ 3000]\n",
      "loss: 0.183441  [  752/ 3000]\n",
      "loss: 0.135320  [  760/ 3000]\n",
      "loss: 0.159946  [  768/ 3000]\n",
      "loss: 0.111863  [  776/ 3000]\n",
      "loss: 0.249031  [  784/ 3000]\n",
      "loss: 0.154385  [  792/ 3000]\n",
      "loss: 0.224709  [  800/ 3000]\n",
      "loss: 0.124475  [  808/ 3000]\n",
      "loss: 0.088679  [  816/ 3000]\n",
      "loss: 0.094051  [  824/ 3000]\n",
      "loss: 0.117399  [  832/ 3000]\n",
      "loss: 0.077075  [  840/ 3000]\n",
      "loss: 0.076399  [  848/ 3000]\n",
      "loss: 0.073249  [  856/ 3000]\n",
      "loss: 0.153233  [  864/ 3000]\n",
      "loss: 0.079852  [  872/ 3000]\n",
      "loss: 0.095862  [  880/ 3000]\n",
      "loss: 0.192987  [  888/ 3000]\n",
      "loss: 0.096367  [  896/ 3000]\n",
      "loss: 0.260867  [  904/ 3000]\n",
      "loss: 0.109047  [  912/ 3000]\n",
      "loss: 0.096863  [  920/ 3000]\n",
      "loss: 0.132004  [  928/ 3000]\n",
      "loss: 0.102503  [  936/ 3000]\n",
      "loss: 0.237993  [  944/ 3000]\n",
      "loss: 0.080923  [  952/ 3000]\n",
      "loss: 0.111174  [  960/ 3000]\n",
      "loss: 0.081093  [  968/ 3000]\n",
      "loss: 0.057360  [  976/ 3000]\n",
      "loss: 0.073482  [  984/ 3000]\n",
      "loss: 0.218171  [  992/ 3000]\n",
      "loss: 0.159904  [ 1000/ 3000]\n",
      "loss: 0.104092  [ 1008/ 3000]\n",
      "loss: 0.184787  [ 1016/ 3000]\n",
      "loss: 0.111554  [ 1024/ 3000]\n",
      "loss: 0.163840  [ 1032/ 3000]\n",
      "loss: 0.046623  [ 1040/ 3000]\n",
      "loss: 0.089008  [ 1048/ 3000]\n",
      "loss: 0.058040  [ 1056/ 3000]\n",
      "loss: 0.118041  [ 1064/ 3000]\n",
      "loss: 0.093699  [ 1072/ 3000]\n",
      "loss: 0.097035  [ 1080/ 3000]\n",
      "loss: 0.185758  [ 1088/ 3000]\n",
      "loss: 0.130985  [ 1096/ 3000]\n",
      "loss: 0.068089  [ 1104/ 3000]\n",
      "loss: 0.173498  [ 1112/ 3000]\n",
      "loss: 0.071231  [ 1120/ 3000]\n",
      "loss: 0.091771  [ 1128/ 3000]\n",
      "loss: 0.117317  [ 1136/ 3000]\n",
      "loss: 0.203099  [ 1144/ 3000]\n",
      "loss: 0.089480  [ 1152/ 3000]\n",
      "loss: 0.063010  [ 1160/ 3000]\n",
      "loss: 0.087014  [ 1168/ 3000]\n",
      "loss: 0.080803  [ 1176/ 3000]\n",
      "loss: 0.230133  [ 1184/ 3000]\n",
      "loss: 0.109741  [ 1192/ 3000]\n",
      "loss: 0.112214  [ 1200/ 3000]\n",
      "loss: 0.107603  [ 1208/ 3000]\n",
      "loss: 0.106687  [ 1216/ 3000]\n",
      "loss: 0.143812  [ 1224/ 3000]\n",
      "loss: 0.155147  [ 1232/ 3000]\n",
      "loss: 0.138009  [ 1240/ 3000]\n",
      "loss: 0.171047  [ 1248/ 3000]\n",
      "loss: 0.042281  [ 1256/ 3000]\n",
      "loss: 0.084247  [ 1264/ 3000]\n",
      "loss: 0.070533  [ 1272/ 3000]\n",
      "loss: 0.112690  [ 1280/ 3000]\n",
      "loss: 0.163725  [ 1288/ 3000]\n",
      "loss: 0.080957  [ 1296/ 3000]\n",
      "loss: 0.039450  [ 1304/ 3000]\n",
      "loss: 0.163384  [ 1312/ 3000]\n",
      "loss: 0.351888  [ 1320/ 3000]\n",
      "loss: 0.164045  [ 1328/ 3000]\n",
      "loss: 0.129829  [ 1336/ 3000]\n",
      "loss: 0.210370  [ 1344/ 3000]\n",
      "loss: 0.124000  [ 1352/ 3000]\n",
      "loss: 0.099918  [ 1360/ 3000]\n",
      "loss: 0.189115  [ 1368/ 3000]\n",
      "loss: 0.212782  [ 1376/ 3000]\n",
      "loss: 0.165710  [ 1384/ 3000]\n",
      "loss: 0.097984  [ 1392/ 3000]\n",
      "loss: 0.154754  [ 1400/ 3000]\n",
      "loss: 0.124776  [ 1408/ 3000]\n",
      "loss: 0.161379  [ 1416/ 3000]\n",
      "loss: 0.188547  [ 1424/ 3000]\n",
      "loss: 0.129054  [ 1432/ 3000]\n",
      "loss: 0.075103  [ 1440/ 3000]\n",
      "loss: 0.103466  [ 1448/ 3000]\n",
      "loss: 0.139515  [ 1456/ 3000]\n",
      "loss: 0.032864  [ 1464/ 3000]\n",
      "loss: 0.083148  [ 1472/ 3000]\n",
      "loss: 0.061764  [ 1480/ 3000]\n",
      "loss: 0.178130  [ 1488/ 3000]\n",
      "loss: 0.082022  [ 1496/ 3000]\n",
      "loss: 0.110057  [ 1504/ 3000]\n",
      "loss: 0.115715  [ 1512/ 3000]\n",
      "loss: 0.138756  [ 1520/ 3000]\n",
      "loss: 0.088388  [ 1528/ 3000]\n",
      "loss: 0.125180  [ 1536/ 3000]\n",
      "loss: 0.083214  [ 1544/ 3000]\n",
      "loss: 0.170179  [ 1552/ 3000]\n",
      "loss: 0.085539  [ 1560/ 3000]\n",
      "loss: 0.082949  [ 1568/ 3000]\n",
      "loss: 0.087088  [ 1576/ 3000]\n",
      "loss: 0.157819  [ 1584/ 3000]\n",
      "loss: 0.079178  [ 1592/ 3000]\n",
      "loss: 0.160989  [ 1600/ 3000]\n",
      "loss: 0.091504  [ 1608/ 3000]\n",
      "loss: 0.193289  [ 1616/ 3000]\n",
      "loss: 0.166538  [ 1624/ 3000]\n",
      "loss: 0.086394  [ 1632/ 3000]\n",
      "loss: 0.087173  [ 1640/ 3000]\n",
      "loss: 0.151609  [ 1648/ 3000]\n",
      "loss: 0.068204  [ 1656/ 3000]\n",
      "loss: 0.235913  [ 1664/ 3000]\n",
      "loss: 0.073337  [ 1672/ 3000]\n",
      "loss: 0.085695  [ 1680/ 3000]\n",
      "loss: 0.104283  [ 1688/ 3000]\n",
      "loss: 0.164808  [ 1696/ 3000]\n",
      "loss: 0.112765  [ 1704/ 3000]\n",
      "loss: 0.065640  [ 1712/ 3000]\n",
      "loss: 0.097531  [ 1720/ 3000]\n",
      "loss: 0.121143  [ 1728/ 3000]\n",
      "loss: 0.124996  [ 1736/ 3000]\n",
      "loss: 0.135253  [ 1744/ 3000]\n",
      "loss: 0.051761  [ 1752/ 3000]\n",
      "loss: 0.044873  [ 1760/ 3000]\n",
      "loss: 0.199288  [ 1768/ 3000]\n",
      "loss: 0.117869  [ 1776/ 3000]\n",
      "loss: 0.075607  [ 1784/ 3000]\n",
      "loss: 0.084875  [ 1792/ 3000]\n",
      "loss: 0.155605  [ 1800/ 3000]\n",
      "loss: 0.202306  [ 1808/ 3000]\n",
      "loss: 0.058165  [ 1816/ 3000]\n",
      "loss: 0.168968  [ 1824/ 3000]\n",
      "loss: 0.043406  [ 1832/ 3000]\n",
      "loss: 0.024447  [ 1840/ 3000]\n",
      "loss: 0.117949  [ 1848/ 3000]\n",
      "loss: 0.116994  [ 1856/ 3000]\n",
      "loss: 0.129606  [ 1864/ 3000]\n",
      "loss: 0.127570  [ 1872/ 3000]\n",
      "loss: 0.042752  [ 1880/ 3000]\n",
      "loss: 0.066966  [ 1888/ 3000]\n",
      "loss: 0.130579  [ 1896/ 3000]\n",
      "loss: 0.055612  [ 1904/ 3000]\n",
      "loss: 0.091753  [ 1912/ 3000]\n",
      "loss: 0.154845  [ 1920/ 3000]\n",
      "loss: 0.127703  [ 1928/ 3000]\n",
      "loss: 0.178299  [ 1936/ 3000]\n",
      "loss: 0.060859  [ 1944/ 3000]\n",
      "loss: 0.130903  [ 1952/ 3000]\n",
      "loss: 0.058479  [ 1960/ 3000]\n",
      "loss: 0.159616  [ 1968/ 3000]\n",
      "loss: 0.076658  [ 1976/ 3000]\n",
      "loss: 0.180754  [ 1984/ 3000]\n",
      "loss: 0.174149  [ 1992/ 3000]\n",
      "loss: 0.124986  [ 2000/ 3000]\n",
      "loss: 0.151922  [ 2008/ 3000]\n",
      "loss: 0.114347  [ 2016/ 3000]\n",
      "loss: 0.095346  [ 2024/ 3000]\n",
      "loss: 0.154162  [ 2032/ 3000]\n",
      "loss: 0.137242  [ 2040/ 3000]\n",
      "loss: 0.082285  [ 2048/ 3000]\n",
      "loss: 0.080944  [ 2056/ 3000]\n",
      "loss: 0.064419  [ 2064/ 3000]\n",
      "loss: 0.201642  [ 2072/ 3000]\n",
      "loss: 0.090420  [ 2080/ 3000]\n",
      "loss: 0.181258  [ 2088/ 3000]\n",
      "loss: 0.127145  [ 2096/ 3000]\n",
      "loss: 0.066751  [ 2104/ 3000]\n",
      "loss: 0.065358  [ 2112/ 3000]\n",
      "loss: 0.057895  [ 2120/ 3000]\n",
      "loss: 0.099141  [ 2128/ 3000]\n",
      "loss: 0.107239  [ 2136/ 3000]\n",
      "loss: 0.168627  [ 2144/ 3000]\n",
      "loss: 0.183248  [ 2152/ 3000]\n",
      "loss: 0.052870  [ 2160/ 3000]\n",
      "loss: 0.104557  [ 2168/ 3000]\n",
      "loss: 0.073005  [ 2176/ 3000]\n",
      "loss: 0.131947  [ 2184/ 3000]\n",
      "loss: 0.125854  [ 2192/ 3000]\n",
      "loss: 0.060839  [ 2200/ 3000]\n",
      "loss: 0.047616  [ 2208/ 3000]\n",
      "loss: 0.089863  [ 2216/ 3000]\n",
      "loss: 0.147736  [ 2224/ 3000]\n",
      "loss: 0.101275  [ 2232/ 3000]\n",
      "loss: 0.181016  [ 2240/ 3000]\n",
      "loss: 0.047768  [ 2248/ 3000]\n",
      "loss: 0.125786  [ 2256/ 3000]\n",
      "loss: 0.052031  [ 2264/ 3000]\n",
      "loss: 0.155029  [ 2272/ 3000]\n",
      "loss: 0.084444  [ 2280/ 3000]\n",
      "loss: 0.182016  [ 2288/ 3000]\n",
      "loss: 0.102405  [ 2296/ 3000]\n",
      "loss: 0.067689  [ 2304/ 3000]\n",
      "loss: 0.049722  [ 2312/ 3000]\n",
      "loss: 0.058041  [ 2320/ 3000]\n",
      "loss: 0.130161  [ 2328/ 3000]\n",
      "loss: 0.051071  [ 2336/ 3000]\n",
      "loss: 0.157898  [ 2344/ 3000]\n",
      "loss: 0.182816  [ 2352/ 3000]\n",
      "loss: 0.127449  [ 2360/ 3000]\n",
      "loss: 0.096959  [ 2368/ 3000]\n",
      "loss: 0.061875  [ 2376/ 3000]\n",
      "loss: 0.084545  [ 2384/ 3000]\n",
      "loss: 0.087108  [ 2392/ 3000]\n",
      "loss: 0.050293  [ 2400/ 3000]\n",
      "loss: 0.176952  [ 2408/ 3000]\n",
      "loss: 0.116176  [ 2416/ 3000]\n",
      "loss: 0.118287  [ 2424/ 3000]\n",
      "loss: 0.150151  [ 2432/ 3000]\n",
      "loss: 0.088008  [ 2440/ 3000]\n",
      "loss: 0.152883  [ 2448/ 3000]\n",
      "loss: 0.166641  [ 2456/ 3000]\n",
      "loss: 0.088693  [ 2464/ 3000]\n",
      "loss: 0.268361  [ 2472/ 3000]\n",
      "loss: 0.052428  [ 2480/ 3000]\n",
      "loss: 0.106508  [ 2488/ 3000]\n",
      "loss: 0.052156  [ 2496/ 3000]\n",
      "loss: 0.077106  [ 2504/ 3000]\n",
      "loss: 0.194264  [ 2512/ 3000]\n",
      "loss: 0.264761  [ 2520/ 3000]\n",
      "loss: 0.083196  [ 2528/ 3000]\n",
      "loss: 0.111897  [ 2536/ 3000]\n",
      "loss: 0.068863  [ 2544/ 3000]\n",
      "loss: 0.149026  [ 2552/ 3000]\n",
      "loss: 0.120389  [ 2560/ 3000]\n",
      "loss: 0.191444  [ 2568/ 3000]\n",
      "loss: 0.153212  [ 2576/ 3000]\n",
      "loss: 0.129313  [ 2584/ 3000]\n",
      "loss: 0.093519  [ 2592/ 3000]\n",
      "loss: 0.092680  [ 2600/ 3000]\n",
      "loss: 0.136733  [ 2608/ 3000]\n",
      "loss: 0.068524  [ 2616/ 3000]\n",
      "loss: 0.082663  [ 2624/ 3000]\n",
      "loss: 0.151175  [ 2632/ 3000]\n",
      "loss: 0.180942  [ 2640/ 3000]\n",
      "loss: 0.128438  [ 2648/ 3000]\n",
      "loss: 0.141133  [ 2656/ 3000]\n",
      "loss: 0.106368  [ 2664/ 3000]\n",
      "loss: 0.166813  [ 2672/ 3000]\n",
      "loss: 0.178130  [ 2680/ 3000]\n",
      "loss: 0.103270  [ 2688/ 3000]\n",
      "loss: 0.087179  [ 2696/ 3000]\n",
      "loss: 0.115888  [ 2704/ 3000]\n",
      "loss: 0.163956  [ 2712/ 3000]\n",
      "loss: 0.106702  [ 2720/ 3000]\n",
      "loss: 0.172511  [ 2728/ 3000]\n",
      "loss: 0.062345  [ 2736/ 3000]\n",
      "loss: 0.128383  [ 2744/ 3000]\n",
      "loss: 0.136874  [ 2752/ 3000]\n",
      "loss: 0.093271  [ 2760/ 3000]\n",
      "loss: 0.055617  [ 2768/ 3000]\n",
      "loss: 0.178903  [ 2776/ 3000]\n",
      "loss: 0.109169  [ 2784/ 3000]\n",
      "loss: 0.092509  [ 2792/ 3000]\n",
      "loss: 0.181791  [ 2800/ 3000]\n",
      "loss: 0.204237  [ 2808/ 3000]\n",
      "loss: 0.122040  [ 2816/ 3000]\n",
      "loss: 0.122629  [ 2824/ 3000]\n",
      "loss: 0.136100  [ 2832/ 3000]\n",
      "loss: 0.106443  [ 2840/ 3000]\n",
      "loss: 0.097947  [ 2848/ 3000]\n",
      "loss: 0.130306  [ 2856/ 3000]\n",
      "loss: 0.078467  [ 2864/ 3000]\n",
      "loss: 0.145767  [ 2872/ 3000]\n",
      "loss: 0.168136  [ 2880/ 3000]\n",
      "loss: 0.063597  [ 2888/ 3000]\n",
      "loss: 0.040308  [ 2896/ 3000]\n",
      "loss: 0.137471  [ 2904/ 3000]\n",
      "loss: 0.139592  [ 2912/ 3000]\n",
      "loss: 0.113849  [ 2920/ 3000]\n",
      "loss: 0.177293  [ 2928/ 3000]\n",
      "loss: 0.251052  [ 2936/ 3000]\n",
      "loss: 0.067644  [ 2944/ 3000]\n",
      "loss: 0.025655  [ 2952/ 3000]\n",
      "loss: 0.060149  [ 2960/ 3000]\n",
      "loss: 0.082220  [ 2968/ 3000]\n",
      "loss: 0.078704  [ 2976/ 3000]\n",
      "loss: 0.102177  [ 2984/ 3000]\n",
      "loss: 0.042596  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.113236 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.073623  [    0/ 3000]\n",
      "loss: 0.129254  [    8/ 3000]\n",
      "loss: 0.072362  [   16/ 3000]\n",
      "loss: 0.068695  [   24/ 3000]\n",
      "loss: 0.181797  [   32/ 3000]\n",
      "loss: 0.058530  [   40/ 3000]\n",
      "loss: 0.052134  [   48/ 3000]\n",
      "loss: 0.113998  [   56/ 3000]\n",
      "loss: 0.208380  [   64/ 3000]\n",
      "loss: 0.048806  [   72/ 3000]\n",
      "loss: 0.199557  [   80/ 3000]\n",
      "loss: 0.151019  [   88/ 3000]\n",
      "loss: 0.173406  [   96/ 3000]\n",
      "loss: 0.097041  [  104/ 3000]\n",
      "loss: 0.212295  [  112/ 3000]\n",
      "loss: 0.075275  [  120/ 3000]\n",
      "loss: 0.063298  [  128/ 3000]\n",
      "loss: 0.163388  [  136/ 3000]\n",
      "loss: 0.141917  [  144/ 3000]\n",
      "loss: 0.077562  [  152/ 3000]\n",
      "loss: 0.055555  [  160/ 3000]\n",
      "loss: 0.042050  [  168/ 3000]\n",
      "loss: 0.070641  [  176/ 3000]\n",
      "loss: 0.141227  [  184/ 3000]\n",
      "loss: 0.101103  [  192/ 3000]\n",
      "loss: 0.076414  [  200/ 3000]\n",
      "loss: 0.204162  [  208/ 3000]\n",
      "loss: 0.084292  [  216/ 3000]\n",
      "loss: 0.098624  [  224/ 3000]\n",
      "loss: 0.201701  [  232/ 3000]\n",
      "loss: 0.116069  [  240/ 3000]\n",
      "loss: 0.084769  [  248/ 3000]\n",
      "loss: 0.061858  [  256/ 3000]\n",
      "loss: 0.142990  [  264/ 3000]\n",
      "loss: 0.084334  [  272/ 3000]\n",
      "loss: 0.199730  [  280/ 3000]\n",
      "loss: 0.059115  [  288/ 3000]\n",
      "loss: 0.090398  [  296/ 3000]\n",
      "loss: 0.081537  [  304/ 3000]\n",
      "loss: 0.148057  [  312/ 3000]\n",
      "loss: 0.100414  [  320/ 3000]\n",
      "loss: 0.232313  [  328/ 3000]\n",
      "loss: 0.096025  [  336/ 3000]\n",
      "loss: 0.111558  [  344/ 3000]\n",
      "loss: 0.053828  [  352/ 3000]\n",
      "loss: 0.053323  [  360/ 3000]\n",
      "loss: 0.172517  [  368/ 3000]\n",
      "loss: 0.048028  [  376/ 3000]\n",
      "loss: 0.153144  [  384/ 3000]\n",
      "loss: 0.089701  [  392/ 3000]\n",
      "loss: 0.168570  [  400/ 3000]\n",
      "loss: 0.076013  [  408/ 3000]\n",
      "loss: 0.154014  [  416/ 3000]\n",
      "loss: 0.094059  [  424/ 3000]\n",
      "loss: 0.220004  [  432/ 3000]\n",
      "loss: 0.075894  [  440/ 3000]\n",
      "loss: 0.134939  [  448/ 3000]\n",
      "loss: 0.088334  [  456/ 3000]\n",
      "loss: 0.183603  [  464/ 3000]\n",
      "loss: 0.091220  [  472/ 3000]\n",
      "loss: 0.042176  [  480/ 3000]\n",
      "loss: 0.172385  [  488/ 3000]\n",
      "loss: 0.121238  [  496/ 3000]\n",
      "loss: 0.070550  [  504/ 3000]\n",
      "loss: 0.117554  [  512/ 3000]\n",
      "loss: 0.061180  [  520/ 3000]\n",
      "loss: 0.279280  [  528/ 3000]\n",
      "loss: 0.159253  [  536/ 3000]\n",
      "loss: 0.143547  [  544/ 3000]\n",
      "loss: 0.098039  [  552/ 3000]\n",
      "loss: 0.083983  [  560/ 3000]\n",
      "loss: 0.140899  [  568/ 3000]\n",
      "loss: 0.116941  [  576/ 3000]\n",
      "loss: 0.136165  [  584/ 3000]\n",
      "loss: 0.077352  [  592/ 3000]\n",
      "loss: 0.222086  [  600/ 3000]\n",
      "loss: 0.056120  [  608/ 3000]\n",
      "loss: 0.153297  [  616/ 3000]\n",
      "loss: 0.116224  [  624/ 3000]\n",
      "loss: 0.230833  [  632/ 3000]\n",
      "loss: 0.060549  [  640/ 3000]\n",
      "loss: 0.190137  [  648/ 3000]\n",
      "loss: 0.268728  [  656/ 3000]\n",
      "loss: 0.221384  [  664/ 3000]\n",
      "loss: 0.108369  [  672/ 3000]\n",
      "loss: 0.113486  [  680/ 3000]\n",
      "loss: 0.094662  [  688/ 3000]\n",
      "loss: 0.249305  [  696/ 3000]\n",
      "loss: 0.099361  [  704/ 3000]\n",
      "loss: 0.085759  [  712/ 3000]\n",
      "loss: 0.089193  [  720/ 3000]\n",
      "loss: 0.064333  [  728/ 3000]\n",
      "loss: 0.098616  [  736/ 3000]\n",
      "loss: 0.084873  [  744/ 3000]\n",
      "loss: 0.162553  [  752/ 3000]\n",
      "loss: 0.123890  [  760/ 3000]\n",
      "loss: 0.148814  [  768/ 3000]\n",
      "loss: 0.100880  [  776/ 3000]\n",
      "loss: 0.236959  [  784/ 3000]\n",
      "loss: 0.139075  [  792/ 3000]\n",
      "loss: 0.216117  [  800/ 3000]\n",
      "loss: 0.110963  [  808/ 3000]\n",
      "loss: 0.074620  [  816/ 3000]\n",
      "loss: 0.084157  [  824/ 3000]\n",
      "loss: 0.107976  [  832/ 3000]\n",
      "loss: 0.062599  [  840/ 3000]\n",
      "loss: 0.055054  [  848/ 3000]\n",
      "loss: 0.057569  [  856/ 3000]\n",
      "loss: 0.141338  [  864/ 3000]\n",
      "loss: 0.051388  [  872/ 3000]\n",
      "loss: 0.095421  [  880/ 3000]\n",
      "loss: 0.170399  [  888/ 3000]\n",
      "loss: 0.088990  [  896/ 3000]\n",
      "loss: 0.255545  [  904/ 3000]\n",
      "loss: 0.093206  [  912/ 3000]\n",
      "loss: 0.090512  [  920/ 3000]\n",
      "loss: 0.116866  [  928/ 3000]\n",
      "loss: 0.090496  [  936/ 3000]\n",
      "loss: 0.234439  [  944/ 3000]\n",
      "loss: 0.071351  [  952/ 3000]\n",
      "loss: 0.095304  [  960/ 3000]\n",
      "loss: 0.064857  [  968/ 3000]\n",
      "loss: 0.039414  [  976/ 3000]\n",
      "loss: 0.052441  [  984/ 3000]\n",
      "loss: 0.199752  [  992/ 3000]\n",
      "loss: 0.142876  [ 1000/ 3000]\n",
      "loss: 0.094678  [ 1008/ 3000]\n",
      "loss: 0.174240  [ 1016/ 3000]\n",
      "loss: 0.101491  [ 1024/ 3000]\n",
      "loss: 0.151911  [ 1032/ 3000]\n",
      "loss: 0.039330  [ 1040/ 3000]\n",
      "loss: 0.079781  [ 1048/ 3000]\n",
      "loss: 0.047258  [ 1056/ 3000]\n",
      "loss: 0.109682  [ 1064/ 3000]\n",
      "loss: 0.080425  [ 1072/ 3000]\n",
      "loss: 0.086267  [ 1080/ 3000]\n",
      "loss: 0.171972  [ 1088/ 3000]\n",
      "loss: 0.131722  [ 1096/ 3000]\n",
      "loss: 0.056488  [ 1104/ 3000]\n",
      "loss: 0.158119  [ 1112/ 3000]\n",
      "loss: 0.061415  [ 1120/ 3000]\n",
      "loss: 0.081782  [ 1128/ 3000]\n",
      "loss: 0.104161  [ 1136/ 3000]\n",
      "loss: 0.192429  [ 1144/ 3000]\n",
      "loss: 0.078003  [ 1152/ 3000]\n",
      "loss: 0.054874  [ 1160/ 3000]\n",
      "loss: 0.073992  [ 1168/ 3000]\n",
      "loss: 0.066488  [ 1176/ 3000]\n",
      "loss: 0.230407  [ 1184/ 3000]\n",
      "loss: 0.099090  [ 1192/ 3000]\n",
      "loss: 0.098877  [ 1200/ 3000]\n",
      "loss: 0.085790  [ 1208/ 3000]\n",
      "loss: 0.094999  [ 1216/ 3000]\n",
      "loss: 0.136784  [ 1224/ 3000]\n",
      "loss: 0.146244  [ 1232/ 3000]\n",
      "loss: 0.126901  [ 1240/ 3000]\n",
      "loss: 0.156329  [ 1248/ 3000]\n",
      "loss: 0.032336  [ 1256/ 3000]\n",
      "loss: 0.073819  [ 1264/ 3000]\n",
      "loss: 0.058583  [ 1272/ 3000]\n",
      "loss: 0.095859  [ 1280/ 3000]\n",
      "loss: 0.140720  [ 1288/ 3000]\n",
      "loss: 0.065722  [ 1296/ 3000]\n",
      "loss: 0.026154  [ 1304/ 3000]\n",
      "loss: 0.155609  [ 1312/ 3000]\n",
      "loss: 0.353344  [ 1320/ 3000]\n",
      "loss: 0.157018  [ 1328/ 3000]\n",
      "loss: 0.117005  [ 1336/ 3000]\n",
      "loss: 0.201824  [ 1344/ 3000]\n",
      "loss: 0.116261  [ 1352/ 3000]\n",
      "loss: 0.088989  [ 1360/ 3000]\n",
      "loss: 0.179524  [ 1368/ 3000]\n",
      "loss: 0.197407  [ 1376/ 3000]\n",
      "loss: 0.144544  [ 1384/ 3000]\n",
      "loss: 0.085467  [ 1392/ 3000]\n",
      "loss: 0.141849  [ 1400/ 3000]\n",
      "loss: 0.119287  [ 1408/ 3000]\n",
      "loss: 0.149560  [ 1416/ 3000]\n",
      "loss: 0.171731  [ 1424/ 3000]\n",
      "loss: 0.114006  [ 1432/ 3000]\n",
      "loss: 0.066980  [ 1440/ 3000]\n",
      "loss: 0.086039  [ 1448/ 3000]\n",
      "loss: 0.119822  [ 1456/ 3000]\n",
      "loss: 0.023755  [ 1464/ 3000]\n",
      "loss: 0.071749  [ 1472/ 3000]\n",
      "loss: 0.048835  [ 1480/ 3000]\n",
      "loss: 0.168658  [ 1488/ 3000]\n",
      "loss: 0.066415  [ 1496/ 3000]\n",
      "loss: 0.098214  [ 1504/ 3000]\n",
      "loss: 0.108608  [ 1512/ 3000]\n",
      "loss: 0.132075  [ 1520/ 3000]\n",
      "loss: 0.074177  [ 1528/ 3000]\n",
      "loss: 0.119559  [ 1536/ 3000]\n",
      "loss: 0.072352  [ 1544/ 3000]\n",
      "loss: 0.164275  [ 1552/ 3000]\n",
      "loss: 0.075612  [ 1560/ 3000]\n",
      "loss: 0.074344  [ 1568/ 3000]\n",
      "loss: 0.071137  [ 1576/ 3000]\n",
      "loss: 0.151070  [ 1584/ 3000]\n",
      "loss: 0.073786  [ 1592/ 3000]\n",
      "loss: 0.149091  [ 1600/ 3000]\n",
      "loss: 0.078949  [ 1608/ 3000]\n",
      "loss: 0.183696  [ 1616/ 3000]\n",
      "loss: 0.155323  [ 1624/ 3000]\n",
      "loss: 0.075225  [ 1632/ 3000]\n",
      "loss: 0.075924  [ 1640/ 3000]\n",
      "loss: 0.149507  [ 1648/ 3000]\n",
      "loss: 0.060506  [ 1656/ 3000]\n",
      "loss: 0.218351  [ 1664/ 3000]\n",
      "loss: 0.058068  [ 1672/ 3000]\n",
      "loss: 0.078735  [ 1680/ 3000]\n",
      "loss: 0.095152  [ 1688/ 3000]\n",
      "loss: 0.150361  [ 1696/ 3000]\n",
      "loss: 0.100297  [ 1704/ 3000]\n",
      "loss: 0.054424  [ 1712/ 3000]\n",
      "loss: 0.087697  [ 1720/ 3000]\n",
      "loss: 0.102912  [ 1728/ 3000]\n",
      "loss: 0.118425  [ 1736/ 3000]\n",
      "loss: 0.122258  [ 1744/ 3000]\n",
      "loss: 0.041773  [ 1752/ 3000]\n",
      "loss: 0.035859  [ 1760/ 3000]\n",
      "loss: 0.181287  [ 1768/ 3000]\n",
      "loss: 0.110073  [ 1776/ 3000]\n",
      "loss: 0.064154  [ 1784/ 3000]\n",
      "loss: 0.075508  [ 1792/ 3000]\n",
      "loss: 0.147879  [ 1800/ 3000]\n",
      "loss: 0.191603  [ 1808/ 3000]\n",
      "loss: 0.051785  [ 1816/ 3000]\n",
      "loss: 0.166241  [ 1824/ 3000]\n",
      "loss: 0.031986  [ 1832/ 3000]\n",
      "loss: 0.019620  [ 1840/ 3000]\n",
      "loss: 0.106653  [ 1848/ 3000]\n",
      "loss: 0.113043  [ 1856/ 3000]\n",
      "loss: 0.118479  [ 1864/ 3000]\n",
      "loss: 0.112634  [ 1872/ 3000]\n",
      "loss: 0.033720  [ 1880/ 3000]\n",
      "loss: 0.052707  [ 1888/ 3000]\n",
      "loss: 0.122355  [ 1896/ 3000]\n",
      "loss: 0.047830  [ 1904/ 3000]\n",
      "loss: 0.080440  [ 1912/ 3000]\n",
      "loss: 0.145891  [ 1920/ 3000]\n",
      "loss: 0.120761  [ 1928/ 3000]\n",
      "loss: 0.180783  [ 1936/ 3000]\n",
      "loss: 0.049883  [ 1944/ 3000]\n",
      "loss: 0.124598  [ 1952/ 3000]\n",
      "loss: 0.049116  [ 1960/ 3000]\n",
      "loss: 0.153451  [ 1968/ 3000]\n",
      "loss: 0.063504  [ 1976/ 3000]\n",
      "loss: 0.166715  [ 1984/ 3000]\n",
      "loss: 0.165225  [ 1992/ 3000]\n",
      "loss: 0.114913  [ 2000/ 3000]\n",
      "loss: 0.143035  [ 2008/ 3000]\n",
      "loss: 0.103074  [ 2016/ 3000]\n",
      "loss: 0.085319  [ 2024/ 3000]\n",
      "loss: 0.144530  [ 2032/ 3000]\n",
      "loss: 0.127195  [ 2040/ 3000]\n",
      "loss: 0.070343  [ 2048/ 3000]\n",
      "loss: 0.072292  [ 2056/ 3000]\n",
      "loss: 0.058112  [ 2064/ 3000]\n",
      "loss: 0.185000  [ 2072/ 3000]\n",
      "loss: 0.081963  [ 2080/ 3000]\n",
      "loss: 0.169124  [ 2088/ 3000]\n",
      "loss: 0.116024  [ 2096/ 3000]\n",
      "loss: 0.065363  [ 2104/ 3000]\n",
      "loss: 0.055629  [ 2112/ 3000]\n",
      "loss: 0.044302  [ 2120/ 3000]\n",
      "loss: 0.095768  [ 2128/ 3000]\n",
      "loss: 0.100006  [ 2136/ 3000]\n",
      "loss: 0.158081  [ 2144/ 3000]\n",
      "loss: 0.172504  [ 2152/ 3000]\n",
      "loss: 0.047524  [ 2160/ 3000]\n",
      "loss: 0.098338  [ 2168/ 3000]\n",
      "loss: 0.061595  [ 2176/ 3000]\n",
      "loss: 0.122463  [ 2184/ 3000]\n",
      "loss: 0.119191  [ 2192/ 3000]\n",
      "loss: 0.054448  [ 2200/ 3000]\n",
      "loss: 0.040686  [ 2208/ 3000]\n",
      "loss: 0.077422  [ 2216/ 3000]\n",
      "loss: 0.137317  [ 2224/ 3000]\n",
      "loss: 0.097063  [ 2232/ 3000]\n",
      "loss: 0.170827  [ 2240/ 3000]\n",
      "loss: 0.035668  [ 2248/ 3000]\n",
      "loss: 0.113237  [ 2256/ 3000]\n",
      "loss: 0.044405  [ 2264/ 3000]\n",
      "loss: 0.154337  [ 2272/ 3000]\n",
      "loss: 0.074028  [ 2280/ 3000]\n",
      "loss: 0.173463  [ 2288/ 3000]\n",
      "loss: 0.095919  [ 2296/ 3000]\n",
      "loss: 0.064880  [ 2304/ 3000]\n",
      "loss: 0.046704  [ 2312/ 3000]\n",
      "loss: 0.048369  [ 2320/ 3000]\n",
      "loss: 0.118326  [ 2328/ 3000]\n",
      "loss: 0.039881  [ 2336/ 3000]\n",
      "loss: 0.151641  [ 2344/ 3000]\n",
      "loss: 0.174725  [ 2352/ 3000]\n",
      "loss: 0.122920  [ 2360/ 3000]\n",
      "loss: 0.085333  [ 2368/ 3000]\n",
      "loss: 0.050729  [ 2376/ 3000]\n",
      "loss: 0.077772  [ 2384/ 3000]\n",
      "loss: 0.078885  [ 2392/ 3000]\n",
      "loss: 0.039793  [ 2400/ 3000]\n",
      "loss: 0.168182  [ 2408/ 3000]\n",
      "loss: 0.105782  [ 2416/ 3000]\n",
      "loss: 0.115086  [ 2424/ 3000]\n",
      "loss: 0.142808  [ 2432/ 3000]\n",
      "loss: 0.079935  [ 2440/ 3000]\n",
      "loss: 0.151140  [ 2448/ 3000]\n",
      "loss: 0.160585  [ 2456/ 3000]\n",
      "loss: 0.081320  [ 2464/ 3000]\n",
      "loss: 0.268090  [ 2472/ 3000]\n",
      "loss: 0.047446  [ 2480/ 3000]\n",
      "loss: 0.095424  [ 2488/ 3000]\n",
      "loss: 0.045185  [ 2496/ 3000]\n",
      "loss: 0.069125  [ 2504/ 3000]\n",
      "loss: 0.180707  [ 2512/ 3000]\n",
      "loss: 0.260067  [ 2520/ 3000]\n",
      "loss: 0.072020  [ 2528/ 3000]\n",
      "loss: 0.100650  [ 2536/ 3000]\n",
      "loss: 0.057172  [ 2544/ 3000]\n",
      "loss: 0.138319  [ 2552/ 3000]\n",
      "loss: 0.113394  [ 2560/ 3000]\n",
      "loss: 0.182210  [ 2568/ 3000]\n",
      "loss: 0.150813  [ 2576/ 3000]\n",
      "loss: 0.113333  [ 2584/ 3000]\n",
      "loss: 0.086937  [ 2592/ 3000]\n",
      "loss: 0.089682  [ 2600/ 3000]\n",
      "loss: 0.127172  [ 2608/ 3000]\n",
      "loss: 0.060198  [ 2616/ 3000]\n",
      "loss: 0.072454  [ 2624/ 3000]\n",
      "loss: 0.141527  [ 2632/ 3000]\n",
      "loss: 0.170969  [ 2640/ 3000]\n",
      "loss: 0.118385  [ 2648/ 3000]\n",
      "loss: 0.130223  [ 2656/ 3000]\n",
      "loss: 0.096963  [ 2664/ 3000]\n",
      "loss: 0.156895  [ 2672/ 3000]\n",
      "loss: 0.172126  [ 2680/ 3000]\n",
      "loss: 0.089896  [ 2688/ 3000]\n",
      "loss: 0.075726  [ 2696/ 3000]\n",
      "loss: 0.109648  [ 2704/ 3000]\n",
      "loss: 0.149121  [ 2712/ 3000]\n",
      "loss: 0.099414  [ 2720/ 3000]\n",
      "loss: 0.164932  [ 2728/ 3000]\n",
      "loss: 0.053231  [ 2736/ 3000]\n",
      "loss: 0.116234  [ 2744/ 3000]\n",
      "loss: 0.132232  [ 2752/ 3000]\n",
      "loss: 0.088946  [ 2760/ 3000]\n",
      "loss: 0.047971  [ 2768/ 3000]\n",
      "loss: 0.170404  [ 2776/ 3000]\n",
      "loss: 0.103165  [ 2784/ 3000]\n",
      "loss: 0.083735  [ 2792/ 3000]\n",
      "loss: 0.161575  [ 2800/ 3000]\n",
      "loss: 0.196973  [ 2808/ 3000]\n",
      "loss: 0.114090  [ 2816/ 3000]\n",
      "loss: 0.113081  [ 2824/ 3000]\n",
      "loss: 0.127118  [ 2832/ 3000]\n",
      "loss: 0.095636  [ 2840/ 3000]\n",
      "loss: 0.091655  [ 2848/ 3000]\n",
      "loss: 0.123049  [ 2856/ 3000]\n",
      "loss: 0.071107  [ 2864/ 3000]\n",
      "loss: 0.134457  [ 2872/ 3000]\n",
      "loss: 0.161525  [ 2880/ 3000]\n",
      "loss: 0.052997  [ 2888/ 3000]\n",
      "loss: 0.034348  [ 2896/ 3000]\n",
      "loss: 0.125321  [ 2904/ 3000]\n",
      "loss: 0.134046  [ 2912/ 3000]\n",
      "loss: 0.104531  [ 2920/ 3000]\n",
      "loss: 0.164353  [ 2928/ 3000]\n",
      "loss: 0.243909  [ 2936/ 3000]\n",
      "loss: 0.061459  [ 2944/ 3000]\n",
      "loss: 0.019545  [ 2952/ 3000]\n",
      "loss: 0.052630  [ 2960/ 3000]\n",
      "loss: 0.080957  [ 2968/ 3000]\n",
      "loss: 0.073452  [ 2976/ 3000]\n",
      "loss: 0.093046  [ 2984/ 3000]\n",
      "loss: 0.036616  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.106487 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.063996  [    0/ 3000]\n",
      "loss: 0.118769  [    8/ 3000]\n",
      "loss: 0.066074  [   16/ 3000]\n",
      "loss: 0.063566  [   24/ 3000]\n",
      "loss: 0.171127  [   32/ 3000]\n",
      "loss: 0.048739  [   40/ 3000]\n",
      "loss: 0.045374  [   48/ 3000]\n",
      "loss: 0.109942  [   56/ 3000]\n",
      "loss: 0.205810  [   64/ 3000]\n",
      "loss: 0.041046  [   72/ 3000]\n",
      "loss: 0.192896  [   80/ 3000]\n",
      "loss: 0.139185  [   88/ 3000]\n",
      "loss: 0.163355  [   96/ 3000]\n",
      "loss: 0.091930  [  104/ 3000]\n",
      "loss: 0.207510  [  112/ 3000]\n",
      "loss: 0.067014  [  120/ 3000]\n",
      "loss: 0.058176  [  128/ 3000]\n",
      "loss: 0.148482  [  136/ 3000]\n",
      "loss: 0.126946  [  144/ 3000]\n",
      "loss: 0.069772  [  152/ 3000]\n",
      "loss: 0.047576  [  160/ 3000]\n",
      "loss: 0.036274  [  168/ 3000]\n",
      "loss: 0.064581  [  176/ 3000]\n",
      "loss: 0.131664  [  184/ 3000]\n",
      "loss: 0.093923  [  192/ 3000]\n",
      "loss: 0.070354  [  200/ 3000]\n",
      "loss: 0.202779  [  208/ 3000]\n",
      "loss: 0.073752  [  216/ 3000]\n",
      "loss: 0.092528  [  224/ 3000]\n",
      "loss: 0.190331  [  232/ 3000]\n",
      "loss: 0.102903  [  240/ 3000]\n",
      "loss: 0.076208  [  248/ 3000]\n",
      "loss: 0.056987  [  256/ 3000]\n",
      "loss: 0.137448  [  264/ 3000]\n",
      "loss: 0.076314  [  272/ 3000]\n",
      "loss: 0.197488  [  280/ 3000]\n",
      "loss: 0.053531  [  288/ 3000]\n",
      "loss: 0.083667  [  296/ 3000]\n",
      "loss: 0.072161  [  304/ 3000]\n",
      "loss: 0.144819  [  312/ 3000]\n",
      "loss: 0.090756  [  320/ 3000]\n",
      "loss: 0.218605  [  328/ 3000]\n",
      "loss: 0.090458  [  336/ 3000]\n",
      "loss: 0.106242  [  344/ 3000]\n",
      "loss: 0.048101  [  352/ 3000]\n",
      "loss: 0.048676  [  360/ 3000]\n",
      "loss: 0.167659  [  368/ 3000]\n",
      "loss: 0.046293  [  376/ 3000]\n",
      "loss: 0.144149  [  384/ 3000]\n",
      "loss: 0.083368  [  392/ 3000]\n",
      "loss: 0.156842  [  400/ 3000]\n",
      "loss: 0.067660  [  408/ 3000]\n",
      "loss: 0.149442  [  416/ 3000]\n",
      "loss: 0.088115  [  424/ 3000]\n",
      "loss: 0.218186  [  432/ 3000]\n",
      "loss: 0.067964  [  440/ 3000]\n",
      "loss: 0.128299  [  448/ 3000]\n",
      "loss: 0.082678  [  456/ 3000]\n",
      "loss: 0.175255  [  464/ 3000]\n",
      "loss: 0.086227  [  472/ 3000]\n",
      "loss: 0.037277  [  480/ 3000]\n",
      "loss: 0.170144  [  488/ 3000]\n",
      "loss: 0.117603  [  496/ 3000]\n",
      "loss: 0.065972  [  504/ 3000]\n",
      "loss: 0.107354  [  512/ 3000]\n",
      "loss: 0.059892  [  520/ 3000]\n",
      "loss: 0.269158  [  528/ 3000]\n",
      "loss: 0.147286  [  536/ 3000]\n",
      "loss: 0.134992  [  544/ 3000]\n",
      "loss: 0.093398  [  552/ 3000]\n",
      "loss: 0.077203  [  560/ 3000]\n",
      "loss: 0.134396  [  568/ 3000]\n",
      "loss: 0.106695  [  576/ 3000]\n",
      "loss: 0.124602  [  584/ 3000]\n",
      "loss: 0.067753  [  592/ 3000]\n",
      "loss: 0.214045  [  600/ 3000]\n",
      "loss: 0.053995  [  608/ 3000]\n",
      "loss: 0.143857  [  616/ 3000]\n",
      "loss: 0.105788  [  624/ 3000]\n",
      "loss: 0.228507  [  632/ 3000]\n",
      "loss: 0.051801  [  640/ 3000]\n",
      "loss: 0.188717  [  648/ 3000]\n",
      "loss: 0.264427  [  656/ 3000]\n",
      "loss: 0.213782  [  664/ 3000]\n",
      "loss: 0.101710  [  672/ 3000]\n",
      "loss: 0.110959  [  680/ 3000]\n",
      "loss: 0.088211  [  688/ 3000]\n",
      "loss: 0.242230  [  696/ 3000]\n",
      "loss: 0.093331  [  704/ 3000]\n",
      "loss: 0.080959  [  712/ 3000]\n",
      "loss: 0.082747  [  720/ 3000]\n",
      "loss: 0.058992  [  728/ 3000]\n",
      "loss: 0.091220  [  736/ 3000]\n",
      "loss: 0.077424  [  744/ 3000]\n",
      "loss: 0.151595  [  752/ 3000]\n",
      "loss: 0.117792  [  760/ 3000]\n",
      "loss: 0.144267  [  768/ 3000]\n",
      "loss: 0.096723  [  776/ 3000]\n",
      "loss: 0.229711  [  784/ 3000]\n",
      "loss: 0.131217  [  792/ 3000]\n",
      "loss: 0.210455  [  800/ 3000]\n",
      "loss: 0.103603  [  808/ 3000]\n",
      "loss: 0.067805  [  816/ 3000]\n",
      "loss: 0.079330  [  824/ 3000]\n",
      "loss: 0.101169  [  832/ 3000]\n",
      "loss: 0.055761  [  840/ 3000]\n",
      "loss: 0.046204  [  848/ 3000]\n",
      "loss: 0.050384  [  856/ 3000]\n",
      "loss: 0.134476  [  864/ 3000]\n",
      "loss: 0.040103  [  872/ 3000]\n",
      "loss: 0.096051  [  880/ 3000]\n",
      "loss: 0.158251  [  888/ 3000]\n",
      "loss: 0.085960  [  896/ 3000]\n",
      "loss: 0.252709  [  904/ 3000]\n",
      "loss: 0.086941  [  912/ 3000]\n",
      "loss: 0.087675  [  920/ 3000]\n",
      "loss: 0.109462  [  928/ 3000]\n",
      "loss: 0.083456  [  936/ 3000]\n",
      "loss: 0.232154  [  944/ 3000]\n",
      "loss: 0.065527  [  952/ 3000]\n",
      "loss: 0.087168  [  960/ 3000]\n",
      "loss: 0.056894  [  968/ 3000]\n",
      "loss: 0.032241  [  976/ 3000]\n",
      "loss: 0.044106  [  984/ 3000]\n",
      "loss: 0.187758  [  992/ 3000]\n",
      "loss: 0.129679  [ 1000/ 3000]\n",
      "loss: 0.091481  [ 1008/ 3000]\n",
      "loss: 0.168413  [ 1016/ 3000]\n",
      "loss: 0.096906  [ 1024/ 3000]\n",
      "loss: 0.147284  [ 1032/ 3000]\n",
      "loss: 0.036238  [ 1040/ 3000]\n",
      "loss: 0.073830  [ 1048/ 3000]\n",
      "loss: 0.042307  [ 1056/ 3000]\n",
      "loss: 0.105599  [ 1064/ 3000]\n",
      "loss: 0.075052  [ 1072/ 3000]\n",
      "loss: 0.080936  [ 1080/ 3000]\n",
      "loss: 0.165246  [ 1088/ 3000]\n",
      "loss: 0.130639  [ 1096/ 3000]\n",
      "loss: 0.050468  [ 1104/ 3000]\n",
      "loss: 0.151773  [ 1112/ 3000]\n",
      "loss: 0.056651  [ 1120/ 3000]\n",
      "loss: 0.074827  [ 1128/ 3000]\n",
      "loss: 0.096009  [ 1136/ 3000]\n",
      "loss: 0.184238  [ 1144/ 3000]\n",
      "loss: 0.071754  [ 1152/ 3000]\n",
      "loss: 0.050584  [ 1160/ 3000]\n",
      "loss: 0.067267  [ 1168/ 3000]\n",
      "loss: 0.059362  [ 1176/ 3000]\n",
      "loss: 0.228107  [ 1184/ 3000]\n",
      "loss: 0.093748  [ 1192/ 3000]\n",
      "loss: 0.092548  [ 1200/ 3000]\n",
      "loss: 0.074184  [ 1208/ 3000]\n",
      "loss: 0.089568  [ 1216/ 3000]\n",
      "loss: 0.131642  [ 1224/ 3000]\n",
      "loss: 0.141886  [ 1232/ 3000]\n",
      "loss: 0.120698  [ 1240/ 3000]\n",
      "loss: 0.146604  [ 1248/ 3000]\n",
      "loss: 0.028299  [ 1256/ 3000]\n",
      "loss: 0.068886  [ 1264/ 3000]\n",
      "loss: 0.051767  [ 1272/ 3000]\n",
      "loss: 0.085184  [ 1280/ 3000]\n",
      "loss: 0.130477  [ 1288/ 3000]\n",
      "loss: 0.057730  [ 1296/ 3000]\n",
      "loss: 0.019785  [ 1304/ 3000]\n",
      "loss: 0.151077  [ 1312/ 3000]\n",
      "loss: 0.350088  [ 1320/ 3000]\n",
      "loss: 0.154445  [ 1328/ 3000]\n",
      "loss: 0.110271  [ 1336/ 3000]\n",
      "loss: 0.195379  [ 1344/ 3000]\n",
      "loss: 0.111933  [ 1352/ 3000]\n",
      "loss: 0.080622  [ 1360/ 3000]\n",
      "loss: 0.172341  [ 1368/ 3000]\n",
      "loss: 0.186762  [ 1376/ 3000]\n",
      "loss: 0.130772  [ 1384/ 3000]\n",
      "loss: 0.077004  [ 1392/ 3000]\n",
      "loss: 0.134799  [ 1400/ 3000]\n",
      "loss: 0.115707  [ 1408/ 3000]\n",
      "loss: 0.139769  [ 1416/ 3000]\n",
      "loss: 0.162846  [ 1424/ 3000]\n",
      "loss: 0.106485  [ 1432/ 3000]\n",
      "loss: 0.062555  [ 1440/ 3000]\n",
      "loss: 0.074796  [ 1448/ 3000]\n",
      "loss: 0.109978  [ 1456/ 3000]\n",
      "loss: 0.020286  [ 1464/ 3000]\n",
      "loss: 0.066825  [ 1472/ 3000]\n",
      "loss: 0.042767  [ 1480/ 3000]\n",
      "loss: 0.162192  [ 1488/ 3000]\n",
      "loss: 0.059399  [ 1496/ 3000]\n",
      "loss: 0.091793  [ 1504/ 3000]\n",
      "loss: 0.105764  [ 1512/ 3000]\n",
      "loss: 0.125458  [ 1520/ 3000]\n",
      "loss: 0.067665  [ 1528/ 3000]\n",
      "loss: 0.116148  [ 1536/ 3000]\n",
      "loss: 0.066728  [ 1544/ 3000]\n",
      "loss: 0.158954  [ 1552/ 3000]\n",
      "loss: 0.071132  [ 1560/ 3000]\n",
      "loss: 0.069949  [ 1568/ 3000]\n",
      "loss: 0.061479  [ 1576/ 3000]\n",
      "loss: 0.145260  [ 1584/ 3000]\n",
      "loss: 0.071994  [ 1592/ 3000]\n",
      "loss: 0.140581  [ 1600/ 3000]\n",
      "loss: 0.071444  [ 1608/ 3000]\n",
      "loss: 0.177686  [ 1616/ 3000]\n",
      "loss: 0.147758  [ 1624/ 3000]\n",
      "loss: 0.069334  [ 1632/ 3000]\n",
      "loss: 0.071509  [ 1640/ 3000]\n",
      "loss: 0.148266  [ 1648/ 3000]\n",
      "loss: 0.056278  [ 1656/ 3000]\n",
      "loss: 0.204958  [ 1664/ 3000]\n",
      "loss: 0.051147  [ 1672/ 3000]\n",
      "loss: 0.074533  [ 1680/ 3000]\n",
      "loss: 0.091551  [ 1688/ 3000]\n",
      "loss: 0.141294  [ 1696/ 3000]\n",
      "loss: 0.091204  [ 1704/ 3000]\n",
      "loss: 0.047839  [ 1712/ 3000]\n",
      "loss: 0.081029  [ 1720/ 3000]\n",
      "loss: 0.093395  [ 1728/ 3000]\n",
      "loss: 0.114702  [ 1736/ 3000]\n",
      "loss: 0.113757  [ 1744/ 3000]\n",
      "loss: 0.036770  [ 1752/ 3000]\n",
      "loss: 0.030236  [ 1760/ 3000]\n",
      "loss: 0.171844  [ 1768/ 3000]\n",
      "loss: 0.104036  [ 1776/ 3000]\n",
      "loss: 0.056839  [ 1784/ 3000]\n",
      "loss: 0.070927  [ 1792/ 3000]\n",
      "loss: 0.142401  [ 1800/ 3000]\n",
      "loss: 0.184089  [ 1808/ 3000]\n",
      "loss: 0.050722  [ 1816/ 3000]\n",
      "loss: 0.163361  [ 1824/ 3000]\n",
      "loss: 0.026367  [ 1832/ 3000]\n",
      "loss: 0.017425  [ 1840/ 3000]\n",
      "loss: 0.098448  [ 1848/ 3000]\n",
      "loss: 0.109945  [ 1856/ 3000]\n",
      "loss: 0.111832  [ 1864/ 3000]\n",
      "loss: 0.104255  [ 1872/ 3000]\n",
      "loss: 0.030131  [ 1880/ 3000]\n",
      "loss: 0.045625  [ 1888/ 3000]\n",
      "loss: 0.115939  [ 1896/ 3000]\n",
      "loss: 0.043881  [ 1904/ 3000]\n",
      "loss: 0.074062  [ 1912/ 3000]\n",
      "loss: 0.139482  [ 1920/ 3000]\n",
      "loss: 0.116917  [ 1928/ 3000]\n",
      "loss: 0.179839  [ 1936/ 3000]\n",
      "loss: 0.042935  [ 1944/ 3000]\n",
      "loss: 0.121984  [ 1952/ 3000]\n",
      "loss: 0.045100  [ 1960/ 3000]\n",
      "loss: 0.149063  [ 1968/ 3000]\n",
      "loss: 0.057094  [ 1976/ 3000]\n",
      "loss: 0.158760  [ 1984/ 3000]\n",
      "loss: 0.159998  [ 1992/ 3000]\n",
      "loss: 0.108570  [ 2000/ 3000]\n",
      "loss: 0.137142  [ 2008/ 3000]\n",
      "loss: 0.097822  [ 2016/ 3000]\n",
      "loss: 0.080551  [ 2024/ 3000]\n",
      "loss: 0.138038  [ 2032/ 3000]\n",
      "loss: 0.118866  [ 2040/ 3000]\n",
      "loss: 0.062479  [ 2048/ 3000]\n",
      "loss: 0.067633  [ 2056/ 3000]\n",
      "loss: 0.053813  [ 2064/ 3000]\n",
      "loss: 0.174262  [ 2072/ 3000]\n",
      "loss: 0.076440  [ 2080/ 3000]\n",
      "loss: 0.160888  [ 2088/ 3000]\n",
      "loss: 0.108584  [ 2096/ 3000]\n",
      "loss: 0.063940  [ 2104/ 3000]\n",
      "loss: 0.049420  [ 2112/ 3000]\n",
      "loss: 0.037337  [ 2120/ 3000]\n",
      "loss: 0.091676  [ 2128/ 3000]\n",
      "loss: 0.095209  [ 2136/ 3000]\n",
      "loss: 0.148765  [ 2144/ 3000]\n",
      "loss: 0.166505  [ 2152/ 3000]\n",
      "loss: 0.044089  [ 2160/ 3000]\n",
      "loss: 0.095331  [ 2168/ 3000]\n",
      "loss: 0.054804  [ 2176/ 3000]\n",
      "loss: 0.119027  [ 2184/ 3000]\n",
      "loss: 0.115270  [ 2192/ 3000]\n",
      "loss: 0.050041  [ 2200/ 3000]\n",
      "loss: 0.036864  [ 2208/ 3000]\n",
      "loss: 0.069221  [ 2216/ 3000]\n",
      "loss: 0.132398  [ 2224/ 3000]\n",
      "loss: 0.096049  [ 2232/ 3000]\n",
      "loss: 0.163513  [ 2240/ 3000]\n",
      "loss: 0.029662  [ 2248/ 3000]\n",
      "loss: 0.104573  [ 2256/ 3000]\n",
      "loss: 0.040887  [ 2264/ 3000]\n",
      "loss: 0.153254  [ 2272/ 3000]\n",
      "loss: 0.067614  [ 2280/ 3000]\n",
      "loss: 0.167938  [ 2288/ 3000]\n",
      "loss: 0.091597  [ 2296/ 3000]\n",
      "loss: 0.063241  [ 2304/ 3000]\n",
      "loss: 0.044273  [ 2312/ 3000]\n",
      "loss: 0.043516  [ 2320/ 3000]\n",
      "loss: 0.111847  [ 2328/ 3000]\n",
      "loss: 0.033814  [ 2336/ 3000]\n",
      "loss: 0.145767  [ 2344/ 3000]\n",
      "loss: 0.170752  [ 2352/ 3000]\n",
      "loss: 0.119953  [ 2360/ 3000]\n",
      "loss: 0.078165  [ 2368/ 3000]\n",
      "loss: 0.045566  [ 2376/ 3000]\n",
      "loss: 0.074017  [ 2384/ 3000]\n",
      "loss: 0.074535  [ 2392/ 3000]\n",
      "loss: 0.033563  [ 2400/ 3000]\n",
      "loss: 0.161663  [ 2408/ 3000]\n",
      "loss: 0.100974  [ 2416/ 3000]\n",
      "loss: 0.112718  [ 2424/ 3000]\n",
      "loss: 0.136854  [ 2432/ 3000]\n",
      "loss: 0.075148  [ 2440/ 3000]\n",
      "loss: 0.149570  [ 2448/ 3000]\n",
      "loss: 0.156048  [ 2456/ 3000]\n",
      "loss: 0.076957  [ 2464/ 3000]\n",
      "loss: 0.266718  [ 2472/ 3000]\n",
      "loss: 0.044280  [ 2480/ 3000]\n",
      "loss: 0.088915  [ 2488/ 3000]\n",
      "loss: 0.040399  [ 2496/ 3000]\n",
      "loss: 0.064130  [ 2504/ 3000]\n",
      "loss: 0.172107  [ 2512/ 3000]\n",
      "loss: 0.256345  [ 2520/ 3000]\n",
      "loss: 0.064710  [ 2528/ 3000]\n",
      "loss: 0.093262  [ 2536/ 3000]\n",
      "loss: 0.049265  [ 2544/ 3000]\n",
      "loss: 0.131831  [ 2552/ 3000]\n",
      "loss: 0.109764  [ 2560/ 3000]\n",
      "loss: 0.174342  [ 2568/ 3000]\n",
      "loss: 0.148833  [ 2576/ 3000]\n",
      "loss: 0.104101  [ 2584/ 3000]\n",
      "loss: 0.082220  [ 2592/ 3000]\n",
      "loss: 0.087737  [ 2600/ 3000]\n",
      "loss: 0.120654  [ 2608/ 3000]\n",
      "loss: 0.055596  [ 2616/ 3000]\n",
      "loss: 0.065122  [ 2624/ 3000]\n",
      "loss: 0.136125  [ 2632/ 3000]\n",
      "loss: 0.164537  [ 2640/ 3000]\n",
      "loss: 0.112249  [ 2648/ 3000]\n",
      "loss: 0.123998  [ 2656/ 3000]\n",
      "loss: 0.090393  [ 2664/ 3000]\n",
      "loss: 0.149685  [ 2672/ 3000]\n",
      "loss: 0.167967  [ 2680/ 3000]\n",
      "loss: 0.082107  [ 2688/ 3000]\n",
      "loss: 0.068959  [ 2696/ 3000]\n",
      "loss: 0.106074  [ 2704/ 3000]\n",
      "loss: 0.138290  [ 2712/ 3000]\n",
      "loss: 0.093953  [ 2720/ 3000]\n",
      "loss: 0.159310  [ 2728/ 3000]\n",
      "loss: 0.048442  [ 2736/ 3000]\n",
      "loss: 0.108342  [ 2744/ 3000]\n",
      "loss: 0.128691  [ 2752/ 3000]\n",
      "loss: 0.086180  [ 2760/ 3000]\n",
      "loss: 0.043153  [ 2768/ 3000]\n",
      "loss: 0.164518  [ 2776/ 3000]\n",
      "loss: 0.099274  [ 2784/ 3000]\n",
      "loss: 0.077514  [ 2792/ 3000]\n",
      "loss: 0.149640  [ 2800/ 3000]\n",
      "loss: 0.192566  [ 2808/ 3000]\n",
      "loss: 0.107907  [ 2816/ 3000]\n",
      "loss: 0.107687  [ 2824/ 3000]\n",
      "loss: 0.120261  [ 2832/ 3000]\n",
      "loss: 0.088984  [ 2840/ 3000]\n",
      "loss: 0.087766  [ 2848/ 3000]\n",
      "loss: 0.117991  [ 2856/ 3000]\n",
      "loss: 0.065431  [ 2864/ 3000]\n",
      "loss: 0.126311  [ 2872/ 3000]\n",
      "loss: 0.155726  [ 2880/ 3000]\n",
      "loss: 0.046263  [ 2888/ 3000]\n",
      "loss: 0.031055  [ 2896/ 3000]\n",
      "loss: 0.117914  [ 2904/ 3000]\n",
      "loss: 0.129602  [ 2912/ 3000]\n",
      "loss: 0.097459  [ 2920/ 3000]\n",
      "loss: 0.157371  [ 2928/ 3000]\n",
      "loss: 0.237461  [ 2936/ 3000]\n",
      "loss: 0.056788  [ 2944/ 3000]\n",
      "loss: 0.016028  [ 2952/ 3000]\n",
      "loss: 0.048507  [ 2960/ 3000]\n",
      "loss: 0.079561  [ 2968/ 3000]\n",
      "loss: 0.070949  [ 2976/ 3000]\n",
      "loss: 0.087944  [ 2984/ 3000]\n",
      "loss: 0.032322  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.102399 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.057939  [    0/ 3000]\n",
      "loss: 0.112305  [    8/ 3000]\n",
      "loss: 0.060459  [   16/ 3000]\n",
      "loss: 0.060036  [   24/ 3000]\n",
      "loss: 0.164476  [   32/ 3000]\n",
      "loss: 0.043276  [   40/ 3000]\n",
      "loss: 0.041737  [   48/ 3000]\n",
      "loss: 0.106197  [   56/ 3000]\n",
      "loss: 0.202658  [   64/ 3000]\n",
      "loss: 0.036980  [   72/ 3000]\n",
      "loss: 0.187300  [   80/ 3000]\n",
      "loss: 0.130406  [   88/ 3000]\n",
      "loss: 0.156259  [   96/ 3000]\n",
      "loss: 0.088593  [  104/ 3000]\n",
      "loss: 0.204471  [  112/ 3000]\n",
      "loss: 0.063199  [  120/ 3000]\n",
      "loss: 0.054692  [  128/ 3000]\n",
      "loss: 0.138555  [  136/ 3000]\n",
      "loss: 0.119099  [  144/ 3000]\n",
      "loss: 0.066250  [  152/ 3000]\n",
      "loss: 0.043027  [  160/ 3000]\n",
      "loss: 0.032275  [  168/ 3000]\n",
      "loss: 0.060733  [  176/ 3000]\n",
      "loss: 0.125559  [  184/ 3000]\n",
      "loss: 0.090242  [  192/ 3000]\n",
      "loss: 0.066256  [  200/ 3000]\n",
      "loss: 0.200180  [  208/ 3000]\n",
      "loss: 0.067524  [  216/ 3000]\n",
      "loss: 0.087257  [  224/ 3000]\n",
      "loss: 0.183014  [  232/ 3000]\n",
      "loss: 0.094671  [  240/ 3000]\n",
      "loss: 0.071280  [  248/ 3000]\n",
      "loss: 0.053095  [  256/ 3000]\n",
      "loss: 0.132930  [  264/ 3000]\n",
      "loss: 0.071839  [  272/ 3000]\n",
      "loss: 0.196298  [  280/ 3000]\n",
      "loss: 0.050103  [  288/ 3000]\n",
      "loss: 0.079748  [  296/ 3000]\n",
      "loss: 0.066190  [  304/ 3000]\n",
      "loss: 0.142625  [  312/ 3000]\n",
      "loss: 0.084266  [  320/ 3000]\n",
      "loss: 0.208172  [  328/ 3000]\n",
      "loss: 0.085096  [  336/ 3000]\n",
      "loss: 0.103980  [  344/ 3000]\n",
      "loss: 0.044027  [  352/ 3000]\n",
      "loss: 0.046452  [  360/ 3000]\n",
      "loss: 0.162696  [  368/ 3000]\n",
      "loss: 0.044908  [  376/ 3000]\n",
      "loss: 0.137026  [  384/ 3000]\n",
      "loss: 0.080250  [  392/ 3000]\n",
      "loss: 0.147612  [  400/ 3000]\n",
      "loss: 0.061741  [  408/ 3000]\n",
      "loss: 0.144904  [  416/ 3000]\n",
      "loss: 0.083359  [  424/ 3000]\n",
      "loss: 0.216284  [  432/ 3000]\n",
      "loss: 0.063099  [  440/ 3000]\n",
      "loss: 0.121653  [  448/ 3000]\n",
      "loss: 0.078262  [  456/ 3000]\n",
      "loss: 0.169036  [  464/ 3000]\n",
      "loss: 0.083346  [  472/ 3000]\n",
      "loss: 0.034111  [  480/ 3000]\n",
      "loss: 0.168021  [  488/ 3000]\n",
      "loss: 0.114548  [  496/ 3000]\n",
      "loss: 0.064424  [  504/ 3000]\n",
      "loss: 0.100892  [  512/ 3000]\n",
      "loss: 0.059045  [  520/ 3000]\n",
      "loss: 0.262178  [  528/ 3000]\n",
      "loss: 0.140058  [  536/ 3000]\n",
      "loss: 0.128981  [  544/ 3000]\n",
      "loss: 0.089630  [  552/ 3000]\n",
      "loss: 0.072175  [  560/ 3000]\n",
      "loss: 0.129301  [  568/ 3000]\n",
      "loss: 0.100221  [  576/ 3000]\n",
      "loss: 0.116065  [  584/ 3000]\n",
      "loss: 0.061903  [  592/ 3000]\n",
      "loss: 0.207275  [  600/ 3000]\n",
      "loss: 0.052619  [  608/ 3000]\n",
      "loss: 0.137218  [  616/ 3000]\n",
      "loss: 0.098653  [  624/ 3000]\n",
      "loss: 0.226591  [  632/ 3000]\n",
      "loss: 0.045467  [  640/ 3000]\n",
      "loss: 0.186381  [  648/ 3000]\n",
      "loss: 0.259308  [  656/ 3000]\n",
      "loss: 0.208345  [  664/ 3000]\n",
      "loss: 0.098515  [  672/ 3000]\n",
      "loss: 0.108641  [  680/ 3000]\n",
      "loss: 0.083743  [  688/ 3000]\n",
      "loss: 0.235592  [  696/ 3000]\n",
      "loss: 0.089640  [  704/ 3000]\n",
      "loss: 0.077406  [  712/ 3000]\n",
      "loss: 0.079518  [  720/ 3000]\n",
      "loss: 0.055639  [  728/ 3000]\n",
      "loss: 0.086911  [  736/ 3000]\n",
      "loss: 0.071823  [  744/ 3000]\n",
      "loss: 0.143417  [  752/ 3000]\n",
      "loss: 0.112605  [  760/ 3000]\n",
      "loss: 0.142458  [  768/ 3000]\n",
      "loss: 0.093345  [  776/ 3000]\n",
      "loss: 0.223001  [  784/ 3000]\n",
      "loss: 0.125736  [  792/ 3000]\n",
      "loss: 0.205754  [  800/ 3000]\n",
      "loss: 0.098402  [  808/ 3000]\n",
      "loss: 0.063088  [  816/ 3000]\n",
      "loss: 0.076055  [  824/ 3000]\n",
      "loss: 0.095231  [  832/ 3000]\n",
      "loss: 0.051008  [  840/ 3000]\n",
      "loss: 0.041287  [  848/ 3000]\n",
      "loss: 0.046001  [  856/ 3000]\n",
      "loss: 0.129221  [  864/ 3000]\n",
      "loss: 0.034354  [  872/ 3000]\n",
      "loss: 0.096458  [  880/ 3000]\n",
      "loss: 0.149935  [  888/ 3000]\n",
      "loss: 0.083839  [  896/ 3000]\n",
      "loss: 0.248935  [  904/ 3000]\n",
      "loss: 0.082816  [  912/ 3000]\n",
      "loss: 0.085678  [  920/ 3000]\n",
      "loss: 0.104645  [  928/ 3000]\n",
      "loss: 0.079120  [  936/ 3000]\n",
      "loss: 0.229594  [  944/ 3000]\n",
      "loss: 0.061288  [  952/ 3000]\n",
      "loss: 0.081661  [  960/ 3000]\n",
      "loss: 0.051385  [  968/ 3000]\n",
      "loss: 0.028525  [  976/ 3000]\n",
      "loss: 0.039143  [  984/ 3000]\n",
      "loss: 0.179556  [  992/ 3000]\n",
      "loss: 0.120817  [ 1000/ 3000]\n",
      "loss: 0.089579  [ 1008/ 3000]\n",
      "loss: 0.163855  [ 1016/ 3000]\n",
      "loss: 0.093860  [ 1024/ 3000]\n",
      "loss: 0.144496  [ 1032/ 3000]\n",
      "loss: 0.033949  [ 1040/ 3000]\n",
      "loss: 0.069527  [ 1048/ 3000]\n",
      "loss: 0.039508  [ 1056/ 3000]\n",
      "loss: 0.103242  [ 1064/ 3000]\n",
      "loss: 0.071565  [ 1072/ 3000]\n",
      "loss: 0.077329  [ 1080/ 3000]\n",
      "loss: 0.159793  [ 1088/ 3000]\n",
      "loss: 0.128113  [ 1096/ 3000]\n",
      "loss: 0.046152  [ 1104/ 3000]\n",
      "loss: 0.147112  [ 1112/ 3000]\n",
      "loss: 0.053440  [ 1120/ 3000]\n",
      "loss: 0.070293  [ 1128/ 3000]\n",
      "loss: 0.089438  [ 1136/ 3000]\n",
      "loss: 0.178876  [ 1144/ 3000]\n",
      "loss: 0.067327  [ 1152/ 3000]\n",
      "loss: 0.047656  [ 1160/ 3000]\n",
      "loss: 0.062315  [ 1168/ 3000]\n",
      "loss: 0.054441  [ 1176/ 3000]\n",
      "loss: 0.224333  [ 1184/ 3000]\n",
      "loss: 0.089537  [ 1192/ 3000]\n",
      "loss: 0.087887  [ 1200/ 3000]\n",
      "loss: 0.066988  [ 1208/ 3000]\n",
      "loss: 0.085316  [ 1216/ 3000]\n",
      "loss: 0.126856  [ 1224/ 3000]\n",
      "loss: 0.138339  [ 1232/ 3000]\n",
      "loss: 0.116788  [ 1240/ 3000]\n",
      "loss: 0.139928  [ 1248/ 3000]\n",
      "loss: 0.026140  [ 1256/ 3000]\n",
      "loss: 0.065718  [ 1264/ 3000]\n",
      "loss: 0.047433  [ 1272/ 3000]\n",
      "loss: 0.077248  [ 1280/ 3000]\n",
      "loss: 0.123543  [ 1288/ 3000]\n",
      "loss: 0.052994  [ 1296/ 3000]\n",
      "loss: 0.016015  [ 1304/ 3000]\n",
      "loss: 0.147104  [ 1312/ 3000]\n",
      "loss: 0.344606  [ 1320/ 3000]\n",
      "loss: 0.151596  [ 1328/ 3000]\n",
      "loss: 0.105517  [ 1336/ 3000]\n",
      "loss: 0.189550  [ 1344/ 3000]\n",
      "loss: 0.108859  [ 1352/ 3000]\n",
      "loss: 0.073825  [ 1360/ 3000]\n",
      "loss: 0.166135  [ 1368/ 3000]\n",
      "loss: 0.179313  [ 1376/ 3000]\n",
      "loss: 0.120985  [ 1384/ 3000]\n",
      "loss: 0.071348  [ 1392/ 3000]\n",
      "loss: 0.129733  [ 1400/ 3000]\n",
      "loss: 0.112811  [ 1408/ 3000]\n",
      "loss: 0.132163  [ 1416/ 3000]\n",
      "loss: 0.157143  [ 1424/ 3000]\n",
      "loss: 0.101321  [ 1432/ 3000]\n",
      "loss: 0.059582  [ 1440/ 3000]\n",
      "loss: 0.067444  [ 1448/ 3000]\n",
      "loss: 0.103700  [ 1456/ 3000]\n",
      "loss: 0.018286  [ 1464/ 3000]\n",
      "loss: 0.063842  [ 1472/ 3000]\n",
      "loss: 0.039090  [ 1480/ 3000]\n",
      "loss: 0.158196  [ 1488/ 3000]\n",
      "loss: 0.054841  [ 1496/ 3000]\n",
      "loss: 0.086961  [ 1504/ 3000]\n",
      "loss: 0.104302  [ 1512/ 3000]\n",
      "loss: 0.119768  [ 1520/ 3000]\n",
      "loss: 0.063206  [ 1528/ 3000]\n",
      "loss: 0.112791  [ 1536/ 3000]\n",
      "loss: 0.062990  [ 1544/ 3000]\n",
      "loss: 0.154174  [ 1552/ 3000]\n",
      "loss: 0.068243  [ 1560/ 3000]\n",
      "loss: 0.066607  [ 1568/ 3000]\n",
      "loss: 0.055229  [ 1576/ 3000]\n",
      "loss: 0.140016  [ 1584/ 3000]\n",
      "loss: 0.070886  [ 1592/ 3000]\n",
      "loss: 0.134241  [ 1600/ 3000]\n",
      "loss: 0.065919  [ 1608/ 3000]\n",
      "loss: 0.172717  [ 1616/ 3000]\n",
      "loss: 0.142366  [ 1624/ 3000]\n",
      "loss: 0.065585  [ 1632/ 3000]\n",
      "loss: 0.068942  [ 1640/ 3000]\n",
      "loss: 0.147011  [ 1648/ 3000]\n",
      "loss: 0.053448  [ 1656/ 3000]\n",
      "loss: 0.194779  [ 1664/ 3000]\n",
      "loss: 0.046735  [ 1672/ 3000]\n",
      "loss: 0.071176  [ 1680/ 3000]\n",
      "loss: 0.088805  [ 1688/ 3000]\n",
      "loss: 0.133865  [ 1696/ 3000]\n",
      "loss: 0.085058  [ 1704/ 3000]\n",
      "loss: 0.043484  [ 1712/ 3000]\n",
      "loss: 0.075373  [ 1720/ 3000]\n",
      "loss: 0.087020  [ 1728/ 3000]\n",
      "loss: 0.111835  [ 1736/ 3000]\n",
      "loss: 0.107620  [ 1744/ 3000]\n",
      "loss: 0.033541  [ 1752/ 3000]\n",
      "loss: 0.026239  [ 1760/ 3000]\n",
      "loss: 0.164982  [ 1768/ 3000]\n",
      "loss: 0.099176  [ 1776/ 3000]\n",
      "loss: 0.051662  [ 1784/ 3000]\n",
      "loss: 0.067583  [ 1792/ 3000]\n",
      "loss: 0.137457  [ 1800/ 3000]\n",
      "loss: 0.178239  [ 1808/ 3000]\n",
      "loss: 0.050438  [ 1816/ 3000]\n",
      "loss: 0.160565  [ 1824/ 3000]\n",
      "loss: 0.022686  [ 1832/ 3000]\n",
      "loss: 0.016090  [ 1840/ 3000]\n",
      "loss: 0.091933  [ 1848/ 3000]\n",
      "loss: 0.106809  [ 1856/ 3000]\n",
      "loss: 0.107783  [ 1864/ 3000]\n",
      "loss: 0.098463  [ 1872/ 3000]\n",
      "loss: 0.027872  [ 1880/ 3000]\n",
      "loss: 0.041528  [ 1888/ 3000]\n",
      "loss: 0.110458  [ 1896/ 3000]\n",
      "loss: 0.041570  [ 1904/ 3000]\n",
      "loss: 0.068843  [ 1912/ 3000]\n",
      "loss: 0.134344  [ 1920/ 3000]\n",
      "loss: 0.113695  [ 1928/ 3000]\n",
      "loss: 0.176846  [ 1936/ 3000]\n",
      "loss: 0.037933  [ 1944/ 3000]\n",
      "loss: 0.119235  [ 1952/ 3000]\n",
      "loss: 0.043054  [ 1960/ 3000]\n",
      "loss: 0.144856  [ 1968/ 3000]\n",
      "loss: 0.053197  [ 1976/ 3000]\n",
      "loss: 0.152923  [ 1984/ 3000]\n",
      "loss: 0.156351  [ 1992/ 3000]\n",
      "loss: 0.103582  [ 2000/ 3000]\n",
      "loss: 0.132661  [ 2008/ 3000]\n",
      "loss: 0.094145  [ 2016/ 3000]\n",
      "loss: 0.077352  [ 2024/ 3000]\n",
      "loss: 0.132807  [ 2032/ 3000]\n",
      "loss: 0.112567  [ 2040/ 3000]\n",
      "loss: 0.057415  [ 2048/ 3000]\n",
      "loss: 0.063606  [ 2056/ 3000]\n",
      "loss: 0.050405  [ 2064/ 3000]\n",
      "loss: 0.165588  [ 2072/ 3000]\n",
      "loss: 0.072392  [ 2080/ 3000]\n",
      "loss: 0.153773  [ 2088/ 3000]\n",
      "loss: 0.103534  [ 2096/ 3000]\n",
      "loss: 0.062615  [ 2104/ 3000]\n",
      "loss: 0.044902  [ 2112/ 3000]\n",
      "loss: 0.032858  [ 2120/ 3000]\n",
      "loss: 0.088236  [ 2128/ 3000]\n",
      "loss: 0.091145  [ 2136/ 3000]\n",
      "loss: 0.141433  [ 2144/ 3000]\n",
      "loss: 0.162014  [ 2152/ 3000]\n",
      "loss: 0.041640  [ 2160/ 3000]\n",
      "loss: 0.092854  [ 2168/ 3000]\n",
      "loss: 0.049776  [ 2176/ 3000]\n",
      "loss: 0.116662  [ 2184/ 3000]\n",
      "loss: 0.112013  [ 2192/ 3000]\n",
      "loss: 0.047078  [ 2200/ 3000]\n",
      "loss: 0.034100  [ 2208/ 3000]\n",
      "loss: 0.063378  [ 2216/ 3000]\n",
      "loss: 0.128858  [ 2224/ 3000]\n",
      "loss: 0.095117  [ 2232/ 3000]\n",
      "loss: 0.157296  [ 2240/ 3000]\n",
      "loss: 0.026100  [ 2248/ 3000]\n",
      "loss: 0.098277  [ 2256/ 3000]\n",
      "loss: 0.038517  [ 2264/ 3000]\n",
      "loss: 0.152190  [ 2272/ 3000]\n",
      "loss: 0.063390  [ 2280/ 3000]\n",
      "loss: 0.163758  [ 2288/ 3000]\n",
      "loss: 0.088291  [ 2296/ 3000]\n",
      "loss: 0.062040  [ 2304/ 3000]\n",
      "loss: 0.042249  [ 2312/ 3000]\n",
      "loss: 0.040264  [ 2320/ 3000]\n",
      "loss: 0.107503  [ 2328/ 3000]\n",
      "loss: 0.029835  [ 2336/ 3000]\n",
      "loss: 0.141579  [ 2344/ 3000]\n",
      "loss: 0.166232  [ 2352/ 3000]\n",
      "loss: 0.117832  [ 2360/ 3000]\n",
      "loss: 0.072974  [ 2368/ 3000]\n",
      "loss: 0.042563  [ 2376/ 3000]\n",
      "loss: 0.071568  [ 2384/ 3000]\n",
      "loss: 0.071971  [ 2392/ 3000]\n",
      "loss: 0.029172  [ 2400/ 3000]\n",
      "loss: 0.156046  [ 2408/ 3000]\n",
      "loss: 0.097915  [ 2416/ 3000]\n",
      "loss: 0.110443  [ 2424/ 3000]\n",
      "loss: 0.131429  [ 2432/ 3000]\n",
      "loss: 0.071578  [ 2440/ 3000]\n",
      "loss: 0.147512  [ 2448/ 3000]\n",
      "loss: 0.151748  [ 2456/ 3000]\n",
      "loss: 0.073689  [ 2464/ 3000]\n",
      "loss: 0.264758  [ 2472/ 3000]\n",
      "loss: 0.041624  [ 2480/ 3000]\n",
      "loss: 0.084106  [ 2488/ 3000]\n",
      "loss: 0.036511  [ 2496/ 3000]\n",
      "loss: 0.060584  [ 2504/ 3000]\n",
      "loss: 0.165490  [ 2512/ 3000]\n",
      "loss: 0.252828  [ 2520/ 3000]\n",
      "loss: 0.059416  [ 2528/ 3000]\n",
      "loss: 0.087969  [ 2536/ 3000]\n",
      "loss: 0.043211  [ 2544/ 3000]\n",
      "loss: 0.127245  [ 2552/ 3000]\n",
      "loss: 0.107307  [ 2560/ 3000]\n",
      "loss: 0.168190  [ 2568/ 3000]\n",
      "loss: 0.146389  [ 2576/ 3000]\n",
      "loss: 0.097741  [ 2584/ 3000]\n",
      "loss: 0.078262  [ 2592/ 3000]\n",
      "loss: 0.086056  [ 2600/ 3000]\n",
      "loss: 0.115711  [ 2608/ 3000]\n",
      "loss: 0.052576  [ 2616/ 3000]\n",
      "loss: 0.059697  [ 2624/ 3000]\n",
      "loss: 0.132796  [ 2632/ 3000]\n",
      "loss: 0.159725  [ 2640/ 3000]\n",
      "loss: 0.107763  [ 2648/ 3000]\n",
      "loss: 0.119245  [ 2656/ 3000]\n",
      "loss: 0.085170  [ 2664/ 3000]\n",
      "loss: 0.144202  [ 2672/ 3000]\n",
      "loss: 0.163643  [ 2680/ 3000]\n",
      "loss: 0.076733  [ 2688/ 3000]\n",
      "loss: 0.064178  [ 2696/ 3000]\n",
      "loss: 0.103238  [ 2704/ 3000]\n",
      "loss: 0.130300  [ 2712/ 3000]\n",
      "loss: 0.089582  [ 2720/ 3000]\n",
      "loss: 0.154375  [ 2728/ 3000]\n",
      "loss: 0.045591  [ 2736/ 3000]\n",
      "loss: 0.102639  [ 2744/ 3000]\n",
      "loss: 0.125043  [ 2752/ 3000]\n",
      "loss: 0.083760  [ 2760/ 3000]\n",
      "loss: 0.039540  [ 2768/ 3000]\n",
      "loss: 0.159661  [ 2776/ 3000]\n",
      "loss: 0.096386  [ 2784/ 3000]\n",
      "loss: 0.072510  [ 2792/ 3000]\n",
      "loss: 0.141989  [ 2800/ 3000]\n",
      "loss: 0.189305  [ 2808/ 3000]\n",
      "loss: 0.102767  [ 2816/ 3000]\n",
      "loss: 0.103831  [ 2824/ 3000]\n",
      "loss: 0.114816  [ 2832/ 3000]\n",
      "loss: 0.084150  [ 2840/ 3000]\n",
      "loss: 0.084930  [ 2848/ 3000]\n",
      "loss: 0.114066  [ 2856/ 3000]\n",
      "loss: 0.061070  [ 2864/ 3000]\n",
      "loss: 0.119984  [ 2872/ 3000]\n",
      "loss: 0.150504  [ 2880/ 3000]\n",
      "loss: 0.041435  [ 2888/ 3000]\n",
      "loss: 0.028748  [ 2896/ 3000]\n",
      "loss: 0.112163  [ 2904/ 3000]\n",
      "loss: 0.125571  [ 2912/ 3000]\n",
      "loss: 0.092365  [ 2920/ 3000]\n",
      "loss: 0.152325  [ 2928/ 3000]\n",
      "loss: 0.231208  [ 2936/ 3000]\n",
      "loss: 0.052885  [ 2944/ 3000]\n",
      "loss: 0.013719  [ 2952/ 3000]\n",
      "loss: 0.045770  [ 2960/ 3000]\n",
      "loss: 0.077808  [ 2968/ 3000]\n",
      "loss: 0.069082  [ 2976/ 3000]\n",
      "loss: 0.084294  [ 2984/ 3000]\n",
      "loss: 0.028815  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.099468 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.053407  [    0/ 3000]\n",
      "loss: 0.107328  [    8/ 3000]\n",
      "loss: 0.055373  [   16/ 3000]\n",
      "loss: 0.057093  [   24/ 3000]\n",
      "loss: 0.158842  [   32/ 3000]\n",
      "loss: 0.039547  [   40/ 3000]\n",
      "loss: 0.039148  [   48/ 3000]\n",
      "loss: 0.102545  [   56/ 3000]\n",
      "loss: 0.199044  [   64/ 3000]\n",
      "loss: 0.034353  [   72/ 3000]\n",
      "loss: 0.182343  [   80/ 3000]\n",
      "loss: 0.123693  [   88/ 3000]\n",
      "loss: 0.150124  [   96/ 3000]\n",
      "loss: 0.085872  [  104/ 3000]\n",
      "loss: 0.201474  [  112/ 3000]\n",
      "loss: 0.060694  [  120/ 3000]\n",
      "loss: 0.051792  [  128/ 3000]\n",
      "loss: 0.131586  [  136/ 3000]\n",
      "loss: 0.113503  [  144/ 3000]\n",
      "loss: 0.064159  [  152/ 3000]\n",
      "loss: 0.039640  [  160/ 3000]\n",
      "loss: 0.029175  [  168/ 3000]\n",
      "loss: 0.057630  [  176/ 3000]\n",
      "loss: 0.120922  [  184/ 3000]\n",
      "loss: 0.087423  [  192/ 3000]\n",
      "loss: 0.062530  [  200/ 3000]\n",
      "loss: 0.196852  [  208/ 3000]\n",
      "loss: 0.063471  [  216/ 3000]\n",
      "loss: 0.083010  [  224/ 3000]\n",
      "loss: 0.177351  [  232/ 3000]\n",
      "loss: 0.088836  [  240/ 3000]\n",
      "loss: 0.067652  [  248/ 3000]\n",
      "loss: 0.049851  [  256/ 3000]\n",
      "loss: 0.128449  [  264/ 3000]\n",
      "loss: 0.068506  [  272/ 3000]\n",
      "loss: 0.194993  [  280/ 3000]\n",
      "loss: 0.047247  [  288/ 3000]\n",
      "loss: 0.076906  [  296/ 3000]\n",
      "loss: 0.062080  [  304/ 3000]\n",
      "loss: 0.140139  [  312/ 3000]\n",
      "loss: 0.079220  [  320/ 3000]\n",
      "loss: 0.200051  [  328/ 3000]\n",
      "loss: 0.080138  [  336/ 3000]\n",
      "loss: 0.102466  [  344/ 3000]\n",
      "loss: 0.040810  [  352/ 3000]\n",
      "loss: 0.045043  [  360/ 3000]\n",
      "loss: 0.158157  [  368/ 3000]\n",
      "loss: 0.043299  [  376/ 3000]\n",
      "loss: 0.130373  [  384/ 3000]\n",
      "loss: 0.078513  [  392/ 3000]\n",
      "loss: 0.139346  [  400/ 3000]\n",
      "loss: 0.057133  [  408/ 3000]\n",
      "loss: 0.140546  [  416/ 3000]\n",
      "loss: 0.079321  [  424/ 3000]\n",
      "loss: 0.213544  [  432/ 3000]\n",
      "loss: 0.060053  [  440/ 3000]\n",
      "loss: 0.115385  [  448/ 3000]\n",
      "loss: 0.074589  [  456/ 3000]\n",
      "loss: 0.163754  [  464/ 3000]\n",
      "loss: 0.081355  [  472/ 3000]\n",
      "loss: 0.031659  [  480/ 3000]\n",
      "loss: 0.165871  [  488/ 3000]\n",
      "loss: 0.112038  [  496/ 3000]\n",
      "loss: 0.063645  [  504/ 3000]\n",
      "loss: 0.096097  [  512/ 3000]\n",
      "loss: 0.057926  [  520/ 3000]\n",
      "loss: 0.256694  [  528/ 3000]\n",
      "loss: 0.135113  [  536/ 3000]\n",
      "loss: 0.124478  [  544/ 3000]\n",
      "loss: 0.086280  [  552/ 3000]\n",
      "loss: 0.068181  [  560/ 3000]\n",
      "loss: 0.124977  [  568/ 3000]\n",
      "loss: 0.094729  [  576/ 3000]\n",
      "loss: 0.109079  [  584/ 3000]\n",
      "loss: 0.057709  [  592/ 3000]\n",
      "loss: 0.200839  [  600/ 3000]\n",
      "loss: 0.051455  [  608/ 3000]\n",
      "loss: 0.132058  [  616/ 3000]\n",
      "loss: 0.093439  [  624/ 3000]\n",
      "loss: 0.224408  [  632/ 3000]\n",
      "loss: 0.040553  [  640/ 3000]\n",
      "loss: 0.183873  [  648/ 3000]\n",
      "loss: 0.254097  [  656/ 3000]\n",
      "loss: 0.203434  [  664/ 3000]\n",
      "loss: 0.096436  [  672/ 3000]\n",
      "loss: 0.106524  [  680/ 3000]\n",
      "loss: 0.080421  [  688/ 3000]\n",
      "loss: 0.229298  [  696/ 3000]\n",
      "loss: 0.086971  [  704/ 3000]\n",
      "loss: 0.074290  [  712/ 3000]\n",
      "loss: 0.077379  [  720/ 3000]\n",
      "loss: 0.053173  [  728/ 3000]\n",
      "loss: 0.083857  [  736/ 3000]\n",
      "loss: 0.067189  [  744/ 3000]\n",
      "loss: 0.137022  [  752/ 3000]\n",
      "loss: 0.107728  [  760/ 3000]\n",
      "loss: 0.141345  [  768/ 3000]\n",
      "loss: 0.090320  [  776/ 3000]\n",
      "loss: 0.216292  [  784/ 3000]\n",
      "loss: 0.121184  [  792/ 3000]\n",
      "loss: 0.201385  [  800/ 3000]\n",
      "loss: 0.093953  [  808/ 3000]\n",
      "loss: 0.059271  [  816/ 3000]\n",
      "loss: 0.073333  [  824/ 3000]\n",
      "loss: 0.090347  [  832/ 3000]\n",
      "loss: 0.047482  [  840/ 3000]\n",
      "loss: 0.037793  [  848/ 3000]\n",
      "loss: 0.043174  [  856/ 3000]\n",
      "loss: 0.124744  [  864/ 3000]\n",
      "loss: 0.030891  [  872/ 3000]\n",
      "loss: 0.096797  [  880/ 3000]\n",
      "loss: 0.143259  [  888/ 3000]\n",
      "loss: 0.082026  [  896/ 3000]\n",
      "loss: 0.244626  [  904/ 3000]\n",
      "loss: 0.079451  [  912/ 3000]\n",
      "loss: 0.083863  [  920/ 3000]\n",
      "loss: 0.100916  [  928/ 3000]\n",
      "loss: 0.075801  [  936/ 3000]\n",
      "loss: 0.226275  [  944/ 3000]\n",
      "loss: 0.058087  [  952/ 3000]\n",
      "loss: 0.077411  [  960/ 3000]\n",
      "loss: 0.047268  [  968/ 3000]\n",
      "loss: 0.026101  [  976/ 3000]\n",
      "loss: 0.035556  [  984/ 3000]\n",
      "loss: 0.173395  [  992/ 3000]\n",
      "loss: 0.114453  [ 1000/ 3000]\n",
      "loss: 0.087741  [ 1008/ 3000]\n",
      "loss: 0.159848  [ 1016/ 3000]\n",
      "loss: 0.091176  [ 1024/ 3000]\n",
      "loss: 0.141802  [ 1032/ 3000]\n",
      "loss: 0.031921  [ 1040/ 3000]\n",
      "loss: 0.066314  [ 1048/ 3000]\n",
      "loss: 0.037607  [ 1056/ 3000]\n",
      "loss: 0.101453  [ 1064/ 3000]\n",
      "loss: 0.068720  [ 1072/ 3000]\n",
      "loss: 0.074634  [ 1080/ 3000]\n",
      "loss: 0.154420  [ 1088/ 3000]\n",
      "loss: 0.125237  [ 1096/ 3000]\n",
      "loss: 0.042656  [ 1104/ 3000]\n",
      "loss: 0.143337  [ 1112/ 3000]\n",
      "loss: 0.050938  [ 1120/ 3000]\n",
      "loss: 0.067102  [ 1128/ 3000]\n",
      "loss: 0.083950  [ 1136/ 3000]\n",
      "loss: 0.174898  [ 1144/ 3000]\n",
      "loss: 0.063700  [ 1152/ 3000]\n",
      "loss: 0.045411  [ 1160/ 3000]\n",
      "loss: 0.058433  [ 1168/ 3000]\n",
      "loss: 0.050661  [ 1176/ 3000]\n",
      "loss: 0.220035  [ 1184/ 3000]\n",
      "loss: 0.085979  [ 1192/ 3000]\n",
      "loss: 0.083826  [ 1200/ 3000]\n",
      "loss: 0.062078  [ 1208/ 3000]\n",
      "loss: 0.081502  [ 1216/ 3000]\n",
      "loss: 0.122374  [ 1224/ 3000]\n",
      "loss: 0.134702  [ 1232/ 3000]\n",
      "loss: 0.113769  [ 1240/ 3000]\n",
      "loss: 0.134455  [ 1248/ 3000]\n",
      "loss: 0.024660  [ 1256/ 3000]\n",
      "loss: 0.063432  [ 1264/ 3000]\n",
      "loss: 0.044363  [ 1272/ 3000]\n",
      "loss: 0.071077  [ 1280/ 3000]\n",
      "loss: 0.117662  [ 1288/ 3000]\n",
      "loss: 0.049610  [ 1296/ 3000]\n",
      "loss: 0.013482  [ 1304/ 3000]\n",
      "loss: 0.142999  [ 1312/ 3000]\n",
      "loss: 0.338031  [ 1320/ 3000]\n",
      "loss: 0.147994  [ 1328/ 3000]\n",
      "loss: 0.101693  [ 1336/ 3000]\n",
      "loss: 0.184014  [ 1344/ 3000]\n",
      "loss: 0.106386  [ 1352/ 3000]\n",
      "loss: 0.068328  [ 1360/ 3000]\n",
      "loss: 0.160386  [ 1368/ 3000]\n",
      "loss: 0.173478  [ 1376/ 3000]\n",
      "loss: 0.113447  [ 1384/ 3000]\n",
      "loss: 0.067404  [ 1392/ 3000]\n",
      "loss: 0.125272  [ 1400/ 3000]\n",
      "loss: 0.110088  [ 1408/ 3000]\n",
      "loss: 0.125878  [ 1416/ 3000]\n",
      "loss: 0.153052  [ 1424/ 3000]\n",
      "loss: 0.096964  [ 1432/ 3000]\n",
      "loss: 0.057150  [ 1440/ 3000]\n",
      "loss: 0.062264  [ 1448/ 3000]\n",
      "loss: 0.098864  [ 1456/ 3000]\n",
      "loss: 0.016853  [ 1464/ 3000]\n",
      "loss: 0.061679  [ 1472/ 3000]\n",
      "loss: 0.036356  [ 1480/ 3000]\n",
      "loss: 0.155394  [ 1488/ 3000]\n",
      "loss: 0.051364  [ 1496/ 3000]\n",
      "loss: 0.082989  [ 1504/ 3000]\n",
      "loss: 0.103093  [ 1512/ 3000]\n",
      "loss: 0.114891  [ 1520/ 3000]\n",
      "loss: 0.059247  [ 1528/ 3000]\n",
      "loss: 0.109514  [ 1536/ 3000]\n",
      "loss: 0.060056  [ 1544/ 3000]\n",
      "loss: 0.149671  [ 1552/ 3000]\n",
      "loss: 0.066040  [ 1560/ 3000]\n",
      "loss: 0.063570  [ 1568/ 3000]\n",
      "loss: 0.050416  [ 1576/ 3000]\n",
      "loss: 0.135285  [ 1584/ 3000]\n",
      "loss: 0.070002  [ 1592/ 3000]\n",
      "loss: 0.129095  [ 1600/ 3000]\n",
      "loss: 0.061697  [ 1608/ 3000]\n",
      "loss: 0.168530  [ 1616/ 3000]\n",
      "loss: 0.138380  [ 1624/ 3000]\n",
      "loss: 0.063084  [ 1632/ 3000]\n",
      "loss: 0.067004  [ 1640/ 3000]\n",
      "loss: 0.145811  [ 1648/ 3000]\n",
      "loss: 0.051237  [ 1656/ 3000]\n",
      "loss: 0.186014  [ 1664/ 3000]\n",
      "loss: 0.043449  [ 1672/ 3000]\n",
      "loss: 0.068499  [ 1680/ 3000]\n",
      "loss: 0.086215  [ 1688/ 3000]\n",
      "loss: 0.127362  [ 1696/ 3000]\n",
      "loss: 0.080465  [ 1704/ 3000]\n",
      "loss: 0.040421  [ 1712/ 3000]\n",
      "loss: 0.070481  [ 1720/ 3000]\n",
      "loss: 0.082359  [ 1728/ 3000]\n",
      "loss: 0.109356  [ 1736/ 3000]\n",
      "loss: 0.102923  [ 1744/ 3000]\n",
      "loss: 0.031144  [ 1752/ 3000]\n",
      "loss: 0.023221  [ 1760/ 3000]\n",
      "loss: 0.159060  [ 1768/ 3000]\n",
      "loss: 0.095053  [ 1776/ 3000]\n",
      "loss: 0.047790  [ 1784/ 3000]\n",
      "loss: 0.065053  [ 1792/ 3000]\n",
      "loss: 0.132907  [ 1800/ 3000]\n",
      "loss: 0.172950  [ 1808/ 3000]\n",
      "loss: 0.049989  [ 1816/ 3000]\n",
      "loss: 0.157844  [ 1824/ 3000]\n",
      "loss: 0.019978  [ 1832/ 3000]\n",
      "loss: 0.015188  [ 1840/ 3000]\n",
      "loss: 0.086612  [ 1848/ 3000]\n",
      "loss: 0.103901  [ 1856/ 3000]\n",
      "loss: 0.104711  [ 1864/ 3000]\n",
      "loss: 0.094175  [ 1872/ 3000]\n",
      "loss: 0.026063  [ 1880/ 3000]\n",
      "loss: 0.038674  [ 1888/ 3000]\n",
      "loss: 0.105713  [ 1896/ 3000]\n",
      "loss: 0.039898  [ 1904/ 3000]\n",
      "loss: 0.064445  [ 1912/ 3000]\n",
      "loss: 0.130177  [ 1920/ 3000]\n",
      "loss: 0.110428  [ 1928/ 3000]\n",
      "loss: 0.172981  [ 1936/ 3000]\n",
      "loss: 0.034061  [ 1944/ 3000]\n",
      "loss: 0.116363  [ 1952/ 3000]\n",
      "loss: 0.041841  [ 1960/ 3000]\n",
      "loss: 0.140534  [ 1968/ 3000]\n",
      "loss: 0.050350  [ 1976/ 3000]\n",
      "loss: 0.148372  [ 1984/ 3000]\n",
      "loss: 0.153612  [ 1992/ 3000]\n",
      "loss: 0.099133  [ 2000/ 3000]\n",
      "loss: 0.128953  [ 2008/ 3000]\n",
      "loss: 0.090582  [ 2016/ 3000]\n",
      "loss: 0.074810  [ 2024/ 3000]\n",
      "loss: 0.128254  [ 2032/ 3000]\n",
      "loss: 0.107613  [ 2040/ 3000]\n",
      "loss: 0.053852  [ 2048/ 3000]\n",
      "loss: 0.060121  [ 2056/ 3000]\n",
      "loss: 0.047540  [ 2064/ 3000]\n",
      "loss: 0.158287  [ 2072/ 3000]\n",
      "loss: 0.069342  [ 2080/ 3000]\n",
      "loss: 0.147625  [ 2088/ 3000]\n",
      "loss: 0.099917  [ 2096/ 3000]\n",
      "loss: 0.061349  [ 2104/ 3000]\n",
      "loss: 0.041584  [ 2112/ 3000]\n",
      "loss: 0.029652  [ 2120/ 3000]\n",
      "loss: 0.085128  [ 2128/ 3000]\n",
      "loss: 0.087738  [ 2136/ 3000]\n",
      "loss: 0.135533  [ 2144/ 3000]\n",
      "loss: 0.158261  [ 2152/ 3000]\n",
      "loss: 0.039737  [ 2160/ 3000]\n",
      "loss: 0.090317  [ 2168/ 3000]\n",
      "loss: 0.045950  [ 2176/ 3000]\n",
      "loss: 0.114344  [ 2184/ 3000]\n",
      "loss: 0.108734  [ 2192/ 3000]\n",
      "loss: 0.044870  [ 2200/ 3000]\n",
      "loss: 0.031902  [ 2208/ 3000]\n",
      "loss: 0.058798  [ 2216/ 3000]\n",
      "loss: 0.125759  [ 2224/ 3000]\n",
      "loss: 0.093839  [ 2232/ 3000]\n",
      "loss: 0.151790  [ 2240/ 3000]\n",
      "loss: 0.023638  [ 2248/ 3000]\n",
      "loss: 0.092909  [ 2256/ 3000]\n",
      "loss: 0.036537  [ 2264/ 3000]\n",
      "loss: 0.151141  [ 2272/ 3000]\n",
      "loss: 0.060050  [ 2280/ 3000]\n",
      "loss: 0.159743  [ 2288/ 3000]\n",
      "loss: 0.085645  [ 2296/ 3000]\n",
      "loss: 0.060889  [ 2304/ 3000]\n",
      "loss: 0.040472  [ 2312/ 3000]\n",
      "loss: 0.037723  [ 2320/ 3000]\n",
      "loss: 0.104039  [ 2328/ 3000]\n",
      "loss: 0.026989  [ 2336/ 3000]\n",
      "loss: 0.138259  [ 2344/ 3000]\n",
      "loss: 0.161422  [ 2352/ 3000]\n",
      "loss: 0.116130  [ 2360/ 3000]\n",
      "loss: 0.068826  [ 2368/ 3000]\n",
      "loss: 0.040394  [ 2376/ 3000]\n",
      "loss: 0.069616  [ 2384/ 3000]\n",
      "loss: 0.070175  [ 2392/ 3000]\n",
      "loss: 0.025676  [ 2400/ 3000]\n",
      "loss: 0.151181  [ 2408/ 3000]\n",
      "loss: 0.095718  [ 2416/ 3000]\n",
      "loss: 0.108082  [ 2424/ 3000]\n",
      "loss: 0.126489  [ 2432/ 3000]\n",
      "loss: 0.068561  [ 2440/ 3000]\n",
      "loss: 0.145039  [ 2448/ 3000]\n",
      "loss: 0.147502  [ 2456/ 3000]\n",
      "loss: 0.070722  [ 2464/ 3000]\n",
      "loss: 0.262709  [ 2472/ 3000]\n",
      "loss: 0.039346  [ 2480/ 3000]\n",
      "loss: 0.080313  [ 2488/ 3000]\n",
      "loss: 0.033326  [ 2496/ 3000]\n",
      "loss: 0.057594  [ 2504/ 3000]\n",
      "loss: 0.159757  [ 2512/ 3000]\n",
      "loss: 0.249211  [ 2520/ 3000]\n",
      "loss: 0.055447  [ 2528/ 3000]\n",
      "loss: 0.084012  [ 2536/ 3000]\n",
      "loss: 0.038588  [ 2544/ 3000]\n",
      "loss: 0.123410  [ 2552/ 3000]\n",
      "loss: 0.105487  [ 2560/ 3000]\n",
      "loss: 0.163242  [ 2568/ 3000]\n",
      "loss: 0.143726  [ 2576/ 3000]\n",
      "loss: 0.092926  [ 2584/ 3000]\n",
      "loss: 0.074667  [ 2592/ 3000]\n",
      "loss: 0.084628  [ 2600/ 3000]\n",
      "loss: 0.111879  [ 2608/ 3000]\n",
      "loss: 0.050003  [ 2616/ 3000]\n",
      "loss: 0.055446  [ 2624/ 3000]\n",
      "loss: 0.130285  [ 2632/ 3000]\n",
      "loss: 0.155504  [ 2640/ 3000]\n",
      "loss: 0.104144  [ 2648/ 3000]\n",
      "loss: 0.115135  [ 2656/ 3000]\n",
      "loss: 0.080905  [ 2664/ 3000]\n",
      "loss: 0.139558  [ 2672/ 3000]\n",
      "loss: 0.159167  [ 2680/ 3000]\n",
      "loss: 0.072608  [ 2688/ 3000]\n",
      "loss: 0.060440  [ 2696/ 3000]\n",
      "loss: 0.100839  [ 2704/ 3000]\n",
      "loss: 0.123458  [ 2712/ 3000]\n",
      "loss: 0.085979  [ 2720/ 3000]\n",
      "loss: 0.149885  [ 2728/ 3000]\n",
      "loss: 0.043525  [ 2736/ 3000]\n",
      "loss: 0.097875  [ 2744/ 3000]\n",
      "loss: 0.121158  [ 2752/ 3000]\n",
      "loss: 0.081450  [ 2760/ 3000]\n",
      "loss: 0.036589  [ 2768/ 3000]\n",
      "loss: 0.155098  [ 2776/ 3000]\n",
      "loss: 0.094142  [ 2784/ 3000]\n",
      "loss: 0.068347  [ 2792/ 3000]\n",
      "loss: 0.136364  [ 2800/ 3000]\n",
      "loss: 0.185955  [ 2808/ 3000]\n",
      "loss: 0.098302  [ 2816/ 3000]\n",
      "loss: 0.100721  [ 2824/ 3000]\n",
      "loss: 0.110283  [ 2832/ 3000]\n",
      "loss: 0.080435  [ 2840/ 3000]\n",
      "loss: 0.082448  [ 2848/ 3000]\n",
      "loss: 0.110843  [ 2856/ 3000]\n",
      "loss: 0.057484  [ 2864/ 3000]\n",
      "loss: 0.114745  [ 2872/ 3000]\n",
      "loss: 0.145619  [ 2880/ 3000]\n",
      "loss: 0.037776  [ 2888/ 3000]\n",
      "loss: 0.026879  [ 2896/ 3000]\n",
      "loss: 0.107220  [ 2904/ 3000]\n",
      "loss: 0.121953  [ 2912/ 3000]\n",
      "loss: 0.088577  [ 2920/ 3000]\n",
      "loss: 0.147762  [ 2928/ 3000]\n",
      "loss: 0.224979  [ 2936/ 3000]\n",
      "loss: 0.049510  [ 2944/ 3000]\n",
      "loss: 0.012053  [ 2952/ 3000]\n",
      "loss: 0.043693  [ 2960/ 3000]\n",
      "loss: 0.075935  [ 2968/ 3000]\n",
      "loss: 0.067439  [ 2976/ 3000]\n",
      "loss: 0.081470  [ 2984/ 3000]\n",
      "loss: 0.026020  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.097183 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.049792  [    0/ 3000]\n",
      "loss: 0.102931  [    8/ 3000]\n",
      "loss: 0.050842  [   16/ 3000]\n",
      "loss: 0.054358  [   24/ 3000]\n",
      "loss: 0.153779  [   32/ 3000]\n",
      "loss: 0.036559  [   40/ 3000]\n",
      "loss: 0.037002  [   48/ 3000]\n",
      "loss: 0.099259  [   56/ 3000]\n",
      "loss: 0.195300  [   64/ 3000]\n",
      "loss: 0.032443  [   72/ 3000]\n",
      "loss: 0.178073  [   80/ 3000]\n",
      "loss: 0.118013  [   88/ 3000]\n",
      "loss: 0.144621  [   96/ 3000]\n",
      "loss: 0.083398  [  104/ 3000]\n",
      "loss: 0.198498  [  112/ 3000]\n",
      "loss: 0.058203  [  120/ 3000]\n",
      "loss: 0.049267  [  128/ 3000]\n",
      "loss: 0.126146  [  136/ 3000]\n",
      "loss: 0.109091  [  144/ 3000]\n",
      "loss: 0.062547  [  152/ 3000]\n",
      "loss: 0.036864  [  160/ 3000]\n",
      "loss: 0.026646  [  168/ 3000]\n",
      "loss: 0.054819  [  176/ 3000]\n",
      "loss: 0.117281  [  184/ 3000]\n",
      "loss: 0.084925  [  192/ 3000]\n",
      "loss: 0.059116  [  200/ 3000]\n",
      "loss: 0.193476  [  208/ 3000]\n",
      "loss: 0.060516  [  216/ 3000]\n",
      "loss: 0.079178  [  224/ 3000]\n",
      "loss: 0.172340  [  232/ 3000]\n",
      "loss: 0.084521  [  240/ 3000]\n",
      "loss: 0.064705  [  248/ 3000]\n",
      "loss: 0.047108  [  256/ 3000]\n",
      "loss: 0.124295  [  264/ 3000]\n",
      "loss: 0.065830  [  272/ 3000]\n",
      "loss: 0.193295  [  280/ 3000]\n",
      "loss: 0.044701  [  288/ 3000]\n",
      "loss: 0.074511  [  296/ 3000]\n",
      "loss: 0.058919  [  304/ 3000]\n",
      "loss: 0.137624  [  312/ 3000]\n",
      "loss: 0.075010  [  320/ 3000]\n",
      "loss: 0.193099  [  328/ 3000]\n",
      "loss: 0.075747  [  336/ 3000]\n",
      "loss: 0.101280  [  344/ 3000]\n",
      "loss: 0.038151  [  352/ 3000]\n",
      "loss: 0.043933  [  360/ 3000]\n",
      "loss: 0.154409  [  368/ 3000]\n",
      "loss: 0.041484  [  376/ 3000]\n",
      "loss: 0.124528  [  384/ 3000]\n",
      "loss: 0.077328  [  392/ 3000]\n",
      "loss: 0.132108  [  400/ 3000]\n",
      "loss: 0.053477  [  408/ 3000]\n",
      "loss: 0.136303  [  416/ 3000]\n",
      "loss: 0.075596  [  424/ 3000]\n",
      "loss: 0.210141  [  432/ 3000]\n",
      "loss: 0.057952  [  440/ 3000]\n",
      "loss: 0.109833  [  448/ 3000]\n",
      "loss: 0.071504  [  456/ 3000]\n",
      "loss: 0.159376  [  464/ 3000]\n",
      "loss: 0.079680  [  472/ 3000]\n",
      "loss: 0.029680  [  480/ 3000]\n",
      "loss: 0.163669  [  488/ 3000]\n",
      "loss: 0.110096  [  496/ 3000]\n",
      "loss: 0.062668  [  504/ 3000]\n",
      "loss: 0.092404  [  512/ 3000]\n",
      "loss: 0.056662  [  520/ 3000]\n",
      "loss: 0.251849  [  528/ 3000]\n",
      "loss: 0.131110  [  536/ 3000]\n",
      "loss: 0.120666  [  544/ 3000]\n",
      "loss: 0.082935  [  552/ 3000]\n",
      "loss: 0.064611  [  560/ 3000]\n",
      "loss: 0.121289  [  568/ 3000]\n",
      "loss: 0.089866  [  576/ 3000]\n",
      "loss: 0.103169  [  584/ 3000]\n",
      "loss: 0.054542  [  592/ 3000]\n",
      "loss: 0.194710  [  600/ 3000]\n",
      "loss: 0.050526  [  608/ 3000]\n",
      "loss: 0.127928  [  616/ 3000]\n",
      "loss: 0.089434  [  624/ 3000]\n",
      "loss: 0.221998  [  632/ 3000]\n",
      "loss: 0.036656  [  640/ 3000]\n",
      "loss: 0.181406  [  648/ 3000]\n",
      "loss: 0.249054  [  656/ 3000]\n",
      "loss: 0.199247  [  664/ 3000]\n",
      "loss: 0.094547  [  672/ 3000]\n",
      "loss: 0.104598  [  680/ 3000]\n",
      "loss: 0.077615  [  688/ 3000]\n",
      "loss: 0.222951  [  696/ 3000]\n",
      "loss: 0.084659  [  704/ 3000]\n",
      "loss: 0.071343  [  712/ 3000]\n",
      "loss: 0.075774  [  720/ 3000]\n",
      "loss: 0.051091  [  728/ 3000]\n",
      "loss: 0.081365  [  736/ 3000]\n",
      "loss: 0.063196  [  744/ 3000]\n",
      "loss: 0.131600  [  752/ 3000]\n",
      "loss: 0.103125  [  760/ 3000]\n",
      "loss: 0.140425  [  768/ 3000]\n",
      "loss: 0.087427  [  776/ 3000]\n",
      "loss: 0.209951  [  784/ 3000]\n",
      "loss: 0.117080  [  792/ 3000]\n",
      "loss: 0.197529  [  800/ 3000]\n",
      "loss: 0.089765  [  808/ 3000]\n",
      "loss: 0.056039  [  816/ 3000]\n",
      "loss: 0.070909  [  824/ 3000]\n",
      "loss: 0.086359  [  832/ 3000]\n",
      "loss: 0.044644  [  840/ 3000]\n",
      "loss: 0.035071  [  848/ 3000]\n",
      "loss: 0.041184  [  856/ 3000]\n",
      "loss: 0.120772  [  864/ 3000]\n",
      "loss: 0.028400  [  872/ 3000]\n",
      "loss: 0.096621  [  880/ 3000]\n",
      "loss: 0.137752  [  888/ 3000]\n",
      "loss: 0.080456  [  896/ 3000]\n",
      "loss: 0.240299  [  904/ 3000]\n",
      "loss: 0.076601  [  912/ 3000]\n",
      "loss: 0.082254  [  920/ 3000]\n",
      "loss: 0.097850  [  928/ 3000]\n",
      "loss: 0.073017  [  936/ 3000]\n",
      "loss: 0.222429  [  944/ 3000]\n",
      "loss: 0.055263  [  952/ 3000]\n",
      "loss: 0.073800  [  960/ 3000]\n",
      "loss: 0.044161  [  968/ 3000]\n",
      "loss: 0.024313  [  976/ 3000]\n",
      "loss: 0.032679  [  984/ 3000]\n",
      "loss: 0.168046  [  992/ 3000]\n",
      "loss: 0.109447  [ 1000/ 3000]\n",
      "loss: 0.085819  [ 1008/ 3000]\n",
      "loss: 0.156199  [ 1016/ 3000]\n",
      "loss: 0.088638  [ 1024/ 3000]\n",
      "loss: 0.138998  [ 1032/ 3000]\n",
      "loss: 0.030190  [ 1040/ 3000]\n",
      "loss: 0.063680  [ 1048/ 3000]\n",
      "loss: 0.036109  [ 1056/ 3000]\n",
      "loss: 0.099791  [ 1064/ 3000]\n",
      "loss: 0.066338  [ 1072/ 3000]\n",
      "loss: 0.072339  [ 1080/ 3000]\n",
      "loss: 0.149030  [ 1088/ 3000]\n",
      "loss: 0.122462  [ 1096/ 3000]\n",
      "loss: 0.039650  [ 1104/ 3000]\n",
      "loss: 0.140006  [ 1112/ 3000]\n",
      "loss: 0.048884  [ 1120/ 3000]\n",
      "loss: 0.064611  [ 1128/ 3000]\n",
      "loss: 0.079133  [ 1136/ 3000]\n",
      "loss: 0.171457  [ 1144/ 3000]\n",
      "loss: 0.060687  [ 1152/ 3000]\n",
      "loss: 0.043515  [ 1160/ 3000]\n",
      "loss: 0.055124  [ 1168/ 3000]\n",
      "loss: 0.047620  [ 1176/ 3000]\n",
      "loss: 0.215685  [ 1184/ 3000]\n",
      "loss: 0.082838  [ 1192/ 3000]\n",
      "loss: 0.079918  [ 1200/ 3000]\n",
      "loss: 0.058446  [ 1208/ 3000]\n",
      "loss: 0.077965  [ 1216/ 3000]\n",
      "loss: 0.117989  [ 1224/ 3000]\n",
      "loss: 0.130735  [ 1232/ 3000]\n",
      "loss: 0.111057  [ 1240/ 3000]\n",
      "loss: 0.129878  [ 1248/ 3000]\n",
      "loss: 0.023387  [ 1256/ 3000]\n",
      "loss: 0.061522  [ 1264/ 3000]\n",
      "loss: 0.041906  [ 1272/ 3000]\n",
      "loss: 0.065928  [ 1280/ 3000]\n",
      "loss: 0.112306  [ 1288/ 3000]\n",
      "loss: 0.046944  [ 1296/ 3000]\n",
      "loss: 0.011696  [ 1304/ 3000]\n",
      "loss: 0.138871  [ 1312/ 3000]\n",
      "loss: 0.331324  [ 1320/ 3000]\n",
      "loss: 0.143913  [ 1328/ 3000]\n",
      "loss: 0.098537  [ 1336/ 3000]\n",
      "loss: 0.178643  [ 1344/ 3000]\n",
      "loss: 0.104005  [ 1352/ 3000]\n",
      "loss: 0.063702  [ 1360/ 3000]\n",
      "loss: 0.155041  [ 1368/ 3000]\n",
      "loss: 0.168554  [ 1376/ 3000]\n",
      "loss: 0.107355  [ 1384/ 3000]\n",
      "loss: 0.064303  [ 1392/ 3000]\n",
      "loss: 0.121277  [ 1400/ 3000]\n",
      "loss: 0.107634  [ 1408/ 3000]\n",
      "loss: 0.120644  [ 1416/ 3000]\n",
      "loss: 0.149834  [ 1424/ 3000]\n",
      "loss: 0.093053  [ 1432/ 3000]\n",
      "loss: 0.055037  [ 1440/ 3000]\n",
      "loss: 0.058382  [ 1448/ 3000]\n",
      "loss: 0.094626  [ 1456/ 3000]\n",
      "loss: 0.015703  [ 1464/ 3000]\n",
      "loss: 0.060012  [ 1472/ 3000]\n",
      "loss: 0.034106  [ 1480/ 3000]\n",
      "loss: 0.153142  [ 1488/ 3000]\n",
      "loss: 0.048448  [ 1496/ 3000]\n",
      "loss: 0.079381  [ 1504/ 3000]\n",
      "loss: 0.102055  [ 1512/ 3000]\n",
      "loss: 0.110525  [ 1520/ 3000]\n",
      "loss: 0.055450  [ 1528/ 3000]\n",
      "loss: 0.106556  [ 1536/ 3000]\n",
      "loss: 0.057416  [ 1544/ 3000]\n",
      "loss: 0.145746  [ 1552/ 3000]\n",
      "loss: 0.064025  [ 1560/ 3000]\n",
      "loss: 0.060874  [ 1568/ 3000]\n",
      "loss: 0.046685  [ 1576/ 3000]\n",
      "loss: 0.131103  [ 1584/ 3000]\n",
      "loss: 0.069166  [ 1592/ 3000]\n",
      "loss: 0.124638  [ 1600/ 3000]\n",
      "loss: 0.058417  [ 1608/ 3000]\n",
      "loss: 0.164815  [ 1616/ 3000]\n",
      "loss: 0.135156  [ 1624/ 3000]\n",
      "loss: 0.061160  [ 1632/ 3000]\n",
      "loss: 0.065303  [ 1640/ 3000]\n",
      "loss: 0.144398  [ 1648/ 3000]\n",
      "loss: 0.049524  [ 1656/ 3000]\n",
      "loss: 0.178352  [ 1664/ 3000]\n",
      "loss: 0.040847  [ 1672/ 3000]\n",
      "loss: 0.066075  [ 1680/ 3000]\n",
      "loss: 0.083741  [ 1688/ 3000]\n",
      "loss: 0.122009  [ 1696/ 3000]\n",
      "loss: 0.076917  [ 1704/ 3000]\n",
      "loss: 0.037868  [ 1712/ 3000]\n",
      "loss: 0.066234  [ 1720/ 3000]\n",
      "loss: 0.078765  [ 1728/ 3000]\n",
      "loss: 0.107174  [ 1736/ 3000]\n",
      "loss: 0.099305  [ 1744/ 3000]\n",
      "loss: 0.029198  [ 1752/ 3000]\n",
      "loss: 0.020772  [ 1760/ 3000]\n",
      "loss: 0.153676  [ 1768/ 3000]\n",
      "loss: 0.091664  [ 1776/ 3000]\n",
      "loss: 0.044675  [ 1784/ 3000]\n",
      "loss: 0.063145  [ 1792/ 3000]\n",
      "loss: 0.128588  [ 1800/ 3000]\n",
      "loss: 0.167945  [ 1808/ 3000]\n",
      "loss: 0.049300  [ 1816/ 3000]\n",
      "loss: 0.155122  [ 1824/ 3000]\n",
      "loss: 0.017754  [ 1832/ 3000]\n",
      "loss: 0.014486  [ 1840/ 3000]\n",
      "loss: 0.082038  [ 1848/ 3000]\n",
      "loss: 0.101338  [ 1856/ 3000]\n",
      "loss: 0.102147  [ 1864/ 3000]\n",
      "loss: 0.090815  [ 1872/ 3000]\n",
      "loss: 0.024549  [ 1880/ 3000]\n",
      "loss: 0.036418  [ 1888/ 3000]\n",
      "loss: 0.101388  [ 1896/ 3000]\n",
      "loss: 0.038580  [ 1904/ 3000]\n",
      "loss: 0.060812  [ 1912/ 3000]\n",
      "loss: 0.126577  [ 1920/ 3000]\n",
      "loss: 0.107441  [ 1928/ 3000]\n",
      "loss: 0.168666  [ 1936/ 3000]\n",
      "loss: 0.030868  [ 1944/ 3000]\n",
      "loss: 0.113503  [ 1952/ 3000]\n",
      "loss: 0.040863  [ 1960/ 3000]\n",
      "loss: 0.136571  [ 1968/ 3000]\n",
      "loss: 0.047945  [ 1976/ 3000]\n",
      "loss: 0.144721  [ 1984/ 3000]\n",
      "loss: 0.151113  [ 1992/ 3000]\n",
      "loss: 0.095343  [ 2000/ 3000]\n",
      "loss: 0.125560  [ 2008/ 3000]\n",
      "loss: 0.087067  [ 2016/ 3000]\n",
      "loss: 0.072505  [ 2024/ 3000]\n",
      "loss: 0.124142  [ 2032/ 3000]\n",
      "loss: 0.103664  [ 2040/ 3000]\n",
      "loss: 0.051238  [ 2048/ 3000]\n",
      "loss: 0.057094  [ 2056/ 3000]\n",
      "loss: 0.045046  [ 2064/ 3000]\n",
      "loss: 0.151875  [ 2072/ 3000]\n",
      "loss: 0.066710  [ 2080/ 3000]\n",
      "loss: 0.142090  [ 2088/ 3000]\n",
      "loss: 0.096991  [ 2096/ 3000]\n",
      "loss: 0.060141  [ 2104/ 3000]\n",
      "loss: 0.039218  [ 2112/ 3000]\n",
      "loss: 0.027296  [ 2120/ 3000]\n",
      "loss: 0.082483  [ 2128/ 3000]\n",
      "loss: 0.084848  [ 2136/ 3000]\n",
      "loss: 0.130649  [ 2144/ 3000]\n",
      "loss: 0.155000  [ 2152/ 3000]\n",
      "loss: 0.038090  [ 2160/ 3000]\n",
      "loss: 0.087814  [ 2168/ 3000]\n",
      "loss: 0.042772  [ 2176/ 3000]\n",
      "loss: 0.111973  [ 2184/ 3000]\n",
      "loss: 0.105359  [ 2192/ 3000]\n",
      "loss: 0.043087  [ 2200/ 3000]\n",
      "loss: 0.030132  [ 2208/ 3000]\n",
      "loss: 0.055166  [ 2216/ 3000]\n",
      "loss: 0.123006  [ 2224/ 3000]\n",
      "loss: 0.092348  [ 2232/ 3000]\n",
      "loss: 0.147144  [ 2240/ 3000]\n",
      "loss: 0.021791  [ 2248/ 3000]\n",
      "loss: 0.088271  [ 2256/ 3000]\n",
      "loss: 0.034728  [ 2264/ 3000]\n",
      "loss: 0.149931  [ 2272/ 3000]\n",
      "loss: 0.057605  [ 2280/ 3000]\n",
      "loss: 0.155693  [ 2288/ 3000]\n",
      "loss: 0.083403  [ 2296/ 3000]\n",
      "loss: 0.060107  [ 2304/ 3000]\n",
      "loss: 0.038909  [ 2312/ 3000]\n",
      "loss: 0.035547  [ 2320/ 3000]\n",
      "loss: 0.100910  [ 2328/ 3000]\n",
      "loss: 0.024763  [ 2336/ 3000]\n",
      "loss: 0.135540  [ 2344/ 3000]\n",
      "loss: 0.155976  [ 2352/ 3000]\n",
      "loss: 0.114561  [ 2360/ 3000]\n",
      "loss: 0.065294  [ 2368/ 3000]\n",
      "loss: 0.038739  [ 2376/ 3000]\n",
      "loss: 0.067956  [ 2384/ 3000]\n",
      "loss: 0.068713  [ 2392/ 3000]\n",
      "loss: 0.022811  [ 2400/ 3000]\n",
      "loss: 0.146848  [ 2408/ 3000]\n",
      "loss: 0.094087  [ 2416/ 3000]\n",
      "loss: 0.105713  [ 2424/ 3000]\n",
      "loss: 0.121909  [ 2432/ 3000]\n",
      "loss: 0.066193  [ 2440/ 3000]\n",
      "loss: 0.142086  [ 2448/ 3000]\n",
      "loss: 0.143319  [ 2456/ 3000]\n",
      "loss: 0.068016  [ 2464/ 3000]\n",
      "loss: 0.260338  [ 2472/ 3000]\n",
      "loss: 0.037405  [ 2480/ 3000]\n",
      "loss: 0.077100  [ 2488/ 3000]\n",
      "loss: 0.030659  [ 2496/ 3000]\n",
      "loss: 0.054846  [ 2504/ 3000]\n",
      "loss: 0.154514  [ 2512/ 3000]\n",
      "loss: 0.245438  [ 2520/ 3000]\n",
      "loss: 0.052144  [ 2528/ 3000]\n",
      "loss: 0.080786  [ 2536/ 3000]\n",
      "loss: 0.034983  [ 2544/ 3000]\n",
      "loss: 0.120014  [ 2552/ 3000]\n",
      "loss: 0.104074  [ 2560/ 3000]\n",
      "loss: 0.158885  [ 2568/ 3000]\n",
      "loss: 0.140999  [ 2576/ 3000]\n",
      "loss: 0.088917  [ 2584/ 3000]\n",
      "loss: 0.071330  [ 2592/ 3000]\n",
      "loss: 0.083171  [ 2600/ 3000]\n",
      "loss: 0.108458  [ 2608/ 3000]\n",
      "loss: 0.047695  [ 2616/ 3000]\n",
      "loss: 0.052094  [ 2624/ 3000]\n",
      "loss: 0.128151  [ 2632/ 3000]\n",
      "loss: 0.151619  [ 2640/ 3000]\n",
      "loss: 0.100978  [ 2648/ 3000]\n",
      "loss: 0.111184  [ 2656/ 3000]\n",
      "loss: 0.077420  [ 2664/ 3000]\n",
      "loss: 0.135607  [ 2672/ 3000]\n",
      "loss: 0.155001  [ 2680/ 3000]\n",
      "loss: 0.069343  [ 2688/ 3000]\n",
      "loss: 0.057379  [ 2696/ 3000]\n",
      "loss: 0.098644  [ 2704/ 3000]\n",
      "loss: 0.117468  [ 2712/ 3000]\n",
      "loss: 0.082731  [ 2720/ 3000]\n",
      "loss: 0.145426  [ 2728/ 3000]\n",
      "loss: 0.041746  [ 2736/ 3000]\n",
      "loss: 0.093894  [ 2744/ 3000]\n",
      "loss: 0.117385  [ 2752/ 3000]\n",
      "loss: 0.079106  [ 2760/ 3000]\n",
      "loss: 0.034189  [ 2768/ 3000]\n",
      "loss: 0.150616  [ 2776/ 3000]\n",
      "loss: 0.092122  [ 2784/ 3000]\n",
      "loss: 0.064812  [ 2792/ 3000]\n",
      "loss: 0.131888  [ 2800/ 3000]\n",
      "loss: 0.182767  [ 2808/ 3000]\n",
      "loss: 0.094482  [ 2816/ 3000]\n",
      "loss: 0.098152  [ 2824/ 3000]\n",
      "loss: 0.106494  [ 2832/ 3000]\n",
      "loss: 0.077331  [ 2840/ 3000]\n",
      "loss: 0.080037  [ 2848/ 3000]\n",
      "loss: 0.107753  [ 2856/ 3000]\n",
      "loss: 0.054203  [ 2864/ 3000]\n",
      "loss: 0.110677  [ 2872/ 3000]\n",
      "loss: 0.141023  [ 2880/ 3000]\n",
      "loss: 0.034647  [ 2888/ 3000]\n",
      "loss: 0.025254  [ 2896/ 3000]\n",
      "loss: 0.102536  [ 2904/ 3000]\n",
      "loss: 0.118623  [ 2912/ 3000]\n",
      "loss: 0.085505  [ 2920/ 3000]\n",
      "loss: 0.143568  [ 2928/ 3000]\n",
      "loss: 0.218930  [ 2936/ 3000]\n",
      "loss: 0.046569  [ 2944/ 3000]\n",
      "loss: 0.010752  [ 2952/ 3000]\n",
      "loss: 0.041925  [ 2960/ 3000]\n",
      "loss: 0.074165  [ 2968/ 3000]\n",
      "loss: 0.065976  [ 2976/ 3000]\n",
      "loss: 0.079210  [ 2984/ 3000]\n",
      "loss: 0.023736  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.095323 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.046604  [    0/ 3000]\n",
      "loss: 0.098875  [    8/ 3000]\n",
      "loss: 0.046916  [   16/ 3000]\n",
      "loss: 0.051740  [   24/ 3000]\n",
      "loss: 0.148950  [   32/ 3000]\n",
      "loss: 0.034020  [   40/ 3000]\n",
      "loss: 0.035086  [   48/ 3000]\n",
      "loss: 0.096421  [   56/ 3000]\n",
      "loss: 0.191429  [   64/ 3000]\n",
      "loss: 0.030924  [   72/ 3000]\n",
      "loss: 0.174239  [   80/ 3000]\n",
      "loss: 0.113094  [   88/ 3000]\n",
      "loss: 0.139359  [   96/ 3000]\n",
      "loss: 0.080819  [  104/ 3000]\n",
      "loss: 0.195462  [  112/ 3000]\n",
      "loss: 0.055914  [  120/ 3000]\n",
      "loss: 0.047132  [  128/ 3000]\n",
      "loss: 0.121299  [  136/ 3000]\n",
      "loss: 0.105309  [  144/ 3000]\n",
      "loss: 0.061012  [  152/ 3000]\n",
      "loss: 0.034516  [  160/ 3000]\n",
      "loss: 0.024636  [  168/ 3000]\n",
      "loss: 0.052199  [  176/ 3000]\n",
      "loss: 0.114122  [  184/ 3000]\n",
      "loss: 0.082374  [  192/ 3000]\n",
      "loss: 0.056206  [  200/ 3000]\n",
      "loss: 0.190408  [  208/ 3000]\n",
      "loss: 0.058168  [  216/ 3000]\n",
      "loss: 0.075813  [  224/ 3000]\n",
      "loss: 0.167563  [  232/ 3000]\n",
      "loss: 0.080885  [  240/ 3000]\n",
      "loss: 0.062132  [  248/ 3000]\n",
      "loss: 0.044770  [  256/ 3000]\n",
      "loss: 0.120440  [  264/ 3000]\n",
      "loss: 0.063639  [  272/ 3000]\n",
      "loss: 0.191502  [  280/ 3000]\n",
      "loss: 0.042420  [  288/ 3000]\n",
      "loss: 0.072458  [  296/ 3000]\n",
      "loss: 0.056313  [  304/ 3000]\n",
      "loss: 0.135234  [  312/ 3000]\n",
      "loss: 0.071295  [  320/ 3000]\n",
      "loss: 0.186714  [  328/ 3000]\n",
      "loss: 0.071766  [  336/ 3000]\n",
      "loss: 0.100284  [  344/ 3000]\n",
      "loss: 0.035873  [  352/ 3000]\n",
      "loss: 0.042994  [  360/ 3000]\n",
      "loss: 0.151270  [  368/ 3000]\n",
      "loss: 0.039649  [  376/ 3000]\n",
      "loss: 0.119629  [  384/ 3000]\n",
      "loss: 0.076161  [  392/ 3000]\n",
      "loss: 0.125574  [  400/ 3000]\n",
      "loss: 0.050429  [  408/ 3000]\n",
      "loss: 0.132081  [  416/ 3000]\n",
      "loss: 0.072093  [  424/ 3000]\n",
      "loss: 0.206549  [  432/ 3000]\n",
      "loss: 0.056296  [  440/ 3000]\n",
      "loss: 0.105124  [  448/ 3000]\n",
      "loss: 0.068867  [  456/ 3000]\n",
      "loss: 0.155497  [  464/ 3000]\n",
      "loss: 0.078108  [  472/ 3000]\n",
      "loss: 0.027968  [  480/ 3000]\n",
      "loss: 0.161365  [  488/ 3000]\n",
      "loss: 0.108683  [  496/ 3000]\n",
      "loss: 0.061335  [  504/ 3000]\n",
      "loss: 0.089310  [  512/ 3000]\n",
      "loss: 0.055407  [  520/ 3000]\n",
      "loss: 0.247708  [  528/ 3000]\n",
      "loss: 0.127559  [  536/ 3000]\n",
      "loss: 0.117157  [  544/ 3000]\n",
      "loss: 0.079683  [  552/ 3000]\n",
      "loss: 0.061488  [  560/ 3000]\n",
      "loss: 0.118061  [  568/ 3000]\n",
      "loss: 0.085513  [  576/ 3000]\n",
      "loss: 0.098184  [  584/ 3000]\n",
      "loss: 0.052017  [  592/ 3000]\n",
      "loss: 0.188966  [  600/ 3000]\n",
      "loss: 0.049671  [  608/ 3000]\n",
      "loss: 0.124091  [  616/ 3000]\n",
      "loss: 0.086003  [  624/ 3000]\n",
      "loss: 0.219447  [  632/ 3000]\n",
      "loss: 0.033556  [  640/ 3000]\n",
      "loss: 0.178802  [  648/ 3000]\n",
      "loss: 0.244196  [  656/ 3000]\n",
      "loss: 0.195162  [  664/ 3000]\n",
      "loss: 0.092760  [  672/ 3000]\n",
      "loss: 0.102633  [  680/ 3000]\n",
      "loss: 0.074934  [  688/ 3000]\n",
      "loss: 0.217290  [  696/ 3000]\n",
      "loss: 0.082551  [  704/ 3000]\n",
      "loss: 0.068530  [  712/ 3000]\n",
      "loss: 0.074351  [  720/ 3000]\n",
      "loss: 0.049159  [  728/ 3000]\n",
      "loss: 0.079327  [  736/ 3000]\n",
      "loss: 0.059530  [  744/ 3000]\n",
      "loss: 0.126955  [  752/ 3000]\n",
      "loss: 0.098937  [  760/ 3000]\n",
      "loss: 0.139536  [  768/ 3000]\n",
      "loss: 0.084728  [  776/ 3000]\n",
      "loss: 0.203721  [  784/ 3000]\n",
      "loss: 0.113275  [  792/ 3000]\n",
      "loss: 0.194094  [  800/ 3000]\n",
      "loss: 0.085959  [  808/ 3000]\n",
      "loss: 0.053082  [  816/ 3000]\n",
      "loss: 0.068729  [  824/ 3000]\n",
      "loss: 0.082985  [  832/ 3000]\n",
      "loss: 0.042252  [  840/ 3000]\n",
      "loss: 0.032864  [  848/ 3000]\n",
      "loss: 0.039575  [  856/ 3000]\n",
      "loss: 0.117139  [  864/ 3000]\n",
      "loss: 0.026372  [  872/ 3000]\n",
      "loss: 0.096103  [  880/ 3000]\n",
      "loss: 0.132862  [  888/ 3000]\n",
      "loss: 0.079138  [  896/ 3000]\n",
      "loss: 0.235956  [  904/ 3000]\n",
      "loss: 0.074041  [  912/ 3000]\n",
      "loss: 0.080636  [  920/ 3000]\n",
      "loss: 0.095279  [  928/ 3000]\n",
      "loss: 0.070483  [  936/ 3000]\n",
      "loss: 0.218263  [  944/ 3000]\n",
      "loss: 0.052814  [  952/ 3000]\n",
      "loss: 0.070786  [  960/ 3000]\n",
      "loss: 0.041720  [  968/ 3000]\n",
      "loss: 0.022850  [  976/ 3000]\n",
      "loss: 0.030227  [  984/ 3000]\n",
      "loss: 0.163317  [  992/ 3000]\n",
      "loss: 0.105034  [ 1000/ 3000]\n",
      "loss: 0.083941  [ 1008/ 3000]\n",
      "loss: 0.152674  [ 1016/ 3000]\n",
      "loss: 0.086100  [ 1024/ 3000]\n",
      "loss: 0.136185  [ 1032/ 3000]\n",
      "loss: 0.028629  [ 1040/ 3000]\n",
      "loss: 0.061428  [ 1048/ 3000]\n",
      "loss: 0.034751  [ 1056/ 3000]\n",
      "loss: 0.098035  [ 1064/ 3000]\n",
      "loss: 0.064209  [ 1072/ 3000]\n",
      "loss: 0.070360  [ 1080/ 3000]\n",
      "loss: 0.144093  [ 1088/ 3000]\n",
      "loss: 0.119813  [ 1096/ 3000]\n",
      "loss: 0.037067  [ 1104/ 3000]\n",
      "loss: 0.136988  [ 1112/ 3000]\n",
      "loss: 0.047035  [ 1120/ 3000]\n",
      "loss: 0.062657  [ 1128/ 3000]\n",
      "loss: 0.074956  [ 1136/ 3000]\n",
      "loss: 0.168243  [ 1144/ 3000]\n",
      "loss: 0.058045  [ 1152/ 3000]\n",
      "loss: 0.041935  [ 1160/ 3000]\n",
      "loss: 0.052256  [ 1168/ 3000]\n",
      "loss: 0.045173  [ 1176/ 3000]\n",
      "loss: 0.211643  [ 1184/ 3000]\n",
      "loss: 0.080233  [ 1192/ 3000]\n",
      "loss: 0.076199  [ 1200/ 3000]\n",
      "loss: 0.055520  [ 1208/ 3000]\n",
      "loss: 0.074892  [ 1216/ 3000]\n",
      "loss: 0.113932  [ 1224/ 3000]\n",
      "loss: 0.126898  [ 1232/ 3000]\n",
      "loss: 0.108377  [ 1240/ 3000]\n",
      "loss: 0.125806  [ 1248/ 3000]\n",
      "loss: 0.022300  [ 1256/ 3000]\n",
      "loss: 0.059920  [ 1264/ 3000]\n",
      "loss: 0.039786  [ 1272/ 3000]\n",
      "loss: 0.061403  [ 1280/ 3000]\n",
      "loss: 0.107336  [ 1288/ 3000]\n",
      "loss: 0.044606  [ 1296/ 3000]\n",
      "loss: 0.010350  [ 1304/ 3000]\n",
      "loss: 0.134761  [ 1312/ 3000]\n",
      "loss: 0.324683  [ 1320/ 3000]\n",
      "loss: 0.139470  [ 1328/ 3000]\n",
      "loss: 0.095574  [ 1336/ 3000]\n",
      "loss: 0.173470  [ 1344/ 3000]\n",
      "loss: 0.101954  [ 1352/ 3000]\n",
      "loss: 0.059707  [ 1360/ 3000]\n",
      "loss: 0.150343  [ 1368/ 3000]\n",
      "loss: 0.164237  [ 1376/ 3000]\n",
      "loss: 0.102120  [ 1384/ 3000]\n",
      "loss: 0.061602  [ 1392/ 3000]\n",
      "loss: 0.117602  [ 1400/ 3000]\n",
      "loss: 0.105255  [ 1408/ 3000]\n",
      "loss: 0.116227  [ 1416/ 3000]\n",
      "loss: 0.146982  [ 1424/ 3000]\n",
      "loss: 0.089591  [ 1432/ 3000]\n",
      "loss: 0.053066  [ 1440/ 3000]\n",
      "loss: 0.055271  [ 1448/ 3000]\n",
      "loss: 0.090841  [ 1456/ 3000]\n",
      "loss: 0.014685  [ 1464/ 3000]\n",
      "loss: 0.058706  [ 1472/ 3000]\n",
      "loss: 0.032273  [ 1480/ 3000]\n",
      "loss: 0.151494  [ 1488/ 3000]\n",
      "loss: 0.046027  [ 1496/ 3000]\n",
      "loss: 0.076159  [ 1504/ 3000]\n",
      "loss: 0.101063  [ 1512/ 3000]\n",
      "loss: 0.106515  [ 1520/ 3000]\n",
      "loss: 0.051959  [ 1528/ 3000]\n",
      "loss: 0.103804  [ 1536/ 3000]\n",
      "loss: 0.055133  [ 1544/ 3000]\n",
      "loss: 0.142103  [ 1552/ 3000]\n",
      "loss: 0.062230  [ 1560/ 3000]\n",
      "loss: 0.058499  [ 1568/ 3000]\n",
      "loss: 0.043586  [ 1576/ 3000]\n",
      "loss: 0.127225  [ 1584/ 3000]\n",
      "loss: 0.068143  [ 1592/ 3000]\n",
      "loss: 0.120693  [ 1600/ 3000]\n",
      "loss: 0.055682  [ 1608/ 3000]\n",
      "loss: 0.161558  [ 1616/ 3000]\n",
      "loss: 0.132362  [ 1624/ 3000]\n",
      "loss: 0.059604  [ 1632/ 3000]\n",
      "loss: 0.063625  [ 1640/ 3000]\n",
      "loss: 0.142790  [ 1648/ 3000]\n",
      "loss: 0.048055  [ 1656/ 3000]\n",
      "loss: 0.171453  [ 1664/ 3000]\n",
      "loss: 0.038609  [ 1672/ 3000]\n",
      "loss: 0.063909  [ 1680/ 3000]\n",
      "loss: 0.081459  [ 1688/ 3000]\n",
      "loss: 0.117346  [ 1696/ 3000]\n",
      "loss: 0.073934  [ 1704/ 3000]\n",
      "loss: 0.035725  [ 1712/ 3000]\n",
      "loss: 0.062291  [ 1720/ 3000]\n",
      "loss: 0.075760  [ 1728/ 3000]\n",
      "loss: 0.105165  [ 1736/ 3000]\n",
      "loss: 0.096310  [ 1744/ 3000]\n",
      "loss: 0.027645  [ 1752/ 3000]\n",
      "loss: 0.018804  [ 1760/ 3000]\n",
      "loss: 0.148805  [ 1768/ 3000]\n",
      "loss: 0.088504  [ 1776/ 3000]\n",
      "loss: 0.042174  [ 1784/ 3000]\n",
      "loss: 0.061492  [ 1792/ 3000]\n",
      "loss: 0.124474  [ 1800/ 3000]\n",
      "loss: 0.163310  [ 1808/ 3000]\n",
      "loss: 0.048416  [ 1816/ 3000]\n",
      "loss: 0.152486  [ 1824/ 3000]\n",
      "loss: 0.015860  [ 1832/ 3000]\n",
      "loss: 0.013914  [ 1840/ 3000]\n",
      "loss: 0.077986  [ 1848/ 3000]\n",
      "loss: 0.098806  [ 1856/ 3000]\n",
      "loss: 0.099591  [ 1864/ 3000]\n",
      "loss: 0.087827  [ 1872/ 3000]\n",
      "loss: 0.023206  [ 1880/ 3000]\n",
      "loss: 0.034357  [ 1888/ 3000]\n",
      "loss: 0.097286  [ 1896/ 3000]\n",
      "loss: 0.037532  [ 1904/ 3000]\n",
      "loss: 0.057642  [ 1912/ 3000]\n",
      "loss: 0.123593  [ 1920/ 3000]\n",
      "loss: 0.104490  [ 1928/ 3000]\n",
      "loss: 0.164403  [ 1936/ 3000]\n",
      "loss: 0.028163  [ 1944/ 3000]\n",
      "loss: 0.110915  [ 1952/ 3000]\n",
      "loss: 0.040026  [ 1960/ 3000]\n",
      "loss: 0.132845  [ 1968/ 3000]\n",
      "loss: 0.045914  [ 1976/ 3000]\n",
      "loss: 0.141563  [ 1984/ 3000]\n",
      "loss: 0.148580  [ 1992/ 3000]\n",
      "loss: 0.091904  [ 2000/ 3000]\n",
      "loss: 0.122262  [ 2008/ 3000]\n",
      "loss: 0.083644  [ 2016/ 3000]\n",
      "loss: 0.070518  [ 2024/ 3000]\n",
      "loss: 0.120546  [ 2032/ 3000]\n",
      "loss: 0.100294  [ 2040/ 3000]\n",
      "loss: 0.049153  [ 2048/ 3000]\n",
      "loss: 0.054414  [ 2056/ 3000]\n",
      "loss: 0.042864  [ 2064/ 3000]\n",
      "loss: 0.146350  [ 2072/ 3000]\n",
      "loss: 0.064384  [ 2080/ 3000]\n",
      "loss: 0.137031  [ 2088/ 3000]\n",
      "loss: 0.094376  [ 2096/ 3000]\n",
      "loss: 0.058968  [ 2104/ 3000]\n",
      "loss: 0.037573  [ 2112/ 3000]\n",
      "loss: 0.025386  [ 2120/ 3000]\n",
      "loss: 0.080286  [ 2128/ 3000]\n",
      "loss: 0.082352  [ 2136/ 3000]\n",
      "loss: 0.126648  [ 2144/ 3000]\n",
      "loss: 0.152055  [ 2152/ 3000]\n",
      "loss: 0.036549  [ 2160/ 3000]\n",
      "loss: 0.085144  [ 2168/ 3000]\n",
      "loss: 0.040146  [ 2176/ 3000]\n",
      "loss: 0.109668  [ 2184/ 3000]\n",
      "loss: 0.102057  [ 2192/ 3000]\n",
      "loss: 0.041712  [ 2200/ 3000]\n",
      "loss: 0.028615  [ 2208/ 3000]\n",
      "loss: 0.052196  [ 2216/ 3000]\n",
      "loss: 0.120487  [ 2224/ 3000]\n",
      "loss: 0.090657  [ 2232/ 3000]\n",
      "loss: 0.143245  [ 2240/ 3000]\n",
      "loss: 0.020345  [ 2248/ 3000]\n",
      "loss: 0.084063  [ 2256/ 3000]\n",
      "loss: 0.032994  [ 2264/ 3000]\n",
      "loss: 0.148479  [ 2272/ 3000]\n",
      "loss: 0.055467  [ 2280/ 3000]\n",
      "loss: 0.151485  [ 2288/ 3000]\n",
      "loss: 0.081297  [ 2296/ 3000]\n",
      "loss: 0.059526  [ 2304/ 3000]\n",
      "loss: 0.037603  [ 2312/ 3000]\n",
      "loss: 0.033700  [ 2320/ 3000]\n",
      "loss: 0.098083  [ 2328/ 3000]\n",
      "loss: 0.023063  [ 2336/ 3000]\n",
      "loss: 0.133180  [ 2344/ 3000]\n",
      "loss: 0.150475  [ 2352/ 3000]\n",
      "loss: 0.113193  [ 2360/ 3000]\n",
      "loss: 0.062197  [ 2368/ 3000]\n",
      "loss: 0.037390  [ 2376/ 3000]\n",
      "loss: 0.066393  [ 2384/ 3000]\n",
      "loss: 0.067391  [ 2392/ 3000]\n",
      "loss: 0.020476  [ 2400/ 3000]\n",
      "loss: 0.142824  [ 2408/ 3000]\n",
      "loss: 0.092608  [ 2416/ 3000]\n",
      "loss: 0.103204  [ 2424/ 3000]\n",
      "loss: 0.117738  [ 2432/ 3000]\n",
      "loss: 0.064218  [ 2440/ 3000]\n",
      "loss: 0.138899  [ 2448/ 3000]\n",
      "loss: 0.139531  [ 2456/ 3000]\n",
      "loss: 0.065545  [ 2464/ 3000]\n",
      "loss: 0.257795  [ 2472/ 3000]\n",
      "loss: 0.035802  [ 2480/ 3000]\n",
      "loss: 0.074163  [ 2488/ 3000]\n",
      "loss: 0.028448  [ 2496/ 3000]\n",
      "loss: 0.052295  [ 2504/ 3000]\n",
      "loss: 0.149839  [ 2512/ 3000]\n",
      "loss: 0.242016  [ 2520/ 3000]\n",
      "loss: 0.049363  [ 2528/ 3000]\n",
      "loss: 0.078100  [ 2536/ 3000]\n",
      "loss: 0.032068  [ 2544/ 3000]\n",
      "loss: 0.116958  [ 2552/ 3000]\n",
      "loss: 0.102625  [ 2560/ 3000]\n",
      "loss: 0.155107  [ 2568/ 3000]\n",
      "loss: 0.138395  [ 2576/ 3000]\n",
      "loss: 0.085334  [ 2584/ 3000]\n",
      "loss: 0.068223  [ 2592/ 3000]\n",
      "loss: 0.081711  [ 2600/ 3000]\n",
      "loss: 0.105339  [ 2608/ 3000]\n",
      "loss: 0.045593  [ 2616/ 3000]\n",
      "loss: 0.049298  [ 2624/ 3000]\n",
      "loss: 0.126278  [ 2632/ 3000]\n",
      "loss: 0.147982  [ 2640/ 3000]\n",
      "loss: 0.098204  [ 2648/ 3000]\n",
      "loss: 0.107702  [ 2656/ 3000]\n",
      "loss: 0.074435  [ 2664/ 3000]\n",
      "loss: 0.132017  [ 2672/ 3000]\n",
      "loss: 0.150943  [ 2680/ 3000]\n",
      "loss: 0.066667  [ 2688/ 3000]\n",
      "loss: 0.054844  [ 2696/ 3000]\n",
      "loss: 0.096636  [ 2704/ 3000]\n",
      "loss: 0.112218  [ 2712/ 3000]\n",
      "loss: 0.079750  [ 2720/ 3000]\n",
      "loss: 0.141330  [ 2728/ 3000]\n",
      "loss: 0.040244  [ 2736/ 3000]\n",
      "loss: 0.090403  [ 2744/ 3000]\n",
      "loss: 0.113635  [ 2752/ 3000]\n",
      "loss: 0.076906  [ 2760/ 3000]\n",
      "loss: 0.032147  [ 2768/ 3000]\n",
      "loss: 0.146204  [ 2776/ 3000]\n",
      "loss: 0.090283  [ 2784/ 3000]\n",
      "loss: 0.061733  [ 2792/ 3000]\n",
      "loss: 0.128179  [ 2800/ 3000]\n",
      "loss: 0.179632  [ 2808/ 3000]\n",
      "loss: 0.090899  [ 2816/ 3000]\n",
      "loss: 0.095904  [ 2824/ 3000]\n",
      "loss: 0.103159  [ 2832/ 3000]\n",
      "loss: 0.074687  [ 2840/ 3000]\n",
      "loss: 0.077398  [ 2848/ 3000]\n",
      "loss: 0.104735  [ 2856/ 3000]\n",
      "loss: 0.051360  [ 2864/ 3000]\n",
      "loss: 0.107363  [ 2872/ 3000]\n",
      "loss: 0.136590  [ 2880/ 3000]\n",
      "loss: 0.031983  [ 2888/ 3000]\n",
      "loss: 0.023800  [ 2896/ 3000]\n",
      "loss: 0.098031  [ 2904/ 3000]\n",
      "loss: 0.115632  [ 2912/ 3000]\n",
      "loss: 0.082807  [ 2920/ 3000]\n",
      "loss: 0.139585  [ 2928/ 3000]\n",
      "loss: 0.213230  [ 2936/ 3000]\n",
      "loss: 0.043917  [ 2944/ 3000]\n",
      "loss: 0.009735  [ 2952/ 3000]\n",
      "loss: 0.040382  [ 2960/ 3000]\n",
      "loss: 0.072488  [ 2968/ 3000]\n",
      "loss: 0.064501  [ 2976/ 3000]\n",
      "loss: 0.077365  [ 2984/ 3000]\n",
      "loss: 0.021845  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.093783 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.043839  [    0/ 3000]\n",
      "loss: 0.095190  [    8/ 3000]\n",
      "loss: 0.043573  [   16/ 3000]\n",
      "loss: 0.049279  [   24/ 3000]\n",
      "loss: 0.144299  [   32/ 3000]\n",
      "loss: 0.031850  [   40/ 3000]\n",
      "loss: 0.033400  [   48/ 3000]\n",
      "loss: 0.093866  [   56/ 3000]\n",
      "loss: 0.187539  [   64/ 3000]\n",
      "loss: 0.029709  [   72/ 3000]\n",
      "loss: 0.170855  [   80/ 3000]\n",
      "loss: 0.108657  [   88/ 3000]\n",
      "loss: 0.134509  [   96/ 3000]\n",
      "loss: 0.078160  [  104/ 3000]\n",
      "loss: 0.192370  [  112/ 3000]\n",
      "loss: 0.053725  [  120/ 3000]\n",
      "loss: 0.045205  [  128/ 3000]\n",
      "loss: 0.116868  [  136/ 3000]\n",
      "loss: 0.101922  [  144/ 3000]\n",
      "loss: 0.059537  [  152/ 3000]\n",
      "loss: 0.032485  [  160/ 3000]\n",
      "loss: 0.022949  [  168/ 3000]\n",
      "loss: 0.049606  [  176/ 3000]\n",
      "loss: 0.111289  [  184/ 3000]\n",
      "loss: 0.079857  [  192/ 3000]\n",
      "loss: 0.053685  [  200/ 3000]\n",
      "loss: 0.187483  [  208/ 3000]\n",
      "loss: 0.056249  [  216/ 3000]\n",
      "loss: 0.072931  [  224/ 3000]\n",
      "loss: 0.162823  [  232/ 3000]\n",
      "loss: 0.077927  [  240/ 3000]\n",
      "loss: 0.059791  [  248/ 3000]\n",
      "loss: 0.042768  [  256/ 3000]\n",
      "loss: 0.116762  [  264/ 3000]\n",
      "loss: 0.061753  [  272/ 3000]\n",
      "loss: 0.189581  [  280/ 3000]\n",
      "loss: 0.040383  [  288/ 3000]\n",
      "loss: 0.070565  [  296/ 3000]\n",
      "loss: 0.054023  [  304/ 3000]\n",
      "loss: 0.132796  [  312/ 3000]\n",
      "loss: 0.068002  [  320/ 3000]\n",
      "loss: 0.180718  [  328/ 3000]\n",
      "loss: 0.067882  [  336/ 3000]\n",
      "loss: 0.099304  [  344/ 3000]\n",
      "loss: 0.033950  [  352/ 3000]\n",
      "loss: 0.042116  [  360/ 3000]\n",
      "loss: 0.148370  [  368/ 3000]\n",
      "loss: 0.037911  [  376/ 3000]\n",
      "loss: 0.115542  [  384/ 3000]\n",
      "loss: 0.074883  [  392/ 3000]\n",
      "loss: 0.119928  [  400/ 3000]\n",
      "loss: 0.047888  [  408/ 3000]\n",
      "loss: 0.128027  [  416/ 3000]\n",
      "loss: 0.068881  [  424/ 3000]\n",
      "loss: 0.202759  [  432/ 3000]\n",
      "loss: 0.054861  [  440/ 3000]\n",
      "loss: 0.101101  [  448/ 3000]\n",
      "loss: 0.066453  [  456/ 3000]\n",
      "loss: 0.151687  [  464/ 3000]\n",
      "loss: 0.076537  [  472/ 3000]\n",
      "loss: 0.026472  [  480/ 3000]\n",
      "loss: 0.159071  [  488/ 3000]\n",
      "loss: 0.107430  [  496/ 3000]\n",
      "loss: 0.059709  [  504/ 3000]\n",
      "loss: 0.086617  [  512/ 3000]\n",
      "loss: 0.054278  [  520/ 3000]\n",
      "loss: 0.243915  [  528/ 3000]\n",
      "loss: 0.124411  [  536/ 3000]\n",
      "loss: 0.114052  [  544/ 3000]\n",
      "loss: 0.076533  [  552/ 3000]\n",
      "loss: 0.058728  [  560/ 3000]\n",
      "loss: 0.115185  [  568/ 3000]\n",
      "loss: 0.081532  [  576/ 3000]\n",
      "loss: 0.093871  [  584/ 3000]\n",
      "loss: 0.049792  [  592/ 3000]\n",
      "loss: 0.183200  [  600/ 3000]\n",
      "loss: 0.048947  [  608/ 3000]\n",
      "loss: 0.120753  [  616/ 3000]\n",
      "loss: 0.083062  [  624/ 3000]\n",
      "loss: 0.216818  [  632/ 3000]\n",
      "loss: 0.030967  [  640/ 3000]\n",
      "loss: 0.176135  [  648/ 3000]\n",
      "loss: 0.239316  [  656/ 3000]\n",
      "loss: 0.191531  [  664/ 3000]\n",
      "loss: 0.090958  [  672/ 3000]\n",
      "loss: 0.100676  [  680/ 3000]\n",
      "loss: 0.072474  [  688/ 3000]\n",
      "loss: 0.211846  [  696/ 3000]\n",
      "loss: 0.080730  [  704/ 3000]\n",
      "loss: 0.065952  [  712/ 3000]\n",
      "loss: 0.072958  [  720/ 3000]\n",
      "loss: 0.047469  [  728/ 3000]\n",
      "loss: 0.077628  [  736/ 3000]\n",
      "loss: 0.056243  [  744/ 3000]\n",
      "loss: 0.122817  [  752/ 3000]\n",
      "loss: 0.095034  [  760/ 3000]\n",
      "loss: 0.138690  [  768/ 3000]\n",
      "loss: 0.082172  [  776/ 3000]\n",
      "loss: 0.197607  [  784/ 3000]\n",
      "loss: 0.109569  [  792/ 3000]\n",
      "loss: 0.191082  [  800/ 3000]\n",
      "loss: 0.082504  [  808/ 3000]\n",
      "loss: 0.050355  [  816/ 3000]\n",
      "loss: 0.066801  [  824/ 3000]\n",
      "loss: 0.079919  [  832/ 3000]\n",
      "loss: 0.040030  [  840/ 3000]\n",
      "loss: 0.030961  [  848/ 3000]\n",
      "loss: 0.038221  [  856/ 3000]\n",
      "loss: 0.113732  [  864/ 3000]\n",
      "loss: 0.024645  [  872/ 3000]\n",
      "loss: 0.095324  [  880/ 3000]\n",
      "loss: 0.128322  [  888/ 3000]\n",
      "loss: 0.077918  [  896/ 3000]\n",
      "loss: 0.231576  [  904/ 3000]\n",
      "loss: 0.071914  [  912/ 3000]\n",
      "loss: 0.079102  [  920/ 3000]\n",
      "loss: 0.092879  [  928/ 3000]\n",
      "loss: 0.068076  [  936/ 3000]\n",
      "loss: 0.213756  [  944/ 3000]\n",
      "loss: 0.050687  [  952/ 3000]\n",
      "loss: 0.068108  [  960/ 3000]\n",
      "loss: 0.039755  [  968/ 3000]\n",
      "loss: 0.021538  [  976/ 3000]\n",
      "loss: 0.028070  [  984/ 3000]\n",
      "loss: 0.158830  [  992/ 3000]\n",
      "loss: 0.101122  [ 1000/ 3000]\n",
      "loss: 0.081996  [ 1008/ 3000]\n",
      "loss: 0.149316  [ 1016/ 3000]\n",
      "loss: 0.083656  [ 1024/ 3000]\n",
      "loss: 0.133121  [ 1032/ 3000]\n",
      "loss: 0.027286  [ 1040/ 3000]\n",
      "loss: 0.059407  [ 1048/ 3000]\n",
      "loss: 0.033560  [ 1056/ 3000]\n",
      "loss: 0.096350  [ 1064/ 3000]\n",
      "loss: 0.062231  [ 1072/ 3000]\n",
      "loss: 0.068634  [ 1080/ 3000]\n",
      "loss: 0.139337  [ 1088/ 3000]\n",
      "loss: 0.117300  [ 1096/ 3000]\n",
      "loss: 0.034847  [ 1104/ 3000]\n",
      "loss: 0.134031  [ 1112/ 3000]\n",
      "loss: 0.045326  [ 1120/ 3000]\n",
      "loss: 0.060957  [ 1128/ 3000]\n",
      "loss: 0.071244  [ 1136/ 3000]\n",
      "loss: 0.164819  [ 1144/ 3000]\n",
      "loss: 0.055715  [ 1152/ 3000]\n",
      "loss: 0.040549  [ 1160/ 3000]\n",
      "loss: 0.049713  [ 1168/ 3000]\n",
      "loss: 0.042992  [ 1176/ 3000]\n",
      "loss: 0.207801  [ 1184/ 3000]\n",
      "loss: 0.077877  [ 1192/ 3000]\n",
      "loss: 0.072655  [ 1200/ 3000]\n",
      "loss: 0.053150  [ 1208/ 3000]\n",
      "loss: 0.071970  [ 1216/ 3000]\n",
      "loss: 0.110079  [ 1224/ 3000]\n",
      "loss: 0.123070  [ 1232/ 3000]\n",
      "loss: 0.105835  [ 1240/ 3000]\n",
      "loss: 0.121992  [ 1248/ 3000]\n",
      "loss: 0.021181  [ 1256/ 3000]\n",
      "loss: 0.058568  [ 1264/ 3000]\n",
      "loss: 0.037971  [ 1272/ 3000]\n",
      "loss: 0.057459  [ 1280/ 3000]\n",
      "loss: 0.102616  [ 1288/ 3000]\n",
      "loss: 0.042519  [ 1296/ 3000]\n",
      "loss: 0.009274  [ 1304/ 3000]\n",
      "loss: 0.130812  [ 1312/ 3000]\n",
      "loss: 0.318025  [ 1320/ 3000]\n",
      "loss: 0.135080  [ 1328/ 3000]\n",
      "loss: 0.092917  [ 1336/ 3000]\n",
      "loss: 0.168600  [ 1344/ 3000]\n",
      "loss: 0.100036  [ 1352/ 3000]\n",
      "loss: 0.056158  [ 1360/ 3000]\n",
      "loss: 0.146073  [ 1368/ 3000]\n",
      "loss: 0.160258  [ 1376/ 3000]\n",
      "loss: 0.097491  [ 1384/ 3000]\n",
      "loss: 0.059128  [ 1392/ 3000]\n",
      "loss: 0.114122  [ 1400/ 3000]\n",
      "loss: 0.102742  [ 1408/ 3000]\n",
      "loss: 0.112327  [ 1416/ 3000]\n",
      "loss: 0.144509  [ 1424/ 3000]\n",
      "loss: 0.086482  [ 1432/ 3000]\n",
      "loss: 0.051188  [ 1440/ 3000]\n",
      "loss: 0.052672  [ 1448/ 3000]\n",
      "loss: 0.087414  [ 1456/ 3000]\n",
      "loss: 0.013821  [ 1464/ 3000]\n",
      "loss: 0.057504  [ 1472/ 3000]\n",
      "loss: 0.030717  [ 1480/ 3000]\n",
      "loss: 0.149953  [ 1488/ 3000]\n",
      "loss: 0.043938  [ 1496/ 3000]\n",
      "loss: 0.073312  [ 1504/ 3000]\n",
      "loss: 0.100170  [ 1512/ 3000]\n",
      "loss: 0.102830  [ 1520/ 3000]\n",
      "loss: 0.048712  [ 1528/ 3000]\n",
      "loss: 0.101201  [ 1536/ 3000]\n",
      "loss: 0.052849  [ 1544/ 3000]\n",
      "loss: 0.138797  [ 1552/ 3000]\n",
      "loss: 0.060444  [ 1560/ 3000]\n",
      "loss: 0.056216  [ 1568/ 3000]\n",
      "loss: 0.040857  [ 1576/ 3000]\n",
      "loss: 0.123785  [ 1584/ 3000]\n",
      "loss: 0.067077  [ 1592/ 3000]\n",
      "loss: 0.117323  [ 1600/ 3000]\n",
      "loss: 0.053340  [ 1608/ 3000]\n",
      "loss: 0.158479  [ 1616/ 3000]\n",
      "loss: 0.129828  [ 1624/ 3000]\n",
      "loss: 0.058304  [ 1632/ 3000]\n",
      "loss: 0.062028  [ 1640/ 3000]\n",
      "loss: 0.141010  [ 1648/ 3000]\n",
      "loss: 0.046771  [ 1656/ 3000]\n",
      "loss: 0.165058  [ 1664/ 3000]\n",
      "loss: 0.036609  [ 1672/ 3000]\n",
      "loss: 0.061940  [ 1680/ 3000]\n",
      "loss: 0.079186  [ 1688/ 3000]\n",
      "loss: 0.113337  [ 1696/ 3000]\n",
      "loss: 0.071182  [ 1704/ 3000]\n",
      "loss: 0.033976  [ 1712/ 3000]\n",
      "loss: 0.058750  [ 1720/ 3000]\n",
      "loss: 0.073302  [ 1728/ 3000]\n",
      "loss: 0.103223  [ 1736/ 3000]\n",
      "loss: 0.093775  [ 1744/ 3000]\n",
      "loss: 0.026323  [ 1752/ 3000]\n",
      "loss: 0.017200  [ 1760/ 3000]\n",
      "loss: 0.144032  [ 1768/ 3000]\n",
      "loss: 0.085674  [ 1776/ 3000]\n",
      "loss: 0.040034  [ 1784/ 3000]\n",
      "loss: 0.059946  [ 1792/ 3000]\n",
      "loss: 0.120741  [ 1800/ 3000]\n",
      "loss: 0.158907  [ 1808/ 3000]\n",
      "loss: 0.047397  [ 1816/ 3000]\n",
      "loss: 0.149799  [ 1824/ 3000]\n",
      "loss: 0.014248  [ 1832/ 3000]\n",
      "loss: 0.013382  [ 1840/ 3000]\n",
      "loss: 0.074392  [ 1848/ 3000]\n",
      "loss: 0.096506  [ 1856/ 3000]\n",
      "loss: 0.097155  [ 1864/ 3000]\n",
      "loss: 0.085155  [ 1872/ 3000]\n",
      "loss: 0.021918  [ 1880/ 3000]\n",
      "loss: 0.032523  [ 1888/ 3000]\n",
      "loss: 0.093446  [ 1896/ 3000]\n",
      "loss: 0.036658  [ 1904/ 3000]\n",
      "loss: 0.054847  [ 1912/ 3000]\n",
      "loss: 0.120782  [ 1920/ 3000]\n",
      "loss: 0.101680  [ 1928/ 3000]\n",
      "loss: 0.160088  [ 1936/ 3000]\n",
      "loss: 0.025926  [ 1944/ 3000]\n",
      "loss: 0.108348  [ 1952/ 3000]\n",
      "loss: 0.039142  [ 1960/ 3000]\n",
      "loss: 0.129229  [ 1968/ 3000]\n",
      "loss: 0.044077  [ 1976/ 3000]\n",
      "loss: 0.138821  [ 1984/ 3000]\n",
      "loss: 0.146090  [ 1992/ 3000]\n",
      "loss: 0.088697  [ 2000/ 3000]\n",
      "loss: 0.119361  [ 2008/ 3000]\n",
      "loss: 0.080267  [ 2016/ 3000]\n",
      "loss: 0.068704  [ 2024/ 3000]\n",
      "loss: 0.117104  [ 2032/ 3000]\n",
      "loss: 0.097374  [ 2040/ 3000]\n",
      "loss: 0.047429  [ 2048/ 3000]\n",
      "loss: 0.052074  [ 2056/ 3000]\n",
      "loss: 0.040865  [ 2064/ 3000]\n",
      "loss: 0.141300  [ 2072/ 3000]\n",
      "loss: 0.062271  [ 2080/ 3000]\n",
      "loss: 0.132489  [ 2088/ 3000]\n",
      "loss: 0.091899  [ 2096/ 3000]\n",
      "loss: 0.057772  [ 2104/ 3000]\n",
      "loss: 0.036352  [ 2112/ 3000]\n",
      "loss: 0.023770  [ 2120/ 3000]\n",
      "loss: 0.078362  [ 2128/ 3000]\n",
      "loss: 0.080056  [ 2136/ 3000]\n",
      "loss: 0.123182  [ 2144/ 3000]\n",
      "loss: 0.149343  [ 2152/ 3000]\n",
      "loss: 0.035056  [ 2160/ 3000]\n",
      "loss: 0.082535  [ 2168/ 3000]\n",
      "loss: 0.037920  [ 2176/ 3000]\n",
      "loss: 0.107377  [ 2184/ 3000]\n",
      "loss: 0.098511  [ 2192/ 3000]\n",
      "loss: 0.040533  [ 2200/ 3000]\n",
      "loss: 0.027329  [ 2208/ 3000]\n",
      "loss: 0.049738  [ 2216/ 3000]\n",
      "loss: 0.118007  [ 2224/ 3000]\n",
      "loss: 0.088926  [ 2232/ 3000]\n",
      "loss: 0.139892  [ 2240/ 3000]\n",
      "loss: 0.019165  [ 2248/ 3000]\n",
      "loss: 0.080170  [ 2256/ 3000]\n",
      "loss: 0.031413  [ 2264/ 3000]\n",
      "loss: 0.146868  [ 2272/ 3000]\n",
      "loss: 0.053569  [ 2280/ 3000]\n",
      "loss: 0.147287  [ 2288/ 3000]\n",
      "loss: 0.079425  [ 2296/ 3000]\n",
      "loss: 0.058966  [ 2304/ 3000]\n",
      "loss: 0.036382  [ 2312/ 3000]\n",
      "loss: 0.032193  [ 2320/ 3000]\n",
      "loss: 0.095461  [ 2328/ 3000]\n",
      "loss: 0.021697  [ 2336/ 3000]\n",
      "loss: 0.130917  [ 2344/ 3000]\n",
      "loss: 0.145159  [ 2352/ 3000]\n",
      "loss: 0.111880  [ 2360/ 3000]\n",
      "loss: 0.059538  [ 2368/ 3000]\n",
      "loss: 0.036200  [ 2376/ 3000]\n",
      "loss: 0.064898  [ 2384/ 3000]\n",
      "loss: 0.066101  [ 2392/ 3000]\n",
      "loss: 0.018523  [ 2400/ 3000]\n",
      "loss: 0.139311  [ 2408/ 3000]\n",
      "loss: 0.091243  [ 2416/ 3000]\n",
      "loss: 0.100593  [ 2424/ 3000]\n",
      "loss: 0.113915  [ 2432/ 3000]\n",
      "loss: 0.062575  [ 2440/ 3000]\n",
      "loss: 0.135550  [ 2448/ 3000]\n",
      "loss: 0.136140  [ 2456/ 3000]\n",
      "loss: 0.063184  [ 2464/ 3000]\n",
      "loss: 0.255095  [ 2472/ 3000]\n",
      "loss: 0.034382  [ 2480/ 3000]\n",
      "loss: 0.071404  [ 2488/ 3000]\n",
      "loss: 0.026521  [ 2496/ 3000]\n",
      "loss: 0.049957  [ 2504/ 3000]\n",
      "loss: 0.145320  [ 2512/ 3000]\n",
      "loss: 0.238670  [ 2520/ 3000]\n",
      "loss: 0.046962  [ 2528/ 3000]\n",
      "loss: 0.075830  [ 2536/ 3000]\n",
      "loss: 0.029677  [ 2544/ 3000]\n",
      "loss: 0.113971  [ 2552/ 3000]\n",
      "loss: 0.101152  [ 2560/ 3000]\n",
      "loss: 0.151966  [ 2568/ 3000]\n",
      "loss: 0.135762  [ 2576/ 3000]\n",
      "loss: 0.082160  [ 2584/ 3000]\n",
      "loss: 0.065338  [ 2592/ 3000]\n",
      "loss: 0.080324  [ 2600/ 3000]\n",
      "loss: 0.102529  [ 2608/ 3000]\n",
      "loss: 0.043614  [ 2616/ 3000]\n",
      "loss: 0.046857  [ 2624/ 3000]\n",
      "loss: 0.124410  [ 2632/ 3000]\n",
      "loss: 0.144642  [ 2640/ 3000]\n",
      "loss: 0.095705  [ 2648/ 3000]\n",
      "loss: 0.104509  [ 2656/ 3000]\n",
      "loss: 0.071838  [ 2664/ 3000]\n",
      "loss: 0.128679  [ 2672/ 3000]\n",
      "loss: 0.146969  [ 2680/ 3000]\n",
      "loss: 0.064361  [ 2688/ 3000]\n",
      "loss: 0.052677  [ 2696/ 3000]\n",
      "loss: 0.094782  [ 2704/ 3000]\n",
      "loss: 0.107518  [ 2712/ 3000]\n",
      "loss: 0.076949  [ 2720/ 3000]\n",
      "loss: 0.137339  [ 2728/ 3000]\n",
      "loss: 0.038899  [ 2736/ 3000]\n",
      "loss: 0.087107  [ 2744/ 3000]\n",
      "loss: 0.110021  [ 2752/ 3000]\n",
      "loss: 0.074781  [ 2760/ 3000]\n",
      "loss: 0.030452  [ 2768/ 3000]\n",
      "loss: 0.142060  [ 2776/ 3000]\n",
      "loss: 0.088292  [ 2784/ 3000]\n",
      "loss: 0.059008  [ 2792/ 3000]\n",
      "loss: 0.124913  [ 2800/ 3000]\n",
      "loss: 0.176535  [ 2808/ 3000]\n",
      "loss: 0.087581  [ 2816/ 3000]\n",
      "loss: 0.094028  [ 2824/ 3000]\n",
      "loss: 0.100103  [ 2832/ 3000]\n",
      "loss: 0.072373  [ 2840/ 3000]\n",
      "loss: 0.074697  [ 2848/ 3000]\n",
      "loss: 0.101725  [ 2856/ 3000]\n",
      "loss: 0.048749  [ 2864/ 3000]\n",
      "loss: 0.104754  [ 2872/ 3000]\n",
      "loss: 0.132412  [ 2880/ 3000]\n",
      "loss: 0.029554  [ 2888/ 3000]\n",
      "loss: 0.022506  [ 2896/ 3000]\n",
      "loss: 0.093572  [ 2904/ 3000]\n",
      "loss: 0.112788  [ 2912/ 3000]\n",
      "loss: 0.080287  [ 2920/ 3000]\n",
      "loss: 0.135859  [ 2928/ 3000]\n",
      "loss: 0.207751  [ 2936/ 3000]\n",
      "loss: 0.041664  [ 2944/ 3000]\n",
      "loss: 0.008921  [ 2952/ 3000]\n",
      "loss: 0.039091  [ 2960/ 3000]\n",
      "loss: 0.070984  [ 2968/ 3000]\n",
      "loss: 0.063054  [ 2976/ 3000]\n",
      "loss: 0.075767  [ 2984/ 3000]\n",
      "loss: 0.020206  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.092477 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.041410  [    0/ 3000]\n",
      "loss: 0.091728  [    8/ 3000]\n",
      "loss: 0.040489  [   16/ 3000]\n",
      "loss: 0.046977  [   24/ 3000]\n",
      "loss: 0.139863  [   32/ 3000]\n",
      "loss: 0.029838  [   40/ 3000]\n",
      "loss: 0.031978  [   48/ 3000]\n",
      "loss: 0.091411  [   56/ 3000]\n",
      "loss: 0.183662  [   64/ 3000]\n",
      "loss: 0.028630  [   72/ 3000]\n",
      "loss: 0.168011  [   80/ 3000]\n",
      "loss: 0.104713  [   88/ 3000]\n",
      "loss: 0.129874  [   96/ 3000]\n",
      "loss: 0.075371  [  104/ 3000]\n",
      "loss: 0.189325  [  112/ 3000]\n",
      "loss: 0.051536  [  120/ 3000]\n",
      "loss: 0.043489  [  128/ 3000]\n",
      "loss: 0.112697  [  136/ 3000]\n",
      "loss: 0.098829  [  144/ 3000]\n",
      "loss: 0.058027  [  152/ 3000]\n",
      "loss: 0.030792  [  160/ 3000]\n",
      "loss: 0.021475  [  168/ 3000]\n",
      "loss: 0.047194  [  176/ 3000]\n",
      "loss: 0.108708  [  184/ 3000]\n",
      "loss: 0.077352  [  192/ 3000]\n",
      "loss: 0.051518  [  200/ 3000]\n",
      "loss: 0.184524  [  208/ 3000]\n",
      "loss: 0.054533  [  216/ 3000]\n",
      "loss: 0.070355  [  224/ 3000]\n",
      "loss: 0.158211  [  232/ 3000]\n",
      "loss: 0.075189  [  240/ 3000]\n",
      "loss: 0.057654  [  248/ 3000]\n",
      "loss: 0.041014  [  256/ 3000]\n",
      "loss: 0.113269  [  264/ 3000]\n",
      "loss: 0.060132  [  272/ 3000]\n",
      "loss: 0.187656  [  280/ 3000]\n",
      "loss: 0.038519  [  288/ 3000]\n",
      "loss: 0.068703  [  296/ 3000]\n",
      "loss: 0.051978  [  304/ 3000]\n",
      "loss: 0.130394  [  312/ 3000]\n",
      "loss: 0.064991  [  320/ 3000]\n",
      "loss: 0.174897  [  328/ 3000]\n",
      "loss: 0.064317  [  336/ 3000]\n",
      "loss: 0.098380  [  344/ 3000]\n",
      "loss: 0.032257  [  352/ 3000]\n",
      "loss: 0.041300  [  360/ 3000]\n",
      "loss: 0.145779  [  368/ 3000]\n",
      "loss: 0.036268  [  376/ 3000]\n",
      "loss: 0.112079  [  384/ 3000]\n",
      "loss: 0.073354  [  392/ 3000]\n",
      "loss: 0.114936  [  400/ 3000]\n",
      "loss: 0.045637  [  408/ 3000]\n",
      "loss: 0.124035  [  416/ 3000]\n",
      "loss: 0.065938  [  424/ 3000]\n",
      "loss: 0.198864  [  432/ 3000]\n",
      "loss: 0.053517  [  440/ 3000]\n",
      "loss: 0.097578  [  448/ 3000]\n",
      "loss: 0.064229  [  456/ 3000]\n",
      "loss: 0.148181  [  464/ 3000]\n",
      "loss: 0.074997  [  472/ 3000]\n",
      "loss: 0.025101  [  480/ 3000]\n",
      "loss: 0.156655  [  488/ 3000]\n",
      "loss: 0.106275  [  496/ 3000]\n",
      "loss: 0.057913  [  504/ 3000]\n",
      "loss: 0.084315  [  512/ 3000]\n",
      "loss: 0.053152  [  520/ 3000]\n",
      "loss: 0.240041  [  528/ 3000]\n",
      "loss: 0.121403  [  536/ 3000]\n",
      "loss: 0.111147  [  544/ 3000]\n",
      "loss: 0.073530  [  552/ 3000]\n",
      "loss: 0.056341  [  560/ 3000]\n",
      "loss: 0.112489  [  568/ 3000]\n",
      "loss: 0.077921  [  576/ 3000]\n",
      "loss: 0.090004  [  584/ 3000]\n",
      "loss: 0.047888  [  592/ 3000]\n",
      "loss: 0.177542  [  600/ 3000]\n",
      "loss: 0.048214  [  608/ 3000]\n",
      "loss: 0.117530  [  616/ 3000]\n",
      "loss: 0.080417  [  624/ 3000]\n",
      "loss: 0.213993  [  632/ 3000]\n",
      "loss: 0.028836  [  640/ 3000]\n",
      "loss: 0.173401  [  648/ 3000]\n",
      "loss: 0.234596  [  656/ 3000]\n",
      "loss: 0.188183  [  664/ 3000]\n",
      "loss: 0.089089  [  672/ 3000]\n",
      "loss: 0.098822  [  680/ 3000]\n",
      "loss: 0.070260  [  688/ 3000]\n",
      "loss: 0.206648  [  696/ 3000]\n",
      "loss: 0.079064  [  704/ 3000]\n",
      "loss: 0.063562  [  712/ 3000]\n",
      "loss: 0.071521  [  720/ 3000]\n",
      "loss: 0.045947  [  728/ 3000]\n",
      "loss: 0.076137  [  736/ 3000]\n",
      "loss: 0.053209  [  744/ 3000]\n",
      "loss: 0.118881  [  752/ 3000]\n",
      "loss: 0.091433  [  760/ 3000]\n",
      "loss: 0.137628  [  768/ 3000]\n",
      "loss: 0.079743  [  776/ 3000]\n",
      "loss: 0.191718  [  784/ 3000]\n",
      "loss: 0.106090  [  792/ 3000]\n",
      "loss: 0.188327  [  800/ 3000]\n",
      "loss: 0.079316  [  808/ 3000]\n",
      "loss: 0.047917  [  816/ 3000]\n",
      "loss: 0.065076  [  824/ 3000]\n",
      "loss: 0.077264  [  832/ 3000]\n",
      "loss: 0.038017  [  840/ 3000]\n",
      "loss: 0.029247  [  848/ 3000]\n",
      "loss: 0.037100  [  856/ 3000]\n",
      "loss: 0.110437  [  864/ 3000]\n",
      "loss: 0.023139  [  872/ 3000]\n",
      "loss: 0.094357  [  880/ 3000]\n",
      "loss: 0.124087  [  888/ 3000]\n",
      "loss: 0.076861  [  896/ 3000]\n",
      "loss: 0.227385  [  904/ 3000]\n",
      "loss: 0.069905  [  912/ 3000]\n",
      "loss: 0.077546  [  920/ 3000]\n",
      "loss: 0.090720  [  928/ 3000]\n",
      "loss: 0.065739  [  936/ 3000]\n",
      "loss: 0.209205  [  944/ 3000]\n",
      "loss: 0.048664  [  952/ 3000]\n",
      "loss: 0.065707  [  960/ 3000]\n",
      "loss: 0.038093  [  968/ 3000]\n",
      "loss: 0.020411  [  976/ 3000]\n",
      "loss: 0.026178  [  984/ 3000]\n",
      "loss: 0.154587  [  992/ 3000]\n",
      "loss: 0.097796  [ 1000/ 3000]\n",
      "loss: 0.080052  [ 1008/ 3000]\n",
      "loss: 0.146079  [ 1016/ 3000]\n",
      "loss: 0.081375  [ 1024/ 3000]\n",
      "loss: 0.129831  [ 1032/ 3000]\n",
      "loss: 0.026049  [ 1040/ 3000]\n",
      "loss: 0.057628  [ 1048/ 3000]\n",
      "loss: 0.032433  [ 1056/ 3000]\n",
      "loss: 0.094579  [ 1064/ 3000]\n",
      "loss: 0.060354  [ 1072/ 3000]\n",
      "loss: 0.066996  [ 1080/ 3000]\n",
      "loss: 0.134960  [ 1088/ 3000]\n",
      "loss: 0.114937  [ 1096/ 3000]\n",
      "loss: 0.032830  [ 1104/ 3000]\n",
      "loss: 0.131113  [ 1112/ 3000]\n",
      "loss: 0.043710  [ 1120/ 3000]\n",
      "loss: 0.059534  [ 1128/ 3000]\n",
      "loss: 0.067940  [ 1136/ 3000]\n",
      "loss: 0.161380  [ 1144/ 3000]\n",
      "loss: 0.053620  [ 1152/ 3000]\n",
      "loss: 0.039330  [ 1160/ 3000]\n",
      "loss: 0.047424  [ 1168/ 3000]\n",
      "loss: 0.041015  [ 1176/ 3000]\n",
      "loss: 0.204114  [ 1184/ 3000]\n",
      "loss: 0.075650  [ 1192/ 3000]\n",
      "loss: 0.069235  [ 1200/ 3000]\n",
      "loss: 0.051095  [ 1208/ 3000]\n",
      "loss: 0.069308  [ 1216/ 3000]\n",
      "loss: 0.106348  [ 1224/ 3000]\n",
      "loss: 0.119379  [ 1232/ 3000]\n",
      "loss: 0.103364  [ 1240/ 3000]\n",
      "loss: 0.118341  [ 1248/ 3000]\n",
      "loss: 0.020199  [ 1256/ 3000]\n",
      "loss: 0.057399  [ 1264/ 3000]\n",
      "loss: 0.036384  [ 1272/ 3000]\n",
      "loss: 0.053936  [ 1280/ 3000]\n",
      "loss: 0.098205  [ 1288/ 3000]\n",
      "loss: 0.040574  [ 1296/ 3000]\n",
      "loss: 0.008425  [ 1304/ 3000]\n",
      "loss: 0.127075  [ 1312/ 3000]\n",
      "loss: 0.311308  [ 1320/ 3000]\n",
      "loss: 0.130712  [ 1328/ 3000]\n",
      "loss: 0.090340  [ 1336/ 3000]\n",
      "loss: 0.163923  [ 1344/ 3000]\n",
      "loss: 0.098168  [ 1352/ 3000]\n",
      "loss: 0.052929  [ 1360/ 3000]\n",
      "loss: 0.142045  [ 1368/ 3000]\n",
      "loss: 0.156711  [ 1376/ 3000]\n",
      "loss: 0.093449  [ 1384/ 3000]\n",
      "loss: 0.056885  [ 1392/ 3000]\n",
      "loss: 0.110960  [ 1400/ 3000]\n",
      "loss: 0.100454  [ 1408/ 3000]\n",
      "loss: 0.108831  [ 1416/ 3000]\n",
      "loss: 0.142355  [ 1424/ 3000]\n",
      "loss: 0.083668  [ 1432/ 3000]\n",
      "loss: 0.049471  [ 1440/ 3000]\n",
      "loss: 0.050416  [ 1448/ 3000]\n",
      "loss: 0.084245  [ 1456/ 3000]\n",
      "loss: 0.013040  [ 1464/ 3000]\n",
      "loss: 0.056357  [ 1472/ 3000]\n",
      "loss: 0.029422  [ 1480/ 3000]\n",
      "loss: 0.148540  [ 1488/ 3000]\n",
      "loss: 0.042147  [ 1496/ 3000]\n",
      "loss: 0.070675  [ 1504/ 3000]\n",
      "loss: 0.099190  [ 1512/ 3000]\n",
      "loss: 0.099597  [ 1520/ 3000]\n",
      "loss: 0.045732  [ 1528/ 3000]\n",
      "loss: 0.098758  [ 1536/ 3000]\n",
      "loss: 0.050765  [ 1544/ 3000]\n",
      "loss: 0.135733  [ 1552/ 3000]\n",
      "loss: 0.058600  [ 1560/ 3000]\n",
      "loss: 0.054054  [ 1568/ 3000]\n",
      "loss: 0.038476  [ 1576/ 3000]\n",
      "loss: 0.120643  [ 1584/ 3000]\n",
      "loss: 0.065896  [ 1592/ 3000]\n",
      "loss: 0.114149  [ 1600/ 3000]\n",
      "loss: 0.051234  [ 1608/ 3000]\n",
      "loss: 0.155630  [ 1616/ 3000]\n",
      "loss: 0.127487  [ 1624/ 3000]\n",
      "loss: 0.056985  [ 1632/ 3000]\n",
      "loss: 0.060481  [ 1640/ 3000]\n",
      "loss: 0.139212  [ 1648/ 3000]\n",
      "loss: 0.045663  [ 1656/ 3000]\n",
      "loss: 0.159051  [ 1664/ 3000]\n",
      "loss: 0.034765  [ 1672/ 3000]\n",
      "loss: 0.060043  [ 1680/ 3000]\n",
      "loss: 0.077014  [ 1688/ 3000]\n",
      "loss: 0.109898  [ 1696/ 3000]\n",
      "loss: 0.068689  [ 1704/ 3000]\n",
      "loss: 0.032554  [ 1712/ 3000]\n",
      "loss: 0.055473  [ 1720/ 3000]\n",
      "loss: 0.071141  [ 1728/ 3000]\n",
      "loss: 0.101373  [ 1736/ 3000]\n",
      "loss: 0.091488  [ 1744/ 3000]\n",
      "loss: 0.025178  [ 1752/ 3000]\n",
      "loss: 0.015810  [ 1760/ 3000]\n",
      "loss: 0.139492  [ 1768/ 3000]\n",
      "loss: 0.083052  [ 1776/ 3000]\n",
      "loss: 0.038223  [ 1784/ 3000]\n",
      "loss: 0.058548  [ 1792/ 3000]\n",
      "loss: 0.116982  [ 1800/ 3000]\n",
      "loss: 0.154856  [ 1808/ 3000]\n",
      "loss: 0.046299  [ 1816/ 3000]\n",
      "loss: 0.147064  [ 1824/ 3000]\n",
      "loss: 0.012824  [ 1832/ 3000]\n",
      "loss: 0.012946  [ 1840/ 3000]\n",
      "loss: 0.071099  [ 1848/ 3000]\n",
      "loss: 0.094157  [ 1856/ 3000]\n",
      "loss: 0.094767  [ 1864/ 3000]\n",
      "loss: 0.082726  [ 1872/ 3000]\n",
      "loss: 0.020687  [ 1880/ 3000]\n",
      "loss: 0.030753  [ 1888/ 3000]\n",
      "loss: 0.089749  [ 1896/ 3000]\n",
      "loss: 0.035964  [ 1904/ 3000]\n",
      "loss: 0.052303  [ 1912/ 3000]\n",
      "loss: 0.118185  [ 1920/ 3000]\n",
      "loss: 0.098880  [ 1928/ 3000]\n",
      "loss: 0.155770  [ 1936/ 3000]\n",
      "loss: 0.024038  [ 1944/ 3000]\n",
      "loss: 0.105990  [ 1952/ 3000]\n",
      "loss: 0.038319  [ 1960/ 3000]\n",
      "loss: 0.125870  [ 1968/ 3000]\n",
      "loss: 0.042417  [ 1976/ 3000]\n",
      "loss: 0.136255  [ 1984/ 3000]\n",
      "loss: 0.143609  [ 1992/ 3000]\n",
      "loss: 0.085618  [ 2000/ 3000]\n",
      "loss: 0.116441  [ 2008/ 3000]\n",
      "loss: 0.077042  [ 2016/ 3000]\n",
      "loss: 0.067060  [ 2024/ 3000]\n",
      "loss: 0.113965  [ 2032/ 3000]\n",
      "loss: 0.094935  [ 2040/ 3000]\n",
      "loss: 0.045991  [ 2048/ 3000]\n",
      "loss: 0.049960  [ 2056/ 3000]\n",
      "loss: 0.039033  [ 2064/ 3000]\n",
      "loss: 0.136717  [ 2072/ 3000]\n",
      "loss: 0.060324  [ 2080/ 3000]\n",
      "loss: 0.128344  [ 2088/ 3000]\n",
      "loss: 0.089544  [ 2096/ 3000]\n",
      "loss: 0.056535  [ 2104/ 3000]\n",
      "loss: 0.035416  [ 2112/ 3000]\n",
      "loss: 0.022419  [ 2120/ 3000]\n",
      "loss: 0.076767  [ 2128/ 3000]\n",
      "loss: 0.077973  [ 2136/ 3000]\n",
      "loss: 0.120168  [ 2144/ 3000]\n",
      "loss: 0.147031  [ 2152/ 3000]\n",
      "loss: 0.033640  [ 2160/ 3000]\n",
      "loss: 0.079894  [ 2168/ 3000]\n",
      "loss: 0.035991  [ 2176/ 3000]\n",
      "loss: 0.105068  [ 2184/ 3000]\n",
      "loss: 0.094937  [ 2192/ 3000]\n",
      "loss: 0.039485  [ 2200/ 3000]\n",
      "loss: 0.026209  [ 2208/ 3000]\n",
      "loss: 0.047591  [ 2216/ 3000]\n",
      "loss: 0.115570  [ 2224/ 3000]\n",
      "loss: 0.087061  [ 2232/ 3000]\n",
      "loss: 0.136899  [ 2240/ 3000]\n",
      "loss: 0.018173  [ 2248/ 3000]\n",
      "loss: 0.076553  [ 2256/ 3000]\n",
      "loss: 0.029862  [ 2264/ 3000]\n",
      "loss: 0.144986  [ 2272/ 3000]\n",
      "loss: 0.051893  [ 2280/ 3000]\n",
      "loss: 0.143050  [ 2288/ 3000]\n",
      "loss: 0.077631  [ 2296/ 3000]\n",
      "loss: 0.058315  [ 2304/ 3000]\n",
      "loss: 0.035281  [ 2312/ 3000]\n",
      "loss: 0.030750  [ 2320/ 3000]\n",
      "loss: 0.092908  [ 2328/ 3000]\n",
      "loss: 0.020540  [ 2336/ 3000]\n",
      "loss: 0.128641  [ 2344/ 3000]\n",
      "loss: 0.140023  [ 2352/ 3000]\n",
      "loss: 0.110631  [ 2360/ 3000]\n",
      "loss: 0.057027  [ 2368/ 3000]\n",
      "loss: 0.035033  [ 2376/ 3000]\n",
      "loss: 0.063496  [ 2384/ 3000]\n",
      "loss: 0.064830  [ 2392/ 3000]\n",
      "loss: 0.016876  [ 2400/ 3000]\n",
      "loss: 0.136133  [ 2408/ 3000]\n",
      "loss: 0.089900  [ 2416/ 3000]\n",
      "loss: 0.097959  [ 2424/ 3000]\n",
      "loss: 0.110511  [ 2432/ 3000]\n",
      "loss: 0.061008  [ 2440/ 3000]\n",
      "loss: 0.132205  [ 2448/ 3000]\n",
      "loss: 0.133085  [ 2456/ 3000]\n",
      "loss: 0.060921  [ 2464/ 3000]\n",
      "loss: 0.252398  [ 2472/ 3000]\n",
      "loss: 0.033204  [ 2480/ 3000]\n",
      "loss: 0.068853  [ 2488/ 3000]\n",
      "loss: 0.024841  [ 2496/ 3000]\n",
      "loss: 0.047675  [ 2504/ 3000]\n",
      "loss: 0.140847  [ 2512/ 3000]\n",
      "loss: 0.235441  [ 2520/ 3000]\n",
      "loss: 0.044745  [ 2528/ 3000]\n",
      "loss: 0.073695  [ 2536/ 3000]\n",
      "loss: 0.027673  [ 2544/ 3000]\n",
      "loss: 0.111062  [ 2552/ 3000]\n",
      "loss: 0.099660  [ 2560/ 3000]\n",
      "loss: 0.149225  [ 2568/ 3000]\n",
      "loss: 0.133064  [ 2576/ 3000]\n",
      "loss: 0.079290  [ 2584/ 3000]\n",
      "loss: 0.062594  [ 2592/ 3000]\n",
      "loss: 0.079014  [ 2600/ 3000]\n",
      "loss: 0.099956  [ 2608/ 3000]\n",
      "loss: 0.041777  [ 2616/ 3000]\n",
      "loss: 0.044721  [ 2624/ 3000]\n",
      "loss: 0.122650  [ 2632/ 3000]\n",
      "loss: 0.141466  [ 2640/ 3000]\n",
      "loss: 0.093373  [ 2648/ 3000]\n",
      "loss: 0.101505  [ 2656/ 3000]\n",
      "loss: 0.069451  [ 2664/ 3000]\n",
      "loss: 0.125516  [ 2672/ 3000]\n",
      "loss: 0.143123  [ 2680/ 3000]\n",
      "loss: 0.062405  [ 2688/ 3000]\n",
      "loss: 0.050754  [ 2696/ 3000]\n",
      "loss: 0.092998  [ 2704/ 3000]\n",
      "loss: 0.103100  [ 2712/ 3000]\n",
      "loss: 0.074294  [ 2720/ 3000]\n",
      "loss: 0.133427  [ 2728/ 3000]\n",
      "loss: 0.037623  [ 2736/ 3000]\n",
      "loss: 0.084133  [ 2744/ 3000]\n",
      "loss: 0.106558  [ 2752/ 3000]\n",
      "loss: 0.072757  [ 2760/ 3000]\n",
      "loss: 0.028929  [ 2768/ 3000]\n",
      "loss: 0.138116  [ 2776/ 3000]\n",
      "loss: 0.086403  [ 2784/ 3000]\n",
      "loss: 0.056450  [ 2792/ 3000]\n",
      "loss: 0.122060  [ 2800/ 3000]\n",
      "loss: 0.173399  [ 2808/ 3000]\n",
      "loss: 0.084388  [ 2816/ 3000]\n",
      "loss: 0.092174  [ 2824/ 3000]\n",
      "loss: 0.097268  [ 2832/ 3000]\n",
      "loss: 0.070158  [ 2840/ 3000]\n",
      "loss: 0.071944  [ 2848/ 3000]\n",
      "loss: 0.098877  [ 2856/ 3000]\n",
      "loss: 0.046460  [ 2864/ 3000]\n",
      "loss: 0.102563  [ 2872/ 3000]\n",
      "loss: 0.128542  [ 2880/ 3000]\n",
      "loss: 0.027331  [ 2888/ 3000]\n",
      "loss: 0.021315  [ 2896/ 3000]\n",
      "loss: 0.089404  [ 2904/ 3000]\n",
      "loss: 0.110120  [ 2912/ 3000]\n",
      "loss: 0.077982  [ 2920/ 3000]\n",
      "loss: 0.132379  [ 2928/ 3000]\n",
      "loss: 0.202496  [ 2936/ 3000]\n",
      "loss: 0.039699  [ 2944/ 3000]\n",
      "loss: 0.008264  [ 2952/ 3000]\n",
      "loss: 0.037942  [ 2960/ 3000]\n",
      "loss: 0.069548  [ 2968/ 3000]\n",
      "loss: 0.061699  [ 2976/ 3000]\n",
      "loss: 0.074307  [ 2984/ 3000]\n",
      "loss: 0.018787  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.091359 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.039257  [    0/ 3000]\n",
      "loss: 0.088494  [    8/ 3000]\n",
      "loss: 0.037712  [   16/ 3000]\n",
      "loss: 0.044697  [   24/ 3000]\n",
      "loss: 0.135645  [   32/ 3000]\n",
      "loss: 0.028077  [   40/ 3000]\n",
      "loss: 0.030700  [   48/ 3000]\n",
      "loss: 0.089159  [   56/ 3000]\n",
      "loss: 0.179676  [   64/ 3000]\n",
      "loss: 0.027694  [   72/ 3000]\n",
      "loss: 0.165198  [   80/ 3000]\n",
      "loss: 0.101085  [   88/ 3000]\n",
      "loss: 0.125589  [   96/ 3000]\n",
      "loss: 0.072311  [  104/ 3000]\n",
      "loss: 0.186137  [  112/ 3000]\n",
      "loss: 0.049419  [  120/ 3000]\n",
      "loss: 0.041971  [  128/ 3000]\n",
      "loss: 0.108718  [  136/ 3000]\n",
      "loss: 0.096053  [  144/ 3000]\n",
      "loss: 0.056579  [  152/ 3000]\n",
      "loss: 0.029322  [  160/ 3000]\n",
      "loss: 0.020214  [  168/ 3000]\n",
      "loss: 0.044952  [  176/ 3000]\n",
      "loss: 0.106320  [  184/ 3000]\n",
      "loss: 0.074878  [  192/ 3000]\n",
      "loss: 0.049628  [  200/ 3000]\n",
      "loss: 0.181639  [  208/ 3000]\n",
      "loss: 0.053084  [  216/ 3000]\n",
      "loss: 0.068058  [  224/ 3000]\n",
      "loss: 0.153880  [  232/ 3000]\n",
      "loss: 0.072770  [  240/ 3000]\n",
      "loss: 0.055728  [  248/ 3000]\n",
      "loss: 0.039301  [  256/ 3000]\n",
      "loss: 0.109931  [  264/ 3000]\n",
      "loss: 0.058663  [  272/ 3000]\n",
      "loss: 0.185450  [  280/ 3000]\n",
      "loss: 0.036868  [  288/ 3000]\n",
      "loss: 0.067009  [  296/ 3000]\n",
      "loss: 0.050067  [  304/ 3000]\n",
      "loss: 0.127917  [  312/ 3000]\n",
      "loss: 0.062305  [  320/ 3000]\n",
      "loss: 0.169127  [  328/ 3000]\n",
      "loss: 0.060992  [  336/ 3000]\n",
      "loss: 0.097500  [  344/ 3000]\n",
      "loss: 0.030745  [  352/ 3000]\n",
      "loss: 0.040534  [  360/ 3000]\n",
      "loss: 0.143217  [  368/ 3000]\n",
      "loss: 0.034683  [  376/ 3000]\n",
      "loss: 0.109095  [  384/ 3000]\n",
      "loss: 0.071616  [  392/ 3000]\n",
      "loss: 0.110541  [  400/ 3000]\n",
      "loss: 0.043777  [  408/ 3000]\n",
      "loss: 0.120281  [  416/ 3000]\n",
      "loss: 0.063225  [  424/ 3000]\n",
      "loss: 0.195009  [  432/ 3000]\n",
      "loss: 0.052180  [  440/ 3000]\n",
      "loss: 0.094408  [  448/ 3000]\n",
      "loss: 0.062079  [  456/ 3000]\n",
      "loss: 0.144650  [  464/ 3000]\n",
      "loss: 0.073439  [  472/ 3000]\n",
      "loss: 0.023934  [  480/ 3000]\n",
      "loss: 0.154040  [  488/ 3000]\n",
      "loss: 0.105336  [  496/ 3000]\n",
      "loss: 0.055893  [  504/ 3000]\n",
      "loss: 0.082344  [  512/ 3000]\n",
      "loss: 0.052139  [  520/ 3000]\n",
      "loss: 0.236193  [  528/ 3000]\n",
      "loss: 0.118494  [  536/ 3000]\n",
      "loss: 0.108450  [  544/ 3000]\n",
      "loss: 0.070602  [  552/ 3000]\n",
      "loss: 0.054084  [  560/ 3000]\n",
      "loss: 0.109849  [  568/ 3000]\n",
      "loss: 0.074595  [  576/ 3000]\n",
      "loss: 0.086526  [  584/ 3000]\n",
      "loss: 0.046177  [  592/ 3000]\n",
      "loss: 0.172122  [  600/ 3000]\n",
      "loss: 0.047358  [  608/ 3000]\n",
      "loss: 0.114526  [  616/ 3000]\n",
      "loss: 0.078013  [  624/ 3000]\n",
      "loss: 0.211059  [  632/ 3000]\n",
      "loss: 0.026960  [  640/ 3000]\n",
      "loss: 0.170373  [  648/ 3000]\n",
      "loss: 0.229878  [  656/ 3000]\n",
      "loss: 0.185098  [  664/ 3000]\n",
      "loss: 0.087185  [  672/ 3000]\n",
      "loss: 0.096953  [  680/ 3000]\n",
      "loss: 0.068165  [  688/ 3000]\n",
      "loss: 0.201603  [  696/ 3000]\n",
      "loss: 0.077705  [  704/ 3000]\n",
      "loss: 0.061356  [  712/ 3000]\n",
      "loss: 0.070125  [  720/ 3000]\n",
      "loss: 0.044483  [  728/ 3000]\n",
      "loss: 0.074666  [  736/ 3000]\n",
      "loss: 0.050336  [  744/ 3000]\n",
      "loss: 0.115359  [  752/ 3000]\n",
      "loss: 0.088023  [  760/ 3000]\n",
      "loss: 0.136336  [  768/ 3000]\n",
      "loss: 0.077557  [  776/ 3000]\n",
      "loss: 0.186224  [  784/ 3000]\n",
      "loss: 0.102654  [  792/ 3000]\n",
      "loss: 0.185856  [  800/ 3000]\n",
      "loss: 0.076543  [  808/ 3000]\n",
      "loss: 0.045755  [  816/ 3000]\n",
      "loss: 0.063438  [  824/ 3000]\n",
      "loss: 0.074672  [  832/ 3000]\n",
      "loss: 0.036160  [  840/ 3000]\n",
      "loss: 0.027761  [  848/ 3000]\n",
      "loss: 0.036042  [  856/ 3000]\n",
      "loss: 0.107269  [  864/ 3000]\n",
      "loss: 0.021772  [  872/ 3000]\n",
      "loss: 0.093188  [  880/ 3000]\n",
      "loss: 0.120361  [  888/ 3000]\n",
      "loss: 0.075863  [  896/ 3000]\n",
      "loss: 0.223278  [  904/ 3000]\n",
      "loss: 0.068037  [  912/ 3000]\n",
      "loss: 0.076040  [  920/ 3000]\n",
      "loss: 0.088660  [  928/ 3000]\n",
      "loss: 0.063423  [  936/ 3000]\n",
      "loss: 0.204526  [  944/ 3000]\n",
      "loss: 0.046807  [  952/ 3000]\n",
      "loss: 0.063566  [  960/ 3000]\n",
      "loss: 0.036651  [  968/ 3000]\n",
      "loss: 0.019411  [  976/ 3000]\n",
      "loss: 0.024538  [  984/ 3000]\n",
      "loss: 0.150748  [  992/ 3000]\n",
      "loss: 0.094829  [ 1000/ 3000]\n",
      "loss: 0.078141  [ 1008/ 3000]\n",
      "loss: 0.143000  [ 1016/ 3000]\n",
      "loss: 0.079079  [ 1024/ 3000]\n",
      "loss: 0.126591  [ 1032/ 3000]\n",
      "loss: 0.024900  [ 1040/ 3000]\n",
      "loss: 0.055885  [ 1048/ 3000]\n",
      "loss: 0.031333  [ 1056/ 3000]\n",
      "loss: 0.092750  [ 1064/ 3000]\n",
      "loss: 0.058510  [ 1072/ 3000]\n",
      "loss: 0.065379  [ 1080/ 3000]\n",
      "loss: 0.130878  [ 1088/ 3000]\n",
      "loss: 0.112688  [ 1096/ 3000]\n",
      "loss: 0.031007  [ 1104/ 3000]\n",
      "loss: 0.128278  [ 1112/ 3000]\n",
      "loss: 0.042309  [ 1120/ 3000]\n",
      "loss: 0.058203  [ 1128/ 3000]\n",
      "loss: 0.064936  [ 1136/ 3000]\n",
      "loss: 0.157939  [ 1144/ 3000]\n",
      "loss: 0.051736  [ 1152/ 3000]\n",
      "loss: 0.038246  [ 1160/ 3000]\n",
      "loss: 0.045379  [ 1168/ 3000]\n",
      "loss: 0.039241  [ 1176/ 3000]\n",
      "loss: 0.200475  [ 1184/ 3000]\n",
      "loss: 0.073646  [ 1192/ 3000]\n",
      "loss: 0.065990  [ 1200/ 3000]\n",
      "loss: 0.049325  [ 1208/ 3000]\n",
      "loss: 0.066763  [ 1216/ 3000]\n",
      "loss: 0.102911  [ 1224/ 3000]\n",
      "loss: 0.115748  [ 1232/ 3000]\n",
      "loss: 0.100911  [ 1240/ 3000]\n",
      "loss: 0.114814  [ 1248/ 3000]\n",
      "loss: 0.019232  [ 1256/ 3000]\n",
      "loss: 0.056441  [ 1264/ 3000]\n",
      "loss: 0.034966  [ 1272/ 3000]\n",
      "loss: 0.050592  [ 1280/ 3000]\n",
      "loss: 0.093997  [ 1288/ 3000]\n",
      "loss: 0.038710  [ 1296/ 3000]\n",
      "loss: 0.007718  [ 1304/ 3000]\n",
      "loss: 0.123354  [ 1312/ 3000]\n",
      "loss: 0.304697  [ 1320/ 3000]\n",
      "loss: 0.126477  [ 1328/ 3000]\n",
      "loss: 0.087962  [ 1336/ 3000]\n",
      "loss: 0.159464  [ 1344/ 3000]\n",
      "loss: 0.096355  [ 1352/ 3000]\n",
      "loss: 0.050060  [ 1360/ 3000]\n",
      "loss: 0.138392  [ 1368/ 3000]\n",
      "loss: 0.153629  [ 1376/ 3000]\n",
      "loss: 0.089673  [ 1384/ 3000]\n",
      "loss: 0.054729  [ 1392/ 3000]\n",
      "loss: 0.107837  [ 1400/ 3000]\n",
      "loss: 0.098238  [ 1408/ 3000]\n",
      "loss: 0.105622  [ 1416/ 3000]\n",
      "loss: 0.140434  [ 1424/ 3000]\n",
      "loss: 0.081194  [ 1432/ 3000]\n",
      "loss: 0.047823  [ 1440/ 3000]\n",
      "loss: 0.048412  [ 1448/ 3000]\n",
      "loss: 0.081242  [ 1456/ 3000]\n",
      "loss: 0.012347  [ 1464/ 3000]\n",
      "loss: 0.055292  [ 1472/ 3000]\n",
      "loss: 0.028355  [ 1480/ 3000]\n",
      "loss: 0.147271  [ 1488/ 3000]\n",
      "loss: 0.040510  [ 1496/ 3000]\n",
      "loss: 0.068128  [ 1504/ 3000]\n",
      "loss: 0.098079  [ 1512/ 3000]\n",
      "loss: 0.096610  [ 1520/ 3000]\n",
      "loss: 0.043014  [ 1528/ 3000]\n",
      "loss: 0.096353  [ 1536/ 3000]\n",
      "loss: 0.048722  [ 1544/ 3000]\n",
      "loss: 0.132583  [ 1552/ 3000]\n",
      "loss: 0.056830  [ 1560/ 3000]\n",
      "loss: 0.052062  [ 1568/ 3000]\n",
      "loss: 0.036360  [ 1576/ 3000]\n",
      "loss: 0.117760  [ 1584/ 3000]\n",
      "loss: 0.064676  [ 1592/ 3000]\n",
      "loss: 0.111037  [ 1600/ 3000]\n",
      "loss: 0.049380  [ 1608/ 3000]\n",
      "loss: 0.152791  [ 1616/ 3000]\n",
      "loss: 0.125117  [ 1624/ 3000]\n",
      "loss: 0.055630  [ 1632/ 3000]\n",
      "loss: 0.058960  [ 1640/ 3000]\n",
      "loss: 0.137227  [ 1648/ 3000]\n",
      "loss: 0.044683  [ 1656/ 3000]\n",
      "loss: 0.153233  [ 1664/ 3000]\n",
      "loss: 0.032983  [ 1672/ 3000]\n",
      "loss: 0.058282  [ 1680/ 3000]\n",
      "loss: 0.074978  [ 1688/ 3000]\n",
      "loss: 0.106997  [ 1696/ 3000]\n",
      "loss: 0.066481  [ 1704/ 3000]\n",
      "loss: 0.031275  [ 1712/ 3000]\n",
      "loss: 0.052393  [ 1720/ 3000]\n",
      "loss: 0.069214  [ 1728/ 3000]\n",
      "loss: 0.099499  [ 1736/ 3000]\n",
      "loss: 0.089461  [ 1744/ 3000]\n",
      "loss: 0.024168  [ 1752/ 3000]\n",
      "loss: 0.014626  [ 1760/ 3000]\n",
      "loss: 0.134975  [ 1768/ 3000]\n",
      "loss: 0.080418  [ 1776/ 3000]\n",
      "loss: 0.036606  [ 1784/ 3000]\n",
      "loss: 0.057218  [ 1792/ 3000]\n",
      "loss: 0.113356  [ 1800/ 3000]\n",
      "loss: 0.150910  [ 1808/ 3000]\n",
      "loss: 0.045175  [ 1816/ 3000]\n",
      "loss: 0.144119  [ 1824/ 3000]\n",
      "loss: 0.011595  [ 1832/ 3000]\n",
      "loss: 0.012514  [ 1840/ 3000]\n",
      "loss: 0.068124  [ 1848/ 3000]\n",
      "loss: 0.091879  [ 1856/ 3000]\n",
      "loss: 0.092303  [ 1864/ 3000]\n",
      "loss: 0.080506  [ 1872/ 3000]\n",
      "loss: 0.019518  [ 1880/ 3000]\n",
      "loss: 0.029047  [ 1888/ 3000]\n",
      "loss: 0.086212  [ 1896/ 3000]\n",
      "loss: 0.035368  [ 1904/ 3000]\n",
      "loss: 0.049981  [ 1912/ 3000]\n",
      "loss: 0.115732  [ 1920/ 3000]\n",
      "loss: 0.096165  [ 1928/ 3000]\n",
      "loss: 0.151539  [ 1936/ 3000]\n",
      "loss: 0.022464  [ 1944/ 3000]\n",
      "loss: 0.103707  [ 1952/ 3000]\n",
      "loss: 0.037496  [ 1960/ 3000]\n",
      "loss: 0.122722  [ 1968/ 3000]\n",
      "loss: 0.040840  [ 1976/ 3000]\n",
      "loss: 0.133790  [ 1984/ 3000]\n",
      "loss: 0.141153  [ 1992/ 3000]\n",
      "loss: 0.082707  [ 2000/ 3000]\n",
      "loss: 0.113601  [ 2008/ 3000]\n",
      "loss: 0.073847  [ 2016/ 3000]\n",
      "loss: 0.065540  [ 2024/ 3000]\n",
      "loss: 0.111022  [ 2032/ 3000]\n",
      "loss: 0.092692  [ 2040/ 3000]\n",
      "loss: 0.044643  [ 2048/ 3000]\n",
      "loss: 0.048036  [ 2056/ 3000]\n",
      "loss: 0.037346  [ 2064/ 3000]\n",
      "loss: 0.132476  [ 2072/ 3000]\n",
      "loss: 0.058500  [ 2080/ 3000]\n",
      "loss: 0.124326  [ 2088/ 3000]\n",
      "loss: 0.087302  [ 2096/ 3000]\n",
      "loss: 0.055324  [ 2104/ 3000]\n",
      "loss: 0.034651  [ 2112/ 3000]\n",
      "loss: 0.021283  [ 2120/ 3000]\n",
      "loss: 0.075361  [ 2128/ 3000]\n",
      "loss: 0.075981  [ 2136/ 3000]\n",
      "loss: 0.117538  [ 2144/ 3000]\n",
      "loss: 0.144889  [ 2152/ 3000]\n",
      "loss: 0.032237  [ 2160/ 3000]\n",
      "loss: 0.077322  [ 2168/ 3000]\n",
      "loss: 0.034346  [ 2176/ 3000]\n",
      "loss: 0.102808  [ 2184/ 3000]\n",
      "loss: 0.091278  [ 2192/ 3000]\n",
      "loss: 0.038518  [ 2200/ 3000]\n",
      "loss: 0.025173  [ 2208/ 3000]\n",
      "loss: 0.045774  [ 2216/ 3000]\n",
      "loss: 0.113185  [ 2224/ 3000]\n",
      "loss: 0.085101  [ 2232/ 3000]\n",
      "loss: 0.134103  [ 2240/ 3000]\n",
      "loss: 0.017301  [ 2248/ 3000]\n",
      "loss: 0.073152  [ 2256/ 3000]\n",
      "loss: 0.028415  [ 2264/ 3000]\n",
      "loss: 0.143068  [ 2272/ 3000]\n",
      "loss: 0.050404  [ 2280/ 3000]\n",
      "loss: 0.138816  [ 2288/ 3000]\n",
      "loss: 0.075779  [ 2296/ 3000]\n",
      "loss: 0.057642  [ 2304/ 3000]\n",
      "loss: 0.034180  [ 2312/ 3000]\n",
      "loss: 0.029396  [ 2320/ 3000]\n",
      "loss: 0.090550  [ 2328/ 3000]\n",
      "loss: 0.019542  [ 2336/ 3000]\n",
      "loss: 0.126292  [ 2344/ 3000]\n",
      "loss: 0.135066  [ 2352/ 3000]\n",
      "loss: 0.109384  [ 2360/ 3000]\n",
      "loss: 0.054754  [ 2368/ 3000]\n",
      "loss: 0.033986  [ 2376/ 3000]\n",
      "loss: 0.062141  [ 2384/ 3000]\n",
      "loss: 0.063530  [ 2392/ 3000]\n",
      "loss: 0.015523  [ 2400/ 3000]\n",
      "loss: 0.133379  [ 2408/ 3000]\n",
      "loss: 0.088613  [ 2416/ 3000]\n",
      "loss: 0.095372  [ 2424/ 3000]\n",
      "loss: 0.107378  [ 2432/ 3000]\n",
      "loss: 0.059518  [ 2440/ 3000]\n",
      "loss: 0.128819  [ 2448/ 3000]\n",
      "loss: 0.130150  [ 2456/ 3000]\n",
      "loss: 0.058846  [ 2464/ 3000]\n",
      "loss: 0.249683  [ 2472/ 3000]\n",
      "loss: 0.032175  [ 2480/ 3000]\n",
      "loss: 0.066548  [ 2488/ 3000]\n",
      "loss: 0.023261  [ 2496/ 3000]\n",
      "loss: 0.045574  [ 2504/ 3000]\n",
      "loss: 0.136799  [ 2512/ 3000]\n",
      "loss: 0.232219  [ 2520/ 3000]\n",
      "loss: 0.042787  [ 2528/ 3000]\n",
      "loss: 0.071770  [ 2536/ 3000]\n",
      "loss: 0.025998  [ 2544/ 3000]\n",
      "loss: 0.108222  [ 2552/ 3000]\n",
      "loss: 0.098180  [ 2560/ 3000]\n",
      "loss: 0.146628  [ 2568/ 3000]\n",
      "loss: 0.130191  [ 2576/ 3000]\n",
      "loss: 0.076495  [ 2584/ 3000]\n",
      "loss: 0.060083  [ 2592/ 3000]\n",
      "loss: 0.077748  [ 2600/ 3000]\n",
      "loss: 0.097512  [ 2608/ 3000]\n",
      "loss: 0.039985  [ 2616/ 3000]\n",
      "loss: 0.042767  [ 2624/ 3000]\n",
      "loss: 0.120983  [ 2632/ 3000]\n",
      "loss: 0.138544  [ 2640/ 3000]\n",
      "loss: 0.091111  [ 2648/ 3000]\n",
      "loss: 0.098574  [ 2656/ 3000]\n",
      "loss: 0.067326  [ 2664/ 3000]\n",
      "loss: 0.122469  [ 2672/ 3000]\n",
      "loss: 0.139476  [ 2680/ 3000]\n",
      "loss: 0.060681  [ 2688/ 3000]\n",
      "loss: 0.049029  [ 2696/ 3000]\n",
      "loss: 0.091416  [ 2704/ 3000]\n",
      "loss: 0.099069  [ 2712/ 3000]\n",
      "loss: 0.071628  [ 2720/ 3000]\n",
      "loss: 0.129657  [ 2728/ 3000]\n",
      "loss: 0.036382  [ 2736/ 3000]\n",
      "loss: 0.081423  [ 2744/ 3000]\n",
      "loss: 0.103209  [ 2752/ 3000]\n",
      "loss: 0.070906  [ 2760/ 3000]\n",
      "loss: 0.027591  [ 2768/ 3000]\n",
      "loss: 0.134244  [ 2776/ 3000]\n",
      "loss: 0.084494  [ 2784/ 3000]\n",
      "loss: 0.054131  [ 2792/ 3000]\n",
      "loss: 0.119370  [ 2800/ 3000]\n",
      "loss: 0.170202  [ 2808/ 3000]\n",
      "loss: 0.081324  [ 2816/ 3000]\n",
      "loss: 0.090416  [ 2824/ 3000]\n",
      "loss: 0.094644  [ 2832/ 3000]\n",
      "loss: 0.068139  [ 2840/ 3000]\n",
      "loss: 0.069329  [ 2848/ 3000]\n",
      "loss: 0.096152  [ 2856/ 3000]\n",
      "loss: 0.044382  [ 2864/ 3000]\n",
      "loss: 0.100530  [ 2872/ 3000]\n",
      "loss: 0.124897  [ 2880/ 3000]\n",
      "loss: 0.025381  [ 2888/ 3000]\n",
      "loss: 0.020245  [ 2896/ 3000]\n",
      "loss: 0.085533  [ 2904/ 3000]\n",
      "loss: 0.107603  [ 2912/ 3000]\n",
      "loss: 0.075672  [ 2920/ 3000]\n",
      "loss: 0.128958  [ 2928/ 3000]\n",
      "loss: 0.197217  [ 2936/ 3000]\n",
      "loss: 0.037939  [ 2944/ 3000]\n",
      "loss: 0.007734  [ 2952/ 3000]\n",
      "loss: 0.036906  [ 2960/ 3000]\n",
      "loss: 0.068266  [ 2968/ 3000]\n",
      "loss: 0.060403  [ 2976/ 3000]\n",
      "loss: 0.072874  [ 2984/ 3000]\n",
      "loss: 0.017553  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.090403 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.037334  [    0/ 3000]\n",
      "loss: 0.085502  [    8/ 3000]\n",
      "loss: 0.035157  [   16/ 3000]\n",
      "loss: 0.042585  [   24/ 3000]\n",
      "loss: 0.131380  [   32/ 3000]\n",
      "loss: 0.026464  [   40/ 3000]\n",
      "loss: 0.029566  [   48/ 3000]\n",
      "loss: 0.087053  [   56/ 3000]\n",
      "loss: 0.175784  [   64/ 3000]\n",
      "loss: 0.026946  [   72/ 3000]\n",
      "loss: 0.162713  [   80/ 3000]\n",
      "loss: 0.097665  [   88/ 3000]\n",
      "loss: 0.121578  [   96/ 3000]\n",
      "loss: 0.069254  [  104/ 3000]\n",
      "loss: 0.183029  [  112/ 3000]\n",
      "loss: 0.047451  [  120/ 3000]\n",
      "loss: 0.040594  [  128/ 3000]\n",
      "loss: 0.104882  [  136/ 3000]\n",
      "loss: 0.093417  [  144/ 3000]\n",
      "loss: 0.055009  [  152/ 3000]\n",
      "loss: 0.027953  [  160/ 3000]\n",
      "loss: 0.019116  [  168/ 3000]\n",
      "loss: 0.042817  [  176/ 3000]\n",
      "loss: 0.104017  [  184/ 3000]\n",
      "loss: 0.072385  [  192/ 3000]\n",
      "loss: 0.047999  [  200/ 3000]\n",
      "loss: 0.178837  [  208/ 3000]\n",
      "loss: 0.051663  [  216/ 3000]\n",
      "loss: 0.065989  [  224/ 3000]\n",
      "loss: 0.149870  [  232/ 3000]\n",
      "loss: 0.070609  [  240/ 3000]\n",
      "loss: 0.053870  [  248/ 3000]\n",
      "loss: 0.037829  [  256/ 3000]\n",
      "loss: 0.106737  [  264/ 3000]\n",
      "loss: 0.057378  [  272/ 3000]\n",
      "loss: 0.183289  [  280/ 3000]\n",
      "loss: 0.035308  [  288/ 3000]\n",
      "loss: 0.065344  [  296/ 3000]\n",
      "loss: 0.048378  [  304/ 3000]\n",
      "loss: 0.125385  [  312/ 3000]\n",
      "loss: 0.059772  [  320/ 3000]\n",
      "loss: 0.163503  [  328/ 3000]\n",
      "loss: 0.057869  [  336/ 3000]\n",
      "loss: 0.096684  [  344/ 3000]\n",
      "loss: 0.029374  [  352/ 3000]\n",
      "loss: 0.039772  [  360/ 3000]\n",
      "loss: 0.140679  [  368/ 3000]\n",
      "loss: 0.033181  [  376/ 3000]\n",
      "loss: 0.106473  [  384/ 3000]\n",
      "loss: 0.069802  [  392/ 3000]\n",
      "loss: 0.106615  [  400/ 3000]\n",
      "loss: 0.042123  [  408/ 3000]\n",
      "loss: 0.116736  [  416/ 3000]\n",
      "loss: 0.060839  [  424/ 3000]\n",
      "loss: 0.191088  [  432/ 3000]\n",
      "loss: 0.050807  [  440/ 3000]\n",
      "loss: 0.091555  [  448/ 3000]\n",
      "loss: 0.059948  [  456/ 3000]\n",
      "loss: 0.141195  [  464/ 3000]\n",
      "loss: 0.071863  [  472/ 3000]\n",
      "loss: 0.022904  [  480/ 3000]\n",
      "loss: 0.151321  [  488/ 3000]\n",
      "loss: 0.104326  [  496/ 3000]\n",
      "loss: 0.053883  [  504/ 3000]\n",
      "loss: 0.080526  [  512/ 3000]\n",
      "loss: 0.051173  [  520/ 3000]\n",
      "loss: 0.232227  [  528/ 3000]\n",
      "loss: 0.115778  [  536/ 3000]\n",
      "loss: 0.105842  [  544/ 3000]\n",
      "loss: 0.067925  [  552/ 3000]\n",
      "loss: 0.052001  [  560/ 3000]\n",
      "loss: 0.107331  [  568/ 3000]\n",
      "loss: 0.071612  [  576/ 3000]\n",
      "loss: 0.083417  [  584/ 3000]\n",
      "loss: 0.044613  [  592/ 3000]\n",
      "loss: 0.166974  [  600/ 3000]\n",
      "loss: 0.046505  [  608/ 3000]\n",
      "loss: 0.111579  [  616/ 3000]\n",
      "loss: 0.075803  [  624/ 3000]\n",
      "loss: 0.208088  [  632/ 3000]\n",
      "loss: 0.025274  [  640/ 3000]\n",
      "loss: 0.167353  [  648/ 3000]\n",
      "loss: 0.225144  [  656/ 3000]\n",
      "loss: 0.181977  [  664/ 3000]\n",
      "loss: 0.085242  [  672/ 3000]\n",
      "loss: 0.095143  [  680/ 3000]\n",
      "loss: 0.066244  [  688/ 3000]\n",
      "loss: 0.196860  [  696/ 3000]\n",
      "loss: 0.076489  [  704/ 3000]\n",
      "loss: 0.059338  [  712/ 3000]\n",
      "loss: 0.068649  [  720/ 3000]\n",
      "loss: 0.043078  [  728/ 3000]\n",
      "loss: 0.073392  [  736/ 3000]\n",
      "loss: 0.047670  [  744/ 3000]\n",
      "loss: 0.111902  [  752/ 3000]\n",
      "loss: 0.084913  [  760/ 3000]\n",
      "loss: 0.135014  [  768/ 3000]\n",
      "loss: 0.075511  [  776/ 3000]\n",
      "loss: 0.180871  [  784/ 3000]\n",
      "loss: 0.099229  [  792/ 3000]\n",
      "loss: 0.183408  [  800/ 3000]\n",
      "loss: 0.074143  [  808/ 3000]\n",
      "loss: 0.043687  [  816/ 3000]\n",
      "loss: 0.061853  [  824/ 3000]\n",
      "loss: 0.072282  [  832/ 3000]\n",
      "loss: 0.034447  [  840/ 3000]\n",
      "loss: 0.026447  [  848/ 3000]\n",
      "loss: 0.034994  [  856/ 3000]\n",
      "loss: 0.104238  [  864/ 3000]\n",
      "loss: 0.020576  [  872/ 3000]\n",
      "loss: 0.091964  [  880/ 3000]\n",
      "loss: 0.116805  [  888/ 3000]\n",
      "loss: 0.074983  [  896/ 3000]\n",
      "loss: 0.219195  [  904/ 3000]\n",
      "loss: 0.066375  [  912/ 3000]\n",
      "loss: 0.074546  [  920/ 3000]\n",
      "loss: 0.086668  [  928/ 3000]\n",
      "loss: 0.061162  [  936/ 3000]\n",
      "loss: 0.199803  [  944/ 3000]\n",
      "loss: 0.045071  [  952/ 3000]\n",
      "loss: 0.061697  [  960/ 3000]\n",
      "loss: 0.035320  [  968/ 3000]\n",
      "loss: 0.018487  [  976/ 3000]\n",
      "loss: 0.023057  [  984/ 3000]\n",
      "loss: 0.147099  [  992/ 3000]\n",
      "loss: 0.092041  [ 1000/ 3000]\n",
      "loss: 0.076226  [ 1008/ 3000]\n",
      "loss: 0.139933  [ 1016/ 3000]\n",
      "loss: 0.076850  [ 1024/ 3000]\n",
      "loss: 0.123459  [ 1032/ 3000]\n",
      "loss: 0.023818  [ 1040/ 3000]\n",
      "loss: 0.054242  [ 1048/ 3000]\n",
      "loss: 0.030250  [ 1056/ 3000]\n",
      "loss: 0.090832  [ 1064/ 3000]\n",
      "loss: 0.056750  [ 1072/ 3000]\n",
      "loss: 0.063796  [ 1080/ 3000]\n",
      "loss: 0.127198  [ 1088/ 3000]\n",
      "loss: 0.110455  [ 1096/ 3000]\n",
      "loss: 0.029437  [ 1104/ 3000]\n",
      "loss: 0.125314  [ 1112/ 3000]\n",
      "loss: 0.041031  [ 1120/ 3000]\n",
      "loss: 0.056931  [ 1128/ 3000]\n",
      "loss: 0.062249  [ 1136/ 3000]\n",
      "loss: 0.154329  [ 1144/ 3000]\n",
      "loss: 0.050022  [ 1152/ 3000]\n",
      "loss: 0.037184  [ 1160/ 3000]\n",
      "loss: 0.043609  [ 1168/ 3000]\n",
      "loss: 0.037599  [ 1176/ 3000]\n",
      "loss: 0.196814  [ 1184/ 3000]\n",
      "loss: 0.071723  [ 1192/ 3000]\n",
      "loss: 0.062909  [ 1200/ 3000]\n",
      "loss: 0.047756  [ 1208/ 3000]\n",
      "loss: 0.064288  [ 1216/ 3000]\n",
      "loss: 0.099565  [ 1224/ 3000]\n",
      "loss: 0.112423  [ 1232/ 3000]\n",
      "loss: 0.098515  [ 1240/ 3000]\n",
      "loss: 0.111512  [ 1248/ 3000]\n",
      "loss: 0.018317  [ 1256/ 3000]\n",
      "loss: 0.055577  [ 1264/ 3000]\n",
      "loss: 0.033641  [ 1272/ 3000]\n",
      "loss: 0.047701  [ 1280/ 3000]\n",
      "loss: 0.090010  [ 1288/ 3000]\n",
      "loss: 0.036987  [ 1296/ 3000]\n",
      "loss: 0.007113  [ 1304/ 3000]\n",
      "loss: 0.119828  [ 1312/ 3000]\n",
      "loss: 0.298088  [ 1320/ 3000]\n",
      "loss: 0.122305  [ 1328/ 3000]\n",
      "loss: 0.085734  [ 1336/ 3000]\n",
      "loss: 0.155084  [ 1344/ 3000]\n",
      "loss: 0.094513  [ 1352/ 3000]\n",
      "loss: 0.047344  [ 1360/ 3000]\n",
      "loss: 0.135056  [ 1368/ 3000]\n",
      "loss: 0.150783  [ 1376/ 3000]\n",
      "loss: 0.086284  [ 1384/ 3000]\n",
      "loss: 0.052714  [ 1392/ 3000]\n",
      "loss: 0.104990  [ 1400/ 3000]\n",
      "loss: 0.096085  [ 1408/ 3000]\n",
      "loss: 0.102671  [ 1416/ 3000]\n",
      "loss: 0.138534  [ 1424/ 3000]\n",
      "loss: 0.078781  [ 1432/ 3000]\n",
      "loss: 0.046363  [ 1440/ 3000]\n",
      "loss: 0.046620  [ 1448/ 3000]\n",
      "loss: 0.078430  [ 1456/ 3000]\n",
      "loss: 0.011718  [ 1464/ 3000]\n",
      "loss: 0.054270  [ 1472/ 3000]\n",
      "loss: 0.027473  [ 1480/ 3000]\n",
      "loss: 0.145946  [ 1488/ 3000]\n",
      "loss: 0.039014  [ 1496/ 3000]\n",
      "loss: 0.065741  [ 1504/ 3000]\n",
      "loss: 0.096937  [ 1512/ 3000]\n",
      "loss: 0.093722  [ 1520/ 3000]\n",
      "loss: 0.040534  [ 1528/ 3000]\n",
      "loss: 0.094091  [ 1536/ 3000]\n",
      "loss: 0.046744  [ 1544/ 3000]\n",
      "loss: 0.129710  [ 1552/ 3000]\n",
      "loss: 0.055074  [ 1560/ 3000]\n",
      "loss: 0.050284  [ 1568/ 3000]\n",
      "loss: 0.034496  [ 1576/ 3000]\n",
      "loss: 0.115085  [ 1584/ 3000]\n",
      "loss: 0.063390  [ 1592/ 3000]\n",
      "loss: 0.108096  [ 1600/ 3000]\n",
      "loss: 0.047679  [ 1608/ 3000]\n",
      "loss: 0.150080  [ 1616/ 3000]\n",
      "loss: 0.122840  [ 1624/ 3000]\n",
      "loss: 0.054364  [ 1632/ 3000]\n",
      "loss: 0.057455  [ 1640/ 3000]\n",
      "loss: 0.135079  [ 1648/ 3000]\n",
      "loss: 0.043767  [ 1656/ 3000]\n",
      "loss: 0.147625  [ 1664/ 3000]\n",
      "loss: 0.031282  [ 1672/ 3000]\n",
      "loss: 0.056696  [ 1680/ 3000]\n",
      "loss: 0.072872  [ 1688/ 3000]\n",
      "loss: 0.104265  [ 1696/ 3000]\n",
      "loss: 0.064304  [ 1704/ 3000]\n",
      "loss: 0.030138  [ 1712/ 3000]\n",
      "loss: 0.049565  [ 1720/ 3000]\n",
      "loss: 0.067412  [ 1728/ 3000]\n",
      "loss: 0.097677  [ 1736/ 3000]\n",
      "loss: 0.087499  [ 1744/ 3000]\n",
      "loss: 0.023242  [ 1752/ 3000]\n",
      "loss: 0.013599  [ 1760/ 3000]\n",
      "loss: 0.130518  [ 1768/ 3000]\n",
      "loss: 0.077818  [ 1776/ 3000]\n",
      "loss: 0.035224  [ 1784/ 3000]\n",
      "loss: 0.055882  [ 1792/ 3000]\n",
      "loss: 0.109936  [ 1800/ 3000]\n",
      "loss: 0.147199  [ 1808/ 3000]\n",
      "loss: 0.044037  [ 1816/ 3000]\n",
      "loss: 0.141151  [ 1824/ 3000]\n",
      "loss: 0.010511  [ 1832/ 3000]\n",
      "loss: 0.012117  [ 1840/ 3000]\n",
      "loss: 0.065401  [ 1848/ 3000]\n",
      "loss: 0.089575  [ 1856/ 3000]\n",
      "loss: 0.089847  [ 1864/ 3000]\n",
      "loss: 0.078443  [ 1872/ 3000]\n",
      "loss: 0.018394  [ 1880/ 3000]\n",
      "loss: 0.027479  [ 1888/ 3000]\n",
      "loss: 0.082753  [ 1896/ 3000]\n",
      "loss: 0.034845  [ 1904/ 3000]\n",
      "loss: 0.047895  [ 1912/ 3000]\n",
      "loss: 0.113411  [ 1920/ 3000]\n",
      "loss: 0.093495  [ 1928/ 3000]\n",
      "loss: 0.147457  [ 1936/ 3000]\n",
      "loss: 0.021067  [ 1944/ 3000]\n",
      "loss: 0.101528  [ 1952/ 3000]\n",
      "loss: 0.036657  [ 1960/ 3000]\n",
      "loss: 0.119694  [ 1968/ 3000]\n",
      "loss: 0.039379  [ 1976/ 3000]\n",
      "loss: 0.131361  [ 1984/ 3000]\n",
      "loss: 0.138569  [ 1992/ 3000]\n",
      "loss: 0.079825  [ 2000/ 3000]\n",
      "loss: 0.110850  [ 2008/ 3000]\n",
      "loss: 0.070765  [ 2016/ 3000]\n",
      "loss: 0.064101  [ 2024/ 3000]\n",
      "loss: 0.108399  [ 2032/ 3000]\n",
      "loss: 0.090597  [ 2040/ 3000]\n",
      "loss: 0.043405  [ 2048/ 3000]\n",
      "loss: 0.046322  [ 2056/ 3000]\n",
      "loss: 0.035697  [ 2064/ 3000]\n",
      "loss: 0.128492  [ 2072/ 3000]\n",
      "loss: 0.056727  [ 2080/ 3000]\n",
      "loss: 0.120494  [ 2088/ 3000]\n",
      "loss: 0.085147  [ 2096/ 3000]\n",
      "loss: 0.054177  [ 2104/ 3000]\n",
      "loss: 0.033989  [ 2112/ 3000]\n",
      "loss: 0.020239  [ 2120/ 3000]\n",
      "loss: 0.074002  [ 2128/ 3000]\n",
      "loss: 0.074159  [ 2136/ 3000]\n",
      "loss: 0.115016  [ 2144/ 3000]\n",
      "loss: 0.142927  [ 2152/ 3000]\n",
      "loss: 0.030827  [ 2160/ 3000]\n",
      "loss: 0.074838  [ 2168/ 3000]\n",
      "loss: 0.032874  [ 2176/ 3000]\n",
      "loss: 0.100601  [ 2184/ 3000]\n",
      "loss: 0.087743  [ 2192/ 3000]\n",
      "loss: 0.037635  [ 2200/ 3000]\n",
      "loss: 0.024214  [ 2208/ 3000]\n",
      "loss: 0.044141  [ 2216/ 3000]\n",
      "loss: 0.110861  [ 2224/ 3000]\n",
      "loss: 0.083100  [ 2232/ 3000]\n",
      "loss: 0.131417  [ 2240/ 3000]\n",
      "loss: 0.016562  [ 2248/ 3000]\n",
      "loss: 0.069967  [ 2256/ 3000]\n",
      "loss: 0.027007  [ 2264/ 3000]\n",
      "loss: 0.140888  [ 2272/ 3000]\n",
      "loss: 0.049153  [ 2280/ 3000]\n",
      "loss: 0.134584  [ 2288/ 3000]\n",
      "loss: 0.074000  [ 2296/ 3000]\n",
      "loss: 0.056882  [ 2304/ 3000]\n",
      "loss: 0.033178  [ 2312/ 3000]\n",
      "loss: 0.028117  [ 2320/ 3000]\n",
      "loss: 0.088085  [ 2328/ 3000]\n",
      "loss: 0.018668  [ 2336/ 3000]\n",
      "loss: 0.123898  [ 2344/ 3000]\n",
      "loss: 0.130282  [ 2352/ 3000]\n",
      "loss: 0.108126  [ 2360/ 3000]\n",
      "loss: 0.052652  [ 2368/ 3000]\n",
      "loss: 0.032940  [ 2376/ 3000]\n",
      "loss: 0.060863  [ 2384/ 3000]\n",
      "loss: 0.062134  [ 2392/ 3000]\n",
      "loss: 0.014339  [ 2400/ 3000]\n",
      "loss: 0.130771  [ 2408/ 3000]\n",
      "loss: 0.087279  [ 2416/ 3000]\n",
      "loss: 0.092779  [ 2424/ 3000]\n",
      "loss: 0.104545  [ 2432/ 3000]\n",
      "loss: 0.058051  [ 2440/ 3000]\n",
      "loss: 0.125366  [ 2448/ 3000]\n",
      "loss: 0.127241  [ 2456/ 3000]\n",
      "loss: 0.056842  [ 2464/ 3000]\n",
      "loss: 0.246840  [ 2472/ 3000]\n",
      "loss: 0.031288  [ 2480/ 3000]\n",
      "loss: 0.064373  [ 2488/ 3000]\n",
      "loss: 0.021869  [ 2496/ 3000]\n",
      "loss: 0.043569  [ 2504/ 3000]\n",
      "loss: 0.132975  [ 2512/ 3000]\n",
      "loss: 0.228876  [ 2520/ 3000]\n",
      "loss: 0.040942  [ 2528/ 3000]\n",
      "loss: 0.070104  [ 2536/ 3000]\n",
      "loss: 0.024575  [ 2544/ 3000]\n",
      "loss: 0.105440  [ 2552/ 3000]\n",
      "loss: 0.096630  [ 2560/ 3000]\n",
      "loss: 0.144263  [ 2568/ 3000]\n",
      "loss: 0.127281  [ 2576/ 3000]\n",
      "loss: 0.073877  [ 2584/ 3000]\n",
      "loss: 0.057895  [ 2592/ 3000]\n",
      "loss: 0.076596  [ 2600/ 3000]\n",
      "loss: 0.095152  [ 2608/ 3000]\n",
      "loss: 0.038271  [ 2616/ 3000]\n",
      "loss: 0.040873  [ 2624/ 3000]\n",
      "loss: 0.119157  [ 2632/ 3000]\n",
      "loss: 0.135650  [ 2640/ 3000]\n",
      "loss: 0.089173  [ 2648/ 3000]\n",
      "loss: 0.095757  [ 2656/ 3000]\n",
      "loss: 0.065330  [ 2664/ 3000]\n",
      "loss: 0.119382  [ 2672/ 3000]\n",
      "loss: 0.135858  [ 2680/ 3000]\n",
      "loss: 0.059103  [ 2688/ 3000]\n",
      "loss: 0.047413  [ 2696/ 3000]\n",
      "loss: 0.089877  [ 2704/ 3000]\n",
      "loss: 0.095225  [ 2712/ 3000]\n",
      "loss: 0.069032  [ 2720/ 3000]\n",
      "loss: 0.125815  [ 2728/ 3000]\n",
      "loss: 0.035258  [ 2736/ 3000]\n",
      "loss: 0.078837  [ 2744/ 3000]\n",
      "loss: 0.099978  [ 2752/ 3000]\n",
      "loss: 0.069175  [ 2760/ 3000]\n",
      "loss: 0.026367  [ 2768/ 3000]\n",
      "loss: 0.130491  [ 2776/ 3000]\n",
      "loss: 0.082588  [ 2784/ 3000]\n",
      "loss: 0.051944  [ 2792/ 3000]\n",
      "loss: 0.116830  [ 2800/ 3000]\n",
      "loss: 0.166986  [ 2808/ 3000]\n",
      "loss: 0.078361  [ 2816/ 3000]\n",
      "loss: 0.088615  [ 2824/ 3000]\n",
      "loss: 0.092190  [ 2832/ 3000]\n",
      "loss: 0.066172  [ 2840/ 3000]\n",
      "loss: 0.066777  [ 2848/ 3000]\n",
      "loss: 0.093411  [ 2856/ 3000]\n",
      "loss: 0.042450  [ 2864/ 3000]\n",
      "loss: 0.098551  [ 2872/ 3000]\n",
      "loss: 0.121250  [ 2880/ 3000]\n",
      "loss: 0.023600  [ 2888/ 3000]\n",
      "loss: 0.019190  [ 2896/ 3000]\n",
      "loss: 0.081779  [ 2904/ 3000]\n",
      "loss: 0.105237  [ 2912/ 3000]\n",
      "loss: 0.073349  [ 2920/ 3000]\n",
      "loss: 0.125674  [ 2928/ 3000]\n",
      "loss: 0.192097  [ 2936/ 3000]\n",
      "loss: 0.036445  [ 2944/ 3000]\n",
      "loss: 0.007297  [ 2952/ 3000]\n",
      "loss: 0.035889  [ 2960/ 3000]\n",
      "loss: 0.066923  [ 2968/ 3000]\n",
      "loss: 0.059175  [ 2976/ 3000]\n",
      "loss: 0.071550  [ 2984/ 3000]\n",
      "loss: 0.016454  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.089580 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.035631  [    0/ 3000]\n",
      "loss: 0.082851  [    8/ 3000]\n",
      "loss: 0.032815  [   16/ 3000]\n",
      "loss: 0.040566  [   24/ 3000]\n",
      "loss: 0.127235  [   32/ 3000]\n",
      "loss: 0.024971  [   40/ 3000]\n",
      "loss: 0.028504  [   48/ 3000]\n",
      "loss: 0.085121  [   56/ 3000]\n",
      "loss: 0.171907  [   64/ 3000]\n",
      "loss: 0.026205  [   72/ 3000]\n",
      "loss: 0.160284  [   80/ 3000]\n",
      "loss: 0.094454  [   88/ 3000]\n",
      "loss: 0.117910  [   96/ 3000]\n",
      "loss: 0.066206  [  104/ 3000]\n",
      "loss: 0.179821  [  112/ 3000]\n",
      "loss: 0.045653  [  120/ 3000]\n",
      "loss: 0.039384  [  128/ 3000]\n",
      "loss: 0.101229  [  136/ 3000]\n",
      "loss: 0.090995  [  144/ 3000]\n",
      "loss: 0.053303  [  152/ 3000]\n",
      "loss: 0.026728  [  160/ 3000]\n",
      "loss: 0.018213  [  168/ 3000]\n",
      "loss: 0.040797  [  176/ 3000]\n",
      "loss: 0.101764  [  184/ 3000]\n",
      "loss: 0.069930  [  192/ 3000]\n",
      "loss: 0.046478  [  200/ 3000]\n",
      "loss: 0.175980  [  208/ 3000]\n",
      "loss: 0.050340  [  216/ 3000]\n",
      "loss: 0.064020  [  224/ 3000]\n",
      "loss: 0.145785  [  232/ 3000]\n",
      "loss: 0.068634  [  240/ 3000]\n",
      "loss: 0.052120  [  248/ 3000]\n",
      "loss: 0.036528  [  256/ 3000]\n",
      "loss: 0.103534  [  264/ 3000]\n",
      "loss: 0.056168  [  272/ 3000]\n",
      "loss: 0.181306  [  280/ 3000]\n",
      "loss: 0.033885  [  288/ 3000]\n",
      "loss: 0.063845  [  296/ 3000]\n",
      "loss: 0.046856  [  304/ 3000]\n",
      "loss: 0.122880  [  312/ 3000]\n",
      "loss: 0.057452  [  320/ 3000]\n",
      "loss: 0.158073  [  328/ 3000]\n",
      "loss: 0.055061  [  336/ 3000]\n",
      "loss: 0.095746  [  344/ 3000]\n",
      "loss: 0.028104  [  352/ 3000]\n",
      "loss: 0.038973  [  360/ 3000]\n",
      "loss: 0.138098  [  368/ 3000]\n",
      "loss: 0.031784  [  376/ 3000]\n",
      "loss: 0.104073  [  384/ 3000]\n",
      "loss: 0.067866  [  392/ 3000]\n",
      "loss: 0.103055  [  400/ 3000]\n",
      "loss: 0.040682  [  408/ 3000]\n",
      "loss: 0.113333  [  416/ 3000]\n",
      "loss: 0.058564  [  424/ 3000]\n",
      "loss: 0.187302  [  432/ 3000]\n",
      "loss: 0.049439  [  440/ 3000]\n",
      "loss: 0.088984  [  448/ 3000]\n",
      "loss: 0.057830  [  456/ 3000]\n",
      "loss: 0.137595  [  464/ 3000]\n",
      "loss: 0.070326  [  472/ 3000]\n",
      "loss: 0.022021  [  480/ 3000]\n",
      "loss: 0.148513  [  488/ 3000]\n",
      "loss: 0.103359  [  496/ 3000]\n",
      "loss: 0.051920  [  504/ 3000]\n",
      "loss: 0.078947  [  512/ 3000]\n",
      "loss: 0.050245  [  520/ 3000]\n",
      "loss: 0.228103  [  528/ 3000]\n",
      "loss: 0.113015  [  536/ 3000]\n",
      "loss: 0.103234  [  544/ 3000]\n",
      "loss: 0.065294  [  552/ 3000]\n",
      "loss: 0.050110  [  560/ 3000]\n",
      "loss: 0.104770  [  568/ 3000]\n",
      "loss: 0.068881  [  576/ 3000]\n",
      "loss: 0.080426  [  584/ 3000]\n",
      "loss: 0.043170  [  592/ 3000]\n",
      "loss: 0.161922  [  600/ 3000]\n",
      "loss: 0.045634  [  608/ 3000]\n",
      "loss: 0.108745  [  616/ 3000]\n",
      "loss: 0.073721  [  624/ 3000]\n",
      "loss: 0.204971  [  632/ 3000]\n",
      "loss: 0.023811  [  640/ 3000]\n",
      "loss: 0.164142  [  648/ 3000]\n",
      "loss: 0.220408  [  656/ 3000]\n",
      "loss: 0.178961  [  664/ 3000]\n",
      "loss: 0.083293  [  672/ 3000]\n",
      "loss: 0.093328  [  680/ 3000]\n",
      "loss: 0.064467  [  688/ 3000]\n",
      "loss: 0.192295  [  696/ 3000]\n",
      "loss: 0.075333  [  704/ 3000]\n",
      "loss: 0.057552  [  712/ 3000]\n",
      "loss: 0.067270  [  720/ 3000]\n",
      "loss: 0.041765  [  728/ 3000]\n",
      "loss: 0.072141  [  736/ 3000]\n",
      "loss: 0.045182  [  744/ 3000]\n",
      "loss: 0.108605  [  752/ 3000]\n",
      "loss: 0.081996  [  760/ 3000]\n",
      "loss: 0.133486  [  768/ 3000]\n",
      "loss: 0.073563  [  776/ 3000]\n",
      "loss: 0.175683  [  784/ 3000]\n",
      "loss: 0.095946  [  792/ 3000]\n",
      "loss: 0.181048  [  800/ 3000]\n",
      "loss: 0.071997  [  808/ 3000]\n",
      "loss: 0.041882  [  816/ 3000]\n",
      "loss: 0.060409  [  824/ 3000]\n",
      "loss: 0.069973  [  832/ 3000]\n",
      "loss: 0.032859  [  840/ 3000]\n",
      "loss: 0.025319  [  848/ 3000]\n",
      "loss: 0.034001  [  856/ 3000]\n",
      "loss: 0.101393  [  864/ 3000]\n",
      "loss: 0.019450  [  872/ 3000]\n",
      "loss: 0.090573  [  880/ 3000]\n",
      "loss: 0.113660  [  888/ 3000]\n",
      "loss: 0.074051  [  896/ 3000]\n",
      "loss: 0.214963  [  904/ 3000]\n",
      "loss: 0.064819  [  912/ 3000]\n",
      "loss: 0.073088  [  920/ 3000]\n",
      "loss: 0.084665  [  928/ 3000]\n",
      "loss: 0.059004  [  936/ 3000]\n",
      "loss: 0.195212  [  944/ 3000]\n",
      "loss: 0.043418  [  952/ 3000]\n",
      "loss: 0.059972  [  960/ 3000]\n",
      "loss: 0.034059  [  968/ 3000]\n",
      "loss: 0.017637  [  976/ 3000]\n",
      "loss: 0.021743  [  984/ 3000]\n",
      "loss: 0.143588  [  992/ 3000]\n",
      "loss: 0.089371  [ 1000/ 3000]\n",
      "loss: 0.074360  [ 1008/ 3000]\n",
      "loss: 0.136833  [ 1016/ 3000]\n",
      "loss: 0.074773  [ 1024/ 3000]\n",
      "loss: 0.120341  [ 1032/ 3000]\n",
      "loss: 0.022800  [ 1040/ 3000]\n",
      "loss: 0.052681  [ 1048/ 3000]\n",
      "loss: 0.029236  [ 1056/ 3000]\n",
      "loss: 0.088833  [ 1064/ 3000]\n",
      "loss: 0.055066  [ 1072/ 3000]\n",
      "loss: 0.062273  [ 1080/ 3000]\n",
      "loss: 0.123685  [ 1088/ 3000]\n",
      "loss: 0.108275  [ 1096/ 3000]\n",
      "loss: 0.027951  [ 1104/ 3000]\n",
      "loss: 0.122281  [ 1112/ 3000]\n",
      "loss: 0.039722  [ 1120/ 3000]\n",
      "loss: 0.055747  [ 1128/ 3000]\n",
      "loss: 0.059699  [ 1136/ 3000]\n",
      "loss: 0.150668  [ 1144/ 3000]\n",
      "loss: 0.048352  [ 1152/ 3000]\n",
      "loss: 0.036228  [ 1160/ 3000]\n",
      "loss: 0.041965  [ 1168/ 3000]\n",
      "loss: 0.036117  [ 1176/ 3000]\n",
      "loss: 0.193202  [ 1184/ 3000]\n",
      "loss: 0.069847  [ 1192/ 3000]\n",
      "loss: 0.059978  [ 1200/ 3000]\n",
      "loss: 0.046336  [ 1208/ 3000]\n",
      "loss: 0.061912  [ 1216/ 3000]\n",
      "loss: 0.096418  [ 1224/ 3000]\n",
      "loss: 0.109064  [ 1232/ 3000]\n",
      "loss: 0.096116  [ 1240/ 3000]\n",
      "loss: 0.108190  [ 1248/ 3000]\n",
      "loss: 0.017376  [ 1256/ 3000]\n",
      "loss: 0.054783  [ 1264/ 3000]\n",
      "loss: 0.032415  [ 1272/ 3000]\n",
      "loss: 0.045045  [ 1280/ 3000]\n",
      "loss: 0.086290  [ 1288/ 3000]\n",
      "loss: 0.035340  [ 1296/ 3000]\n",
      "loss: 0.006588  [ 1304/ 3000]\n",
      "loss: 0.116396  [ 1312/ 3000]\n",
      "loss: 0.291250  [ 1320/ 3000]\n",
      "loss: 0.118263  [ 1328/ 3000]\n",
      "loss: 0.083665  [ 1336/ 3000]\n",
      "loss: 0.150863  [ 1344/ 3000]\n",
      "loss: 0.092659  [ 1352/ 3000]\n",
      "loss: 0.044941  [ 1360/ 3000]\n",
      "loss: 0.131919  [ 1368/ 3000]\n",
      "loss: 0.148114  [ 1376/ 3000]\n",
      "loss: 0.083197  [ 1384/ 3000]\n",
      "loss: 0.050833  [ 1392/ 3000]\n",
      "loss: 0.102273  [ 1400/ 3000]\n",
      "loss: 0.094052  [ 1408/ 3000]\n",
      "loss: 0.099989  [ 1416/ 3000]\n",
      "loss: 0.136566  [ 1424/ 3000]\n",
      "loss: 0.076414  [ 1432/ 3000]\n",
      "loss: 0.045027  [ 1440/ 3000]\n",
      "loss: 0.045026  [ 1448/ 3000]\n",
      "loss: 0.075759  [ 1456/ 3000]\n",
      "loss: 0.011155  [ 1464/ 3000]\n",
      "loss: 0.053247  [ 1472/ 3000]\n",
      "loss: 0.026719  [ 1480/ 3000]\n",
      "loss: 0.144484  [ 1488/ 3000]\n",
      "loss: 0.037628  [ 1496/ 3000]\n",
      "loss: 0.063508  [ 1504/ 3000]\n",
      "loss: 0.095814  [ 1512/ 3000]\n",
      "loss: 0.090962  [ 1520/ 3000]\n",
      "loss: 0.038345  [ 1528/ 3000]\n",
      "loss: 0.091894  [ 1536/ 3000]\n",
      "loss: 0.044813  [ 1544/ 3000]\n",
      "loss: 0.126828  [ 1552/ 3000]\n",
      "loss: 0.053337  [ 1560/ 3000]\n",
      "loss: 0.048558  [ 1568/ 3000]\n",
      "loss: 0.032802  [ 1576/ 3000]\n",
      "loss: 0.112629  [ 1584/ 3000]\n",
      "loss: 0.062165  [ 1592/ 3000]\n",
      "loss: 0.105236  [ 1600/ 3000]\n",
      "loss: 0.046126  [ 1608/ 3000]\n",
      "loss: 0.147488  [ 1616/ 3000]\n",
      "loss: 0.120483  [ 1624/ 3000]\n",
      "loss: 0.053023  [ 1632/ 3000]\n",
      "loss: 0.055955  [ 1640/ 3000]\n",
      "loss: 0.132874  [ 1648/ 3000]\n",
      "loss: 0.042868  [ 1656/ 3000]\n",
      "loss: 0.142300  [ 1664/ 3000]\n",
      "loss: 0.029728  [ 1672/ 3000]\n",
      "loss: 0.055231  [ 1680/ 3000]\n",
      "loss: 0.070849  [ 1688/ 3000]\n",
      "loss: 0.101706  [ 1696/ 3000]\n",
      "loss: 0.062175  [ 1704/ 3000]\n",
      "loss: 0.029110  [ 1712/ 3000]\n",
      "loss: 0.046968  [ 1720/ 3000]\n",
      "loss: 0.065643  [ 1728/ 3000]\n",
      "loss: 0.095729  [ 1736/ 3000]\n",
      "loss: 0.085540  [ 1744/ 3000]\n",
      "loss: 0.022401  [ 1752/ 3000]\n",
      "loss: 0.012685  [ 1760/ 3000]\n",
      "loss: 0.126180  [ 1768/ 3000]\n",
      "loss: 0.075294  [ 1776/ 3000]\n",
      "loss: 0.033869  [ 1784/ 3000]\n",
      "loss: 0.054578  [ 1792/ 3000]\n",
      "loss: 0.106761  [ 1800/ 3000]\n",
      "loss: 0.143687  [ 1808/ 3000]\n",
      "loss: 0.042802  [ 1816/ 3000]\n",
      "loss: 0.138116  [ 1824/ 3000]\n",
      "loss: 0.009550  [ 1832/ 3000]\n",
      "loss: 0.011758  [ 1840/ 3000]\n",
      "loss: 0.062910  [ 1848/ 3000]\n",
      "loss: 0.087315  [ 1856/ 3000]\n",
      "loss: 0.087508  [ 1864/ 3000]\n",
      "loss: 0.076451  [ 1872/ 3000]\n",
      "loss: 0.017324  [ 1880/ 3000]\n",
      "loss: 0.026011  [ 1888/ 3000]\n",
      "loss: 0.079495  [ 1896/ 3000]\n",
      "loss: 0.034364  [ 1904/ 3000]\n",
      "loss: 0.045921  [ 1912/ 3000]\n",
      "loss: 0.111092  [ 1920/ 3000]\n",
      "loss: 0.090925  [ 1928/ 3000]\n",
      "loss: 0.143531  [ 1936/ 3000]\n",
      "loss: 0.019836  [ 1944/ 3000]\n",
      "loss: 0.099410  [ 1952/ 3000]\n",
      "loss: 0.035789  [ 1960/ 3000]\n",
      "loss: 0.116887  [ 1968/ 3000]\n",
      "loss: 0.037997  [ 1976/ 3000]\n",
      "loss: 0.128844  [ 1984/ 3000]\n",
      "loss: 0.136076  [ 1992/ 3000]\n",
      "loss: 0.077041  [ 2000/ 3000]\n",
      "loss: 0.108171  [ 2008/ 3000]\n",
      "loss: 0.067770  [ 2016/ 3000]\n",
      "loss: 0.062733  [ 2024/ 3000]\n",
      "loss: 0.105769  [ 2032/ 3000]\n",
      "loss: 0.088613  [ 2040/ 3000]\n",
      "loss: 0.042180  [ 2048/ 3000]\n",
      "loss: 0.044646  [ 2056/ 3000]\n",
      "loss: 0.034169  [ 2064/ 3000]\n",
      "loss: 0.124802  [ 2072/ 3000]\n",
      "loss: 0.055032  [ 2080/ 3000]\n",
      "loss: 0.116790  [ 2088/ 3000]\n",
      "loss: 0.083127  [ 2096/ 3000]\n",
      "loss: 0.053068  [ 2104/ 3000]\n",
      "loss: 0.033468  [ 2112/ 3000]\n",
      "loss: 0.019352  [ 2120/ 3000]\n",
      "loss: 0.072694  [ 2128/ 3000]\n",
      "loss: 0.072384  [ 2136/ 3000]\n",
      "loss: 0.112560  [ 2144/ 3000]\n",
      "loss: 0.141002  [ 2152/ 3000]\n",
      "loss: 0.029531  [ 2160/ 3000]\n",
      "loss: 0.072536  [ 2168/ 3000]\n",
      "loss: 0.031506  [ 2176/ 3000]\n",
      "loss: 0.098495  [ 2184/ 3000]\n",
      "loss: 0.084142  [ 2192/ 3000]\n",
      "loss: 0.036777  [ 2200/ 3000]\n",
      "loss: 0.023267  [ 2208/ 3000]\n",
      "loss: 0.042691  [ 2216/ 3000]\n",
      "loss: 0.108538  [ 2224/ 3000]\n",
      "loss: 0.081037  [ 2232/ 3000]\n",
      "loss: 0.128738  [ 2240/ 3000]\n",
      "loss: 0.015902  [ 2248/ 3000]\n",
      "loss: 0.067034  [ 2256/ 3000]\n",
      "loss: 0.025697  [ 2264/ 3000]\n",
      "loss: 0.138563  [ 2272/ 3000]\n",
      "loss: 0.047918  [ 2280/ 3000]\n",
      "loss: 0.130458  [ 2288/ 3000]\n",
      "loss: 0.072215  [ 2296/ 3000]\n",
      "loss: 0.056021  [ 2304/ 3000]\n",
      "loss: 0.032196  [ 2312/ 3000]\n",
      "loss: 0.026833  [ 2320/ 3000]\n",
      "loss: 0.085655  [ 2328/ 3000]\n",
      "loss: 0.017872  [ 2336/ 3000]\n",
      "loss: 0.121483  [ 2344/ 3000]\n",
      "loss: 0.125695  [ 2352/ 3000]\n",
      "loss: 0.106722  [ 2360/ 3000]\n",
      "loss: 0.050734  [ 2368/ 3000]\n",
      "loss: 0.031928  [ 2376/ 3000]\n",
      "loss: 0.059618  [ 2384/ 3000]\n",
      "loss: 0.060700  [ 2392/ 3000]\n",
      "loss: 0.013286  [ 2400/ 3000]\n",
      "loss: 0.128472  [ 2408/ 3000]\n",
      "loss: 0.085901  [ 2416/ 3000]\n",
      "loss: 0.090083  [ 2424/ 3000]\n",
      "loss: 0.101902  [ 2432/ 3000]\n",
      "loss: 0.056693  [ 2440/ 3000]\n",
      "loss: 0.121934  [ 2448/ 3000]\n",
      "loss: 0.124472  [ 2456/ 3000]\n",
      "loss: 0.054968  [ 2464/ 3000]\n",
      "loss: 0.243792  [ 2472/ 3000]\n",
      "loss: 0.030466  [ 2480/ 3000]\n",
      "loss: 0.062250  [ 2488/ 3000]\n",
      "loss: 0.020557  [ 2496/ 3000]\n",
      "loss: 0.041783  [ 2504/ 3000]\n",
      "loss: 0.129266  [ 2512/ 3000]\n",
      "loss: 0.225611  [ 2520/ 3000]\n",
      "loss: 0.039216  [ 2528/ 3000]\n",
      "loss: 0.068469  [ 2536/ 3000]\n",
      "loss: 0.023325  [ 2544/ 3000]\n",
      "loss: 0.102689  [ 2552/ 3000]\n",
      "loss: 0.095083  [ 2560/ 3000]\n",
      "loss: 0.142057  [ 2568/ 3000]\n",
      "loss: 0.124188  [ 2576/ 3000]\n",
      "loss: 0.071423  [ 2584/ 3000]\n",
      "loss: 0.055928  [ 2592/ 3000]\n",
      "loss: 0.075454  [ 2600/ 3000]\n",
      "loss: 0.093050  [ 2608/ 3000]\n",
      "loss: 0.036691  [ 2616/ 3000]\n",
      "loss: 0.039064  [ 2624/ 3000]\n",
      "loss: 0.117252  [ 2632/ 3000]\n",
      "loss: 0.132876  [ 2640/ 3000]\n",
      "loss: 0.087160  [ 2648/ 3000]\n",
      "loss: 0.093138  [ 2656/ 3000]\n",
      "loss: 0.063448  [ 2664/ 3000]\n",
      "loss: 0.116438  [ 2672/ 3000]\n",
      "loss: 0.132391  [ 2680/ 3000]\n",
      "loss: 0.057606  [ 2688/ 3000]\n",
      "loss: 0.045840  [ 2696/ 3000]\n",
      "loss: 0.088385  [ 2704/ 3000]\n",
      "loss: 0.091663  [ 2712/ 3000]\n",
      "loss: 0.066464  [ 2720/ 3000]\n",
      "loss: 0.122049  [ 2728/ 3000]\n",
      "loss: 0.034220  [ 2736/ 3000]\n",
      "loss: 0.076472  [ 2744/ 3000]\n",
      "loss: 0.096846  [ 2752/ 3000]\n",
      "loss: 0.067527  [ 2760/ 3000]\n",
      "loss: 0.025274  [ 2768/ 3000]\n",
      "loss: 0.126653  [ 2776/ 3000]\n",
      "loss: 0.080722  [ 2784/ 3000]\n",
      "loss: 0.049912  [ 2792/ 3000]\n",
      "loss: 0.114352  [ 2800/ 3000]\n",
      "loss: 0.163735  [ 2808/ 3000]\n",
      "loss: 0.075446  [ 2816/ 3000]\n",
      "loss: 0.086828  [ 2824/ 3000]\n",
      "loss: 0.089835  [ 2832/ 3000]\n",
      "loss: 0.064316  [ 2840/ 3000]\n",
      "loss: 0.064275  [ 2848/ 3000]\n",
      "loss: 0.090818  [ 2856/ 3000]\n",
      "loss: 0.040657  [ 2864/ 3000]\n",
      "loss: 0.096746  [ 2872/ 3000]\n",
      "loss: 0.117946  [ 2880/ 3000]\n",
      "loss: 0.021973  [ 2888/ 3000]\n",
      "loss: 0.018245  [ 2896/ 3000]\n",
      "loss: 0.078336  [ 2904/ 3000]\n",
      "loss: 0.102972  [ 2912/ 3000]\n",
      "loss: 0.071092  [ 2920/ 3000]\n",
      "loss: 0.122494  [ 2928/ 3000]\n",
      "loss: 0.186928  [ 2936/ 3000]\n",
      "loss: 0.035140  [ 2944/ 3000]\n",
      "loss: 0.006918  [ 2952/ 3000]\n",
      "loss: 0.034935  [ 2960/ 3000]\n",
      "loss: 0.065512  [ 2968/ 3000]\n",
      "loss: 0.058043  [ 2976/ 3000]\n",
      "loss: 0.070293  [ 2984/ 3000]\n",
      "loss: 0.015484  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.088860 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.034053  [    0/ 3000]\n",
      "loss: 0.080404  [    8/ 3000]\n",
      "loss: 0.030793  [   16/ 3000]\n",
      "loss: 0.038658  [   24/ 3000]\n",
      "loss: 0.123251  [   32/ 3000]\n",
      "loss: 0.023584  [   40/ 3000]\n",
      "loss: 0.027526  [   48/ 3000]\n",
      "loss: 0.083277  [   56/ 3000]\n",
      "loss: 0.167971  [   64/ 3000]\n",
      "loss: 0.025553  [   72/ 3000]\n",
      "loss: 0.157893  [   80/ 3000]\n",
      "loss: 0.091316  [   88/ 3000]\n",
      "loss: 0.114486  [   96/ 3000]\n",
      "loss: 0.063188  [  104/ 3000]\n",
      "loss: 0.176728  [  112/ 3000]\n",
      "loss: 0.043941  [  120/ 3000]\n",
      "loss: 0.038306  [  128/ 3000]\n",
      "loss: 0.097714  [  136/ 3000]\n",
      "loss: 0.088641  [  144/ 3000]\n",
      "loss: 0.051645  [  152/ 3000]\n",
      "loss: 0.025611  [  160/ 3000]\n",
      "loss: 0.017325  [  168/ 3000]\n",
      "loss: 0.038932  [  176/ 3000]\n",
      "loss: 0.099628  [  184/ 3000]\n",
      "loss: 0.067423  [  192/ 3000]\n",
      "loss: 0.045141  [  200/ 3000]\n",
      "loss: 0.173045  [  208/ 3000]\n",
      "loss: 0.048964  [  216/ 3000]\n",
      "loss: 0.062252  [  224/ 3000]\n",
      "loss: 0.141953  [  232/ 3000]\n",
      "loss: 0.066806  [  240/ 3000]\n",
      "loss: 0.050481  [  248/ 3000]\n",
      "loss: 0.035276  [  256/ 3000]\n",
      "loss: 0.100305  [  264/ 3000]\n",
      "loss: 0.055061  [  272/ 3000]\n",
      "loss: 0.179063  [  280/ 3000]\n",
      "loss: 0.032568  [  288/ 3000]\n",
      "loss: 0.062387  [  296/ 3000]\n",
      "loss: 0.045447  [  304/ 3000]\n",
      "loss: 0.120457  [  312/ 3000]\n",
      "loss: 0.055227  [  320/ 3000]\n",
      "loss: 0.152818  [  328/ 3000]\n",
      "loss: 0.052372  [  336/ 3000]\n",
      "loss: 0.094700  [  344/ 3000]\n",
      "loss: 0.026947  [  352/ 3000]\n",
      "loss: 0.038113  [  360/ 3000]\n",
      "loss: 0.135343  [  368/ 3000]\n",
      "loss: 0.030361  [  376/ 3000]\n",
      "loss: 0.101946  [  384/ 3000]\n",
      "loss: 0.065838  [  392/ 3000]\n",
      "loss: 0.099844  [  400/ 3000]\n",
      "loss: 0.039422  [  408/ 3000]\n",
      "loss: 0.110049  [  416/ 3000]\n",
      "loss: 0.056449  [  424/ 3000]\n",
      "loss: 0.183541  [  432/ 3000]\n",
      "loss: 0.048009  [  440/ 3000]\n",
      "loss: 0.086534  [  448/ 3000]\n",
      "loss: 0.055750  [  456/ 3000]\n",
      "loss: 0.133973  [  464/ 3000]\n",
      "loss: 0.068838  [  472/ 3000]\n",
      "loss: 0.021217  [  480/ 3000]\n",
      "loss: 0.145476  [  488/ 3000]\n",
      "loss: 0.102337  [  496/ 3000]\n",
      "loss: 0.049993  [  504/ 3000]\n",
      "loss: 0.077375  [  512/ 3000]\n",
      "loss: 0.049267  [  520/ 3000]\n",
      "loss: 0.223836  [  528/ 3000]\n",
      "loss: 0.110138  [  536/ 3000]\n",
      "loss: 0.100501  [  544/ 3000]\n",
      "loss: 0.062818  [  552/ 3000]\n",
      "loss: 0.048348  [  560/ 3000]\n",
      "loss: 0.102296  [  568/ 3000]\n",
      "loss: 0.066342  [  576/ 3000]\n",
      "loss: 0.077596  [  584/ 3000]\n",
      "loss: 0.041776  [  592/ 3000]\n",
      "loss: 0.157079  [  600/ 3000]\n",
      "loss: 0.044640  [  608/ 3000]\n",
      "loss: 0.106013  [  616/ 3000]\n",
      "loss: 0.071789  [  624/ 3000]\n",
      "loss: 0.201644  [  632/ 3000]\n",
      "loss: 0.022529  [  640/ 3000]\n",
      "loss: 0.160843  [  648/ 3000]\n",
      "loss: 0.215726  [  656/ 3000]\n",
      "loss: 0.176072  [  664/ 3000]\n",
      "loss: 0.081302  [  672/ 3000]\n",
      "loss: 0.091515  [  680/ 3000]\n",
      "loss: 0.062768  [  688/ 3000]\n",
      "loss: 0.187907  [  696/ 3000]\n",
      "loss: 0.074178  [  704/ 3000]\n",
      "loss: 0.055857  [  712/ 3000]\n",
      "loss: 0.065948  [  720/ 3000]\n",
      "loss: 0.040481  [  728/ 3000]\n",
      "loss: 0.070834  [  736/ 3000]\n",
      "loss: 0.042855  [  744/ 3000]\n",
      "loss: 0.105406  [  752/ 3000]\n",
      "loss: 0.079183  [  760/ 3000]\n",
      "loss: 0.131921  [  768/ 3000]\n",
      "loss: 0.071783  [  776/ 3000]\n",
      "loss: 0.171006  [  784/ 3000]\n",
      "loss: 0.092757  [  792/ 3000]\n",
      "loss: 0.178817  [  800/ 3000]\n",
      "loss: 0.070027  [  808/ 3000]\n",
      "loss: 0.040236  [  816/ 3000]\n",
      "loss: 0.058944  [  824/ 3000]\n",
      "loss: 0.067819  [  832/ 3000]\n",
      "loss: 0.031384  [  840/ 3000]\n",
      "loss: 0.024347  [  848/ 3000]\n",
      "loss: 0.033010  [  856/ 3000]\n",
      "loss: 0.098620  [  864/ 3000]\n",
      "loss: 0.018452  [  872/ 3000]\n",
      "loss: 0.089180  [  880/ 3000]\n",
      "loss: 0.110753  [  888/ 3000]\n",
      "loss: 0.073213  [  896/ 3000]\n",
      "loss: 0.210643  [  904/ 3000]\n",
      "loss: 0.063319  [  912/ 3000]\n",
      "loss: 0.071524  [  920/ 3000]\n",
      "loss: 0.082723  [  928/ 3000]\n",
      "loss: 0.056890  [  936/ 3000]\n",
      "loss: 0.190663  [  944/ 3000]\n",
      "loss: 0.041817  [  952/ 3000]\n",
      "loss: 0.058378  [  960/ 3000]\n",
      "loss: 0.032920  [  968/ 3000]\n",
      "loss: 0.016862  [  976/ 3000]\n",
      "loss: 0.020534  [  984/ 3000]\n",
      "loss: 0.140108  [  992/ 3000]\n",
      "loss: 0.086884  [ 1000/ 3000]\n",
      "loss: 0.072541  [ 1008/ 3000]\n",
      "loss: 0.133604  [ 1016/ 3000]\n",
      "loss: 0.072825  [ 1024/ 3000]\n",
      "loss: 0.117210  [ 1032/ 3000]\n",
      "loss: 0.021798  [ 1040/ 3000]\n",
      "loss: 0.051122  [ 1048/ 3000]\n",
      "loss: 0.028249  [ 1056/ 3000]\n",
      "loss: 0.086804  [ 1064/ 3000]\n",
      "loss: 0.053433  [ 1072/ 3000]\n",
      "loss: 0.060724  [ 1080/ 3000]\n",
      "loss: 0.120345  [ 1088/ 3000]\n",
      "loss: 0.106025  [ 1096/ 3000]\n",
      "loss: 0.026575  [ 1104/ 3000]\n",
      "loss: 0.119087  [ 1112/ 3000]\n",
      "loss: 0.038481  [ 1120/ 3000]\n",
      "loss: 0.054680  [ 1128/ 3000]\n",
      "loss: 0.057437  [ 1136/ 3000]\n",
      "loss: 0.146832  [ 1144/ 3000]\n",
      "loss: 0.046820  [ 1152/ 3000]\n",
      "loss: 0.035291  [ 1160/ 3000]\n",
      "loss: 0.040489  [ 1168/ 3000]\n",
      "loss: 0.034733  [ 1176/ 3000]\n",
      "loss: 0.189402  [ 1184/ 3000]\n",
      "loss: 0.068054  [ 1192/ 3000]\n",
      "loss: 0.057180  [ 1200/ 3000]\n",
      "loss: 0.045061  [ 1208/ 3000]\n",
      "loss: 0.059542  [ 1216/ 3000]\n",
      "loss: 0.093312  [ 1224/ 3000]\n",
      "loss: 0.105964  [ 1232/ 3000]\n",
      "loss: 0.093789  [ 1240/ 3000]\n",
      "loss: 0.104985  [ 1248/ 3000]\n",
      "loss: 0.016526  [ 1256/ 3000]\n",
      "loss: 0.054019  [ 1264/ 3000]\n",
      "loss: 0.031292  [ 1272/ 3000]\n",
      "loss: 0.042668  [ 1280/ 3000]\n",
      "loss: 0.082907  [ 1288/ 3000]\n",
      "loss: 0.033753  [ 1296/ 3000]\n",
      "loss: 0.006129  [ 1304/ 3000]\n",
      "loss: 0.113051  [ 1312/ 3000]\n",
      "loss: 0.284311  [ 1320/ 3000]\n",
      "loss: 0.114469  [ 1328/ 3000]\n",
      "loss: 0.081658  [ 1336/ 3000]\n",
      "loss: 0.146929  [ 1344/ 3000]\n",
      "loss: 0.090800  [ 1352/ 3000]\n",
      "loss: 0.042709  [ 1360/ 3000]\n",
      "loss: 0.129001  [ 1368/ 3000]\n",
      "loss: 0.145624  [ 1376/ 3000]\n",
      "loss: 0.080148  [ 1384/ 3000]\n",
      "loss: 0.048915  [ 1392/ 3000]\n",
      "loss: 0.099697  [ 1400/ 3000]\n",
      "loss: 0.092054  [ 1408/ 3000]\n",
      "loss: 0.097401  [ 1416/ 3000]\n",
      "loss: 0.134671  [ 1424/ 3000]\n",
      "loss: 0.074030  [ 1432/ 3000]\n",
      "loss: 0.043767  [ 1440/ 3000]\n",
      "loss: 0.043455  [ 1448/ 3000]\n",
      "loss: 0.073189  [ 1456/ 3000]\n",
      "loss: 0.010623  [ 1464/ 3000]\n",
      "loss: 0.052313  [ 1472/ 3000]\n",
      "loss: 0.026011  [ 1480/ 3000]\n",
      "loss: 0.142848  [ 1488/ 3000]\n",
      "loss: 0.036319  [ 1496/ 3000]\n",
      "loss: 0.061325  [ 1504/ 3000]\n",
      "loss: 0.094419  [ 1512/ 3000]\n",
      "loss: 0.088174  [ 1520/ 3000]\n",
      "loss: 0.036361  [ 1528/ 3000]\n",
      "loss: 0.089728  [ 1536/ 3000]\n",
      "loss: 0.042942  [ 1544/ 3000]\n",
      "loss: 0.123868  [ 1552/ 3000]\n",
      "loss: 0.051694  [ 1560/ 3000]\n",
      "loss: 0.046866  [ 1568/ 3000]\n",
      "loss: 0.031196  [ 1576/ 3000]\n",
      "loss: 0.110296  [ 1584/ 3000]\n",
      "loss: 0.060957  [ 1592/ 3000]\n",
      "loss: 0.102405  [ 1600/ 3000]\n",
      "loss: 0.044715  [ 1608/ 3000]\n",
      "loss: 0.144922  [ 1616/ 3000]\n",
      "loss: 0.118122  [ 1624/ 3000]\n",
      "loss: 0.051729  [ 1632/ 3000]\n",
      "loss: 0.054403  [ 1640/ 3000]\n",
      "loss: 0.130525  [ 1648/ 3000]\n",
      "loss: 0.042015  [ 1656/ 3000]\n",
      "loss: 0.137179  [ 1664/ 3000]\n",
      "loss: 0.028247  [ 1672/ 3000]\n",
      "loss: 0.053827  [ 1680/ 3000]\n",
      "loss: 0.068845  [ 1688/ 3000]\n",
      "loss: 0.099365  [ 1696/ 3000]\n",
      "loss: 0.060085  [ 1704/ 3000]\n",
      "loss: 0.028187  [ 1712/ 3000]\n",
      "loss: 0.044482  [ 1720/ 3000]\n",
      "loss: 0.064116  [ 1728/ 3000]\n",
      "loss: 0.093810  [ 1736/ 3000]\n",
      "loss: 0.083630  [ 1744/ 3000]\n",
      "loss: 0.021623  [ 1752/ 3000]\n",
      "loss: 0.011909  [ 1760/ 3000]\n",
      "loss: 0.122056  [ 1768/ 3000]\n",
      "loss: 0.072764  [ 1776/ 3000]\n",
      "loss: 0.032621  [ 1784/ 3000]\n",
      "loss: 0.053229  [ 1792/ 3000]\n",
      "loss: 0.103650  [ 1800/ 3000]\n",
      "loss: 0.140278  [ 1808/ 3000]\n",
      "loss: 0.041545  [ 1816/ 3000]\n",
      "loss: 0.135118  [ 1824/ 3000]\n",
      "loss: 0.008726  [ 1832/ 3000]\n",
      "loss: 0.011415  [ 1840/ 3000]\n",
      "loss: 0.060520  [ 1848/ 3000]\n",
      "loss: 0.085083  [ 1856/ 3000]\n",
      "loss: 0.085141  [ 1864/ 3000]\n",
      "loss: 0.074598  [ 1872/ 3000]\n",
      "loss: 0.016307  [ 1880/ 3000]\n",
      "loss: 0.024607  [ 1888/ 3000]\n",
      "loss: 0.076426  [ 1896/ 3000]\n",
      "loss: 0.033938  [ 1904/ 3000]\n",
      "loss: 0.044012  [ 1912/ 3000]\n",
      "loss: 0.108818  [ 1920/ 3000]\n",
      "loss: 0.088447  [ 1928/ 3000]\n",
      "loss: 0.139632  [ 1936/ 3000]\n",
      "loss: 0.018735  [ 1944/ 3000]\n",
      "loss: 0.097332  [ 1952/ 3000]\n",
      "loss: 0.034880  [ 1960/ 3000]\n",
      "loss: 0.114185  [ 1968/ 3000]\n",
      "loss: 0.036698  [ 1976/ 3000]\n",
      "loss: 0.126455  [ 1984/ 3000]\n",
      "loss: 0.133479  [ 1992/ 3000]\n",
      "loss: 0.074363  [ 2000/ 3000]\n",
      "loss: 0.105367  [ 2008/ 3000]\n",
      "loss: 0.064954  [ 2016/ 3000]\n",
      "loss: 0.061504  [ 2024/ 3000]\n",
      "loss: 0.103380  [ 2032/ 3000]\n",
      "loss: 0.086776  [ 2040/ 3000]\n",
      "loss: 0.041093  [ 2048/ 3000]\n",
      "loss: 0.043055  [ 2056/ 3000]\n",
      "loss: 0.032663  [ 2064/ 3000]\n",
      "loss: 0.121254  [ 2072/ 3000]\n",
      "loss: 0.053323  [ 2080/ 3000]\n",
      "loss: 0.113332  [ 2088/ 3000]\n",
      "loss: 0.081055  [ 2096/ 3000]\n",
      "loss: 0.051903  [ 2104/ 3000]\n",
      "loss: 0.032970  [ 2112/ 3000]\n",
      "loss: 0.018541  [ 2120/ 3000]\n",
      "loss: 0.071517  [ 2128/ 3000]\n",
      "loss: 0.070685  [ 2136/ 3000]\n",
      "loss: 0.110119  [ 2144/ 3000]\n",
      "loss: 0.139053  [ 2152/ 3000]\n",
      "loss: 0.028322  [ 2160/ 3000]\n",
      "loss: 0.070328  [ 2168/ 3000]\n",
      "loss: 0.030279  [ 2176/ 3000]\n",
      "loss: 0.096420  [ 2184/ 3000]\n",
      "loss: 0.080551  [ 2192/ 3000]\n",
      "loss: 0.035880  [ 2200/ 3000]\n",
      "loss: 0.022344  [ 2208/ 3000]\n",
      "loss: 0.041311  [ 2216/ 3000]\n",
      "loss: 0.106215  [ 2224/ 3000]\n",
      "loss: 0.078925  [ 2232/ 3000]\n",
      "loss: 0.126107  [ 2240/ 3000]\n",
      "loss: 0.015272  [ 2248/ 3000]\n",
      "loss: 0.064174  [ 2256/ 3000]\n",
      "loss: 0.024497  [ 2264/ 3000]\n",
      "loss: 0.136277  [ 2272/ 3000]\n",
      "loss: 0.046788  [ 2280/ 3000]\n",
      "loss: 0.126487  [ 2288/ 3000]\n",
      "loss: 0.070443  [ 2296/ 3000]\n",
      "loss: 0.055015  [ 2304/ 3000]\n",
      "loss: 0.031262  [ 2312/ 3000]\n",
      "loss: 0.025642  [ 2320/ 3000]\n",
      "loss: 0.083321  [ 2328/ 3000]\n",
      "loss: 0.017141  [ 2336/ 3000]\n",
      "loss: 0.119071  [ 2344/ 3000]\n",
      "loss: 0.121307  [ 2352/ 3000]\n",
      "loss: 0.105324  [ 2360/ 3000]\n",
      "loss: 0.048908  [ 2368/ 3000]\n",
      "loss: 0.030952  [ 2376/ 3000]\n",
      "loss: 0.058289  [ 2384/ 3000]\n",
      "loss: 0.059138  [ 2392/ 3000]\n",
      "loss: 0.012369  [ 2400/ 3000]\n",
      "loss: 0.126229  [ 2408/ 3000]\n",
      "loss: 0.084498  [ 2416/ 3000]\n",
      "loss: 0.087446  [ 2424/ 3000]\n",
      "loss: 0.099394  [ 2432/ 3000]\n",
      "loss: 0.055385  [ 2440/ 3000]\n",
      "loss: 0.118530  [ 2448/ 3000]\n",
      "loss: 0.121666  [ 2456/ 3000]\n",
      "loss: 0.053217  [ 2464/ 3000]\n",
      "loss: 0.240753  [ 2472/ 3000]\n",
      "loss: 0.029752  [ 2480/ 3000]\n",
      "loss: 0.060168  [ 2488/ 3000]\n",
      "loss: 0.019362  [ 2496/ 3000]\n",
      "loss: 0.040091  [ 2504/ 3000]\n",
      "loss: 0.125728  [ 2512/ 3000]\n",
      "loss: 0.222279  [ 2520/ 3000]\n",
      "loss: 0.037550  [ 2528/ 3000]\n",
      "loss: 0.066889  [ 2536/ 3000]\n",
      "loss: 0.022204  [ 2544/ 3000]\n",
      "loss: 0.099886  [ 2552/ 3000]\n",
      "loss: 0.093393  [ 2560/ 3000]\n",
      "loss: 0.139920  [ 2568/ 3000]\n",
      "loss: 0.121100  [ 2576/ 3000]\n",
      "loss: 0.069113  [ 2584/ 3000]\n",
      "loss: 0.054089  [ 2592/ 3000]\n",
      "loss: 0.074314  [ 2600/ 3000]\n",
      "loss: 0.090842  [ 2608/ 3000]\n",
      "loss: 0.035183  [ 2616/ 3000]\n",
      "loss: 0.037376  [ 2624/ 3000]\n",
      "loss: 0.115181  [ 2632/ 3000]\n",
      "loss: 0.130157  [ 2640/ 3000]\n",
      "loss: 0.085175  [ 2648/ 3000]\n",
      "loss: 0.090607  [ 2656/ 3000]\n",
      "loss: 0.061738  [ 2664/ 3000]\n",
      "loss: 0.113444  [ 2672/ 3000]\n",
      "loss: 0.128984  [ 2680/ 3000]\n",
      "loss: 0.056142  [ 2688/ 3000]\n",
      "loss: 0.044463  [ 2696/ 3000]\n",
      "loss: 0.086888  [ 2704/ 3000]\n",
      "loss: 0.088231  [ 2712/ 3000]\n",
      "loss: 0.063980  [ 2720/ 3000]\n",
      "loss: 0.118333  [ 2728/ 3000]\n",
      "loss: 0.033273  [ 2736/ 3000]\n",
      "loss: 0.074276  [ 2744/ 3000]\n",
      "loss: 0.093816  [ 2752/ 3000]\n",
      "loss: 0.065941  [ 2760/ 3000]\n",
      "loss: 0.024236  [ 2768/ 3000]\n",
      "loss: 0.122864  [ 2776/ 3000]\n",
      "loss: 0.078811  [ 2784/ 3000]\n",
      "loss: 0.048079  [ 2792/ 3000]\n",
      "loss: 0.111918  [ 2800/ 3000]\n",
      "loss: 0.160537  [ 2808/ 3000]\n",
      "loss: 0.072615  [ 2816/ 3000]\n",
      "loss: 0.085032  [ 2824/ 3000]\n",
      "loss: 0.087526  [ 2832/ 3000]\n",
      "loss: 0.062576  [ 2840/ 3000]\n",
      "loss: 0.061901  [ 2848/ 3000]\n",
      "loss: 0.088312  [ 2856/ 3000]\n",
      "loss: 0.039020  [ 2864/ 3000]\n",
      "loss: 0.095007  [ 2872/ 3000]\n",
      "loss: 0.114611  [ 2880/ 3000]\n",
      "loss: 0.020505  [ 2888/ 3000]\n",
      "loss: 0.017333  [ 2896/ 3000]\n",
      "loss: 0.075171  [ 2904/ 3000]\n",
      "loss: 0.100767  [ 2912/ 3000]\n",
      "loss: 0.068811  [ 2920/ 3000]\n",
      "loss: 0.119426  [ 2928/ 3000]\n",
      "loss: 0.181833  [ 2936/ 3000]\n",
      "loss: 0.033930  [ 2944/ 3000]\n",
      "loss: 0.006583  [ 2952/ 3000]\n",
      "loss: 0.033922  [ 2960/ 3000]\n",
      "loss: 0.064080  [ 2968/ 3000]\n",
      "loss: 0.056853  [ 2976/ 3000]\n",
      "loss: 0.069060  [ 2984/ 3000]\n",
      "loss: 0.014595  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.088237 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.032741  [    0/ 3000]\n",
      "loss: 0.078046  [    8/ 3000]\n",
      "loss: 0.028974  [   16/ 3000]\n",
      "loss: 0.036888  [   24/ 3000]\n",
      "loss: 0.119385  [   32/ 3000]\n",
      "loss: 0.022332  [   40/ 3000]\n",
      "loss: 0.026615  [   48/ 3000]\n",
      "loss: 0.081548  [   56/ 3000]\n",
      "loss: 0.163979  [   64/ 3000]\n",
      "loss: 0.024936  [   72/ 3000]\n",
      "loss: 0.155513  [   80/ 3000]\n",
      "loss: 0.088366  [   88/ 3000]\n",
      "loss: 0.111302  [   96/ 3000]\n",
      "loss: 0.060178  [  104/ 3000]\n",
      "loss: 0.173693  [  112/ 3000]\n",
      "loss: 0.042263  [  120/ 3000]\n",
      "loss: 0.037338  [  128/ 3000]\n",
      "loss: 0.094415  [  136/ 3000]\n",
      "loss: 0.086432  [  144/ 3000]\n",
      "loss: 0.050020  [  152/ 3000]\n",
      "loss: 0.024584  [  160/ 3000]\n",
      "loss: 0.016558  [  168/ 3000]\n",
      "loss: 0.037186  [  176/ 3000]\n",
      "loss: 0.097448  [  184/ 3000]\n",
      "loss: 0.064985  [  192/ 3000]\n",
      "loss: 0.043781  [  200/ 3000]\n",
      "loss: 0.170174  [  208/ 3000]\n",
      "loss: 0.047604  [  216/ 3000]\n",
      "loss: 0.060519  [  224/ 3000]\n",
      "loss: 0.138288  [  232/ 3000]\n",
      "loss: 0.065018  [  240/ 3000]\n",
      "loss: 0.048876  [  248/ 3000]\n",
      "loss: 0.034088  [  256/ 3000]\n",
      "loss: 0.096999  [  264/ 3000]\n",
      "loss: 0.053981  [  272/ 3000]\n",
      "loss: 0.176718  [  280/ 3000]\n",
      "loss: 0.031326  [  288/ 3000]\n",
      "loss: 0.061012  [  296/ 3000]\n",
      "loss: 0.043968  [  304/ 3000]\n",
      "loss: 0.118013  [  312/ 3000]\n",
      "loss: 0.053176  [  320/ 3000]\n",
      "loss: 0.147686  [  328/ 3000]\n",
      "loss: 0.049917  [  336/ 3000]\n",
      "loss: 0.093549  [  344/ 3000]\n",
      "loss: 0.025813  [  352/ 3000]\n",
      "loss: 0.037301  [  360/ 3000]\n",
      "loss: 0.132810  [  368/ 3000]\n",
      "loss: 0.029023  [  376/ 3000]\n",
      "loss: 0.099968  [  384/ 3000]\n",
      "loss: 0.063757  [  392/ 3000]\n",
      "loss: 0.096913  [  400/ 3000]\n",
      "loss: 0.038244  [  408/ 3000]\n",
      "loss: 0.106889  [  416/ 3000]\n",
      "loss: 0.054449  [  424/ 3000]\n",
      "loss: 0.179883  [  432/ 3000]\n",
      "loss: 0.046583  [  440/ 3000]\n",
      "loss: 0.084235  [  448/ 3000]\n",
      "loss: 0.053717  [  456/ 3000]\n",
      "loss: 0.130503  [  464/ 3000]\n",
      "loss: 0.067457  [  472/ 3000]\n",
      "loss: 0.020448  [  480/ 3000]\n",
      "loss: 0.142504  [  488/ 3000]\n",
      "loss: 0.101243  [  496/ 3000]\n",
      "loss: 0.048048  [  504/ 3000]\n",
      "loss: 0.075783  [  512/ 3000]\n",
      "loss: 0.048322  [  520/ 3000]\n",
      "loss: 0.219559  [  528/ 3000]\n",
      "loss: 0.107355  [  536/ 3000]\n",
      "loss: 0.097879  [  544/ 3000]\n",
      "loss: 0.060493  [  552/ 3000]\n",
      "loss: 0.046616  [  560/ 3000]\n",
      "loss: 0.099907  [  568/ 3000]\n",
      "loss: 0.063957  [  576/ 3000]\n",
      "loss: 0.074970  [  584/ 3000]\n",
      "loss: 0.040411  [  592/ 3000]\n",
      "loss: 0.152633  [  600/ 3000]\n",
      "loss: 0.043693  [  608/ 3000]\n",
      "loss: 0.103283  [  616/ 3000]\n",
      "loss: 0.069935  [  624/ 3000]\n",
      "loss: 0.198255  [  632/ 3000]\n",
      "loss: 0.021416  [  640/ 3000]\n",
      "loss: 0.157468  [  648/ 3000]\n",
      "loss: 0.211035  [  656/ 3000]\n",
      "loss: 0.173188  [  664/ 3000]\n",
      "loss: 0.079232  [  672/ 3000]\n",
      "loss: 0.089689  [  680/ 3000]\n",
      "loss: 0.061192  [  688/ 3000]\n",
      "loss: 0.183556  [  696/ 3000]\n",
      "loss: 0.073016  [  704/ 3000]\n",
      "loss: 0.054181  [  712/ 3000]\n",
      "loss: 0.064667  [  720/ 3000]\n",
      "loss: 0.039236  [  728/ 3000]\n",
      "loss: 0.069443  [  736/ 3000]\n",
      "loss: 0.040677  [  744/ 3000]\n",
      "loss: 0.102231  [  752/ 3000]\n",
      "loss: 0.076613  [  760/ 3000]\n",
      "loss: 0.130346  [  768/ 3000]\n",
      "loss: 0.070054  [  776/ 3000]\n",
      "loss: 0.166674  [  784/ 3000]\n",
      "loss: 0.089592  [  792/ 3000]\n",
      "loss: 0.176639  [  800/ 3000]\n",
      "loss: 0.068148  [  808/ 3000]\n",
      "loss: 0.038723  [  816/ 3000]\n",
      "loss: 0.057551  [  824/ 3000]\n",
      "loss: 0.065823  [  832/ 3000]\n",
      "loss: 0.029915  [  840/ 3000]\n",
      "loss: 0.023451  [  848/ 3000]\n",
      "loss: 0.032044  [  856/ 3000]\n",
      "loss: 0.096039  [  864/ 3000]\n",
      "loss: 0.017489  [  872/ 3000]\n",
      "loss: 0.087655  [  880/ 3000]\n",
      "loss: 0.107798  [  888/ 3000]\n",
      "loss: 0.072401  [  896/ 3000]\n",
      "loss: 0.206376  [  904/ 3000]\n",
      "loss: 0.061955  [  912/ 3000]\n",
      "loss: 0.069944  [  920/ 3000]\n",
      "loss: 0.080792  [  928/ 3000]\n",
      "loss: 0.054898  [  936/ 3000]\n",
      "loss: 0.186179  [  944/ 3000]\n",
      "loss: 0.040302  [  952/ 3000]\n",
      "loss: 0.056864  [  960/ 3000]\n",
      "loss: 0.031776  [  968/ 3000]\n",
      "loss: 0.016109  [  976/ 3000]\n",
      "loss: 0.019438  [  984/ 3000]\n",
      "loss: 0.136663  [  992/ 3000]\n",
      "loss: 0.084471  [ 1000/ 3000]\n",
      "loss: 0.070835  [ 1008/ 3000]\n",
      "loss: 0.130541  [ 1016/ 3000]\n",
      "loss: 0.070944  [ 1024/ 3000]\n",
      "loss: 0.114155  [ 1032/ 3000]\n",
      "loss: 0.020881  [ 1040/ 3000]\n",
      "loss: 0.049631  [ 1048/ 3000]\n",
      "loss: 0.027254  [ 1056/ 3000]\n",
      "loss: 0.084727  [ 1064/ 3000]\n",
      "loss: 0.051847  [ 1072/ 3000]\n",
      "loss: 0.059230  [ 1080/ 3000]\n",
      "loss: 0.117133  [ 1088/ 3000]\n",
      "loss: 0.103703  [ 1096/ 3000]\n",
      "loss: 0.025336  [ 1104/ 3000]\n",
      "loss: 0.115938  [ 1112/ 3000]\n",
      "loss: 0.037204  [ 1120/ 3000]\n",
      "loss: 0.053651  [ 1128/ 3000]\n",
      "loss: 0.055351  [ 1136/ 3000]\n",
      "loss: 0.142897  [ 1144/ 3000]\n",
      "loss: 0.045377  [ 1152/ 3000]\n",
      "loss: 0.034297  [ 1160/ 3000]\n",
      "loss: 0.039072  [ 1168/ 3000]\n",
      "loss: 0.033489  [ 1176/ 3000]\n",
      "loss: 0.185507  [ 1184/ 3000]\n",
      "loss: 0.066317  [ 1192/ 3000]\n",
      "loss: 0.054471  [ 1200/ 3000]\n",
      "loss: 0.043818  [ 1208/ 3000]\n",
      "loss: 0.057230  [ 1216/ 3000]\n",
      "loss: 0.090357  [ 1224/ 3000]\n",
      "loss: 0.102845  [ 1232/ 3000]\n",
      "loss: 0.091458  [ 1240/ 3000]\n",
      "loss: 0.101946  [ 1248/ 3000]\n",
      "loss: 0.015666  [ 1256/ 3000]\n",
      "loss: 0.053300  [ 1264/ 3000]\n",
      "loss: 0.030203  [ 1272/ 3000]\n",
      "loss: 0.040433  [ 1280/ 3000]\n",
      "loss: 0.079759  [ 1288/ 3000]\n",
      "loss: 0.032256  [ 1296/ 3000]\n",
      "loss: 0.005699  [ 1304/ 3000]\n",
      "loss: 0.109840  [ 1312/ 3000]\n",
      "loss: 0.277657  [ 1320/ 3000]\n",
      "loss: 0.110967  [ 1328/ 3000]\n",
      "loss: 0.079855  [ 1336/ 3000]\n",
      "loss: 0.143116  [ 1344/ 3000]\n",
      "loss: 0.088978  [ 1352/ 3000]\n",
      "loss: 0.040579  [ 1360/ 3000]\n",
      "loss: 0.126196  [ 1368/ 3000]\n",
      "loss: 0.143333  [ 1376/ 3000]\n",
      "loss: 0.077260  [ 1384/ 3000]\n",
      "loss: 0.047071  [ 1392/ 3000]\n",
      "loss: 0.097155  [ 1400/ 3000]\n",
      "loss: 0.090095  [ 1408/ 3000]\n",
      "loss: 0.094895  [ 1416/ 3000]\n",
      "loss: 0.132744  [ 1424/ 3000]\n",
      "loss: 0.071773  [ 1432/ 3000]\n",
      "loss: 0.042535  [ 1440/ 3000]\n",
      "loss: 0.041915  [ 1448/ 3000]\n",
      "loss: 0.070823  [ 1456/ 3000]\n",
      "loss: 0.010139  [ 1464/ 3000]\n",
      "loss: 0.051304  [ 1472/ 3000]\n",
      "loss: 0.025343  [ 1480/ 3000]\n",
      "loss: 0.141098  [ 1488/ 3000]\n",
      "loss: 0.035115  [ 1496/ 3000]\n",
      "loss: 0.059188  [ 1504/ 3000]\n",
      "loss: 0.092962  [ 1512/ 3000]\n",
      "loss: 0.085518  [ 1520/ 3000]\n",
      "loss: 0.034588  [ 1528/ 3000]\n",
      "loss: 0.087631  [ 1536/ 3000]\n",
      "loss: 0.041100  [ 1544/ 3000]\n",
      "loss: 0.121002  [ 1552/ 3000]\n",
      "loss: 0.050047  [ 1560/ 3000]\n",
      "loss: 0.045264  [ 1568/ 3000]\n",
      "loss: 0.029747  [ 1576/ 3000]\n",
      "loss: 0.108004  [ 1584/ 3000]\n",
      "loss: 0.059803  [ 1592/ 3000]\n",
      "loss: 0.099728  [ 1600/ 3000]\n",
      "loss: 0.043346  [ 1608/ 3000]\n",
      "loss: 0.142374  [ 1616/ 3000]\n",
      "loss: 0.115760  [ 1624/ 3000]\n",
      "loss: 0.050362  [ 1632/ 3000]\n",
      "loss: 0.052868  [ 1640/ 3000]\n",
      "loss: 0.128157  [ 1648/ 3000]\n",
      "loss: 0.041163  [ 1656/ 3000]\n",
      "loss: 0.132103  [ 1664/ 3000]\n",
      "loss: 0.026839  [ 1672/ 3000]\n",
      "loss: 0.052559  [ 1680/ 3000]\n",
      "loss: 0.066838  [ 1688/ 3000]\n",
      "loss: 0.097062  [ 1696/ 3000]\n",
      "loss: 0.058005  [ 1704/ 3000]\n",
      "loss: 0.027313  [ 1712/ 3000]\n",
      "loss: 0.042135  [ 1720/ 3000]\n",
      "loss: 0.062574  [ 1728/ 3000]\n",
      "loss: 0.091837  [ 1736/ 3000]\n",
      "loss: 0.081733  [ 1744/ 3000]\n",
      "loss: 0.020876  [ 1752/ 3000]\n",
      "loss: 0.011221  [ 1760/ 3000]\n",
      "loss: 0.117938  [ 1768/ 3000]\n",
      "loss: 0.070302  [ 1776/ 3000]\n",
      "loss: 0.031468  [ 1784/ 3000]\n",
      "loss: 0.051832  [ 1792/ 3000]\n",
      "loss: 0.100506  [ 1800/ 3000]\n",
      "loss: 0.136844  [ 1808/ 3000]\n",
      "loss: 0.040349  [ 1816/ 3000]\n",
      "loss: 0.132007  [ 1824/ 3000]\n",
      "loss: 0.007988  [ 1832/ 3000]\n",
      "loss: 0.011091  [ 1840/ 3000]\n",
      "loss: 0.058264  [ 1848/ 3000]\n",
      "loss: 0.082924  [ 1856/ 3000]\n",
      "loss: 0.082679  [ 1864/ 3000]\n",
      "loss: 0.072799  [ 1872/ 3000]\n",
      "loss: 0.015380  [ 1880/ 3000]\n",
      "loss: 0.023255  [ 1888/ 3000]\n",
      "loss: 0.073464  [ 1896/ 3000]\n",
      "loss: 0.033524  [ 1904/ 3000]\n",
      "loss: 0.042198  [ 1912/ 3000]\n",
      "loss: 0.106659  [ 1920/ 3000]\n",
      "loss: 0.086111  [ 1928/ 3000]\n",
      "loss: 0.135851  [ 1936/ 3000]\n",
      "loss: 0.017756  [ 1944/ 3000]\n",
      "loss: 0.095350  [ 1952/ 3000]\n",
      "loss: 0.033960  [ 1960/ 3000]\n",
      "loss: 0.111660  [ 1968/ 3000]\n",
      "loss: 0.035497  [ 1976/ 3000]\n",
      "loss: 0.124089  [ 1984/ 3000]\n",
      "loss: 0.130889  [ 1992/ 3000]\n",
      "loss: 0.071773  [ 2000/ 3000]\n",
      "loss: 0.102606  [ 2008/ 3000]\n",
      "loss: 0.062272  [ 2016/ 3000]\n",
      "loss: 0.060311  [ 2024/ 3000]\n",
      "loss: 0.101114  [ 2032/ 3000]\n",
      "loss: 0.084929  [ 2040/ 3000]\n",
      "loss: 0.040001  [ 2048/ 3000]\n",
      "loss: 0.041486  [ 2056/ 3000]\n",
      "loss: 0.031240  [ 2064/ 3000]\n",
      "loss: 0.118033  [ 2072/ 3000]\n",
      "loss: 0.051655  [ 2080/ 3000]\n",
      "loss: 0.109947  [ 2088/ 3000]\n",
      "loss: 0.079092  [ 2096/ 3000]\n",
      "loss: 0.050771  [ 2104/ 3000]\n",
      "loss: 0.032509  [ 2112/ 3000]\n",
      "loss: 0.017782  [ 2120/ 3000]\n",
      "loss: 0.070328  [ 2128/ 3000]\n",
      "loss: 0.069106  [ 2136/ 3000]\n",
      "loss: 0.107892  [ 2144/ 3000]\n",
      "loss: 0.137165  [ 2152/ 3000]\n",
      "loss: 0.027166  [ 2160/ 3000]\n",
      "loss: 0.068216  [ 2168/ 3000]\n",
      "loss: 0.029082  [ 2176/ 3000]\n",
      "loss: 0.094300  [ 2184/ 3000]\n",
      "loss: 0.077079  [ 2192/ 3000]\n",
      "loss: 0.035019  [ 2200/ 3000]\n",
      "loss: 0.021478  [ 2208/ 3000]\n",
      "loss: 0.040058  [ 2216/ 3000]\n",
      "loss: 0.103846  [ 2224/ 3000]\n",
      "loss: 0.076876  [ 2232/ 3000]\n",
      "loss: 0.123625  [ 2240/ 3000]\n",
      "loss: 0.014691  [ 2248/ 3000]\n",
      "loss: 0.061354  [ 2256/ 3000]\n",
      "loss: 0.023340  [ 2264/ 3000]\n",
      "loss: 0.133808  [ 2272/ 3000]\n",
      "loss: 0.045664  [ 2280/ 3000]\n",
      "loss: 0.122456  [ 2288/ 3000]\n",
      "loss: 0.068678  [ 2296/ 3000]\n",
      "loss: 0.053925  [ 2304/ 3000]\n",
      "loss: 0.030304  [ 2312/ 3000]\n",
      "loss: 0.024566  [ 2320/ 3000]\n",
      "loss: 0.081155  [ 2328/ 3000]\n",
      "loss: 0.016513  [ 2336/ 3000]\n",
      "loss: 0.116609  [ 2344/ 3000]\n",
      "loss: 0.117149  [ 2352/ 3000]\n",
      "loss: 0.103810  [ 2360/ 3000]\n",
      "loss: 0.047209  [ 2368/ 3000]\n",
      "loss: 0.029962  [ 2376/ 3000]\n",
      "loss: 0.056948  [ 2384/ 3000]\n",
      "loss: 0.057509  [ 2392/ 3000]\n",
      "loss: 0.011568  [ 2400/ 3000]\n",
      "loss: 0.124173  [ 2408/ 3000]\n",
      "loss: 0.083036  [ 2416/ 3000]\n",
      "loss: 0.084736  [ 2424/ 3000]\n",
      "loss: 0.096888  [ 2432/ 3000]\n",
      "loss: 0.054141  [ 2440/ 3000]\n",
      "loss: 0.115225  [ 2448/ 3000]\n",
      "loss: 0.119001  [ 2456/ 3000]\n",
      "loss: 0.051610  [ 2464/ 3000]\n",
      "loss: 0.237597  [ 2472/ 3000]\n",
      "loss: 0.029105  [ 2480/ 3000]\n",
      "loss: 0.058274  [ 2488/ 3000]\n",
      "loss: 0.018250  [ 2496/ 3000]\n",
      "loss: 0.038533  [ 2504/ 3000]\n",
      "loss: 0.122450  [ 2512/ 3000]\n",
      "loss: 0.218879  [ 2520/ 3000]\n",
      "loss: 0.035978  [ 2528/ 3000]\n",
      "loss: 0.065386  [ 2536/ 3000]\n",
      "loss: 0.021138  [ 2544/ 3000]\n",
      "loss: 0.097133  [ 2552/ 3000]\n",
      "loss: 0.091615  [ 2560/ 3000]\n",
      "loss: 0.137786  [ 2568/ 3000]\n",
      "loss: 0.117912  [ 2576/ 3000]\n",
      "loss: 0.066972  [ 2584/ 3000]\n",
      "loss: 0.052423  [ 2592/ 3000]\n",
      "loss: 0.073199  [ 2600/ 3000]\n",
      "loss: 0.088801  [ 2608/ 3000]\n",
      "loss: 0.033853  [ 2616/ 3000]\n",
      "loss: 0.035770  [ 2624/ 3000]\n",
      "loss: 0.112979  [ 2632/ 3000]\n",
      "loss: 0.127575  [ 2640/ 3000]\n",
      "loss: 0.083252  [ 2648/ 3000]\n",
      "loss: 0.088076  [ 2656/ 3000]\n",
      "loss: 0.059980  [ 2664/ 3000]\n",
      "loss: 0.110443  [ 2672/ 3000]\n",
      "loss: 0.125748  [ 2680/ 3000]\n",
      "loss: 0.054716  [ 2688/ 3000]\n",
      "loss: 0.043096  [ 2696/ 3000]\n",
      "loss: 0.085449  [ 2704/ 3000]\n",
      "loss: 0.084903  [ 2712/ 3000]\n",
      "loss: 0.061637  [ 2720/ 3000]\n",
      "loss: 0.114722  [ 2728/ 3000]\n",
      "loss: 0.032418  [ 2736/ 3000]\n",
      "loss: 0.072216  [ 2744/ 3000]\n",
      "loss: 0.090854  [ 2752/ 3000]\n",
      "loss: 0.064339  [ 2760/ 3000]\n",
      "loss: 0.023243  [ 2768/ 3000]\n",
      "loss: 0.119176  [ 2776/ 3000]\n",
      "loss: 0.076941  [ 2784/ 3000]\n",
      "loss: 0.046389  [ 2792/ 3000]\n",
      "loss: 0.109426  [ 2800/ 3000]\n",
      "loss: 0.157358  [ 2808/ 3000]\n",
      "loss: 0.069943  [ 2816/ 3000]\n",
      "loss: 0.083129  [ 2824/ 3000]\n",
      "loss: 0.085279  [ 2832/ 3000]\n",
      "loss: 0.060880  [ 2840/ 3000]\n",
      "loss: 0.059628  [ 2848/ 3000]\n",
      "loss: 0.085811  [ 2856/ 3000]\n",
      "loss: 0.037452  [ 2864/ 3000]\n",
      "loss: 0.093391  [ 2872/ 3000]\n",
      "loss: 0.111406  [ 2880/ 3000]\n",
      "loss: 0.019199  [ 2888/ 3000]\n",
      "loss: 0.016530  [ 2896/ 3000]\n",
      "loss: 0.072142  [ 2904/ 3000]\n",
      "loss: 0.098646  [ 2912/ 3000]\n",
      "loss: 0.066472  [ 2920/ 3000]\n",
      "loss: 0.116457  [ 2928/ 3000]\n",
      "loss: 0.176834  [ 2936/ 3000]\n",
      "loss: 0.032855  [ 2944/ 3000]\n",
      "loss: 0.006310  [ 2952/ 3000]\n",
      "loss: 0.033007  [ 2960/ 3000]\n",
      "loss: 0.062588  [ 2968/ 3000]\n",
      "loss: 0.055674  [ 2976/ 3000]\n",
      "loss: 0.067816  [ 2984/ 3000]\n",
      "loss: 0.013805  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.087695 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.031549  [    0/ 3000]\n",
      "loss: 0.075931  [    8/ 3000]\n",
      "loss: 0.027291  [   16/ 3000]\n",
      "loss: 0.035218  [   24/ 3000]\n",
      "loss: 0.115586  [   32/ 3000]\n",
      "loss: 0.021154  [   40/ 3000]\n",
      "loss: 0.025776  [   48/ 3000]\n",
      "loss: 0.079941  [   56/ 3000]\n",
      "loss: 0.159944  [   64/ 3000]\n",
      "loss: 0.024344  [   72/ 3000]\n",
      "loss: 0.153102  [   80/ 3000]\n",
      "loss: 0.085548  [   88/ 3000]\n",
      "loss: 0.108188  [   96/ 3000]\n",
      "loss: 0.057218  [  104/ 3000]\n",
      "loss: 0.170644  [  112/ 3000]\n",
      "loss: 0.040686  [  120/ 3000]\n",
      "loss: 0.036435  [  128/ 3000]\n",
      "loss: 0.091184  [  136/ 3000]\n",
      "loss: 0.084326  [  144/ 3000]\n",
      "loss: 0.048405  [  152/ 3000]\n",
      "loss: 0.023676  [  160/ 3000]\n",
      "loss: 0.015828  [  168/ 3000]\n",
      "loss: 0.035551  [  176/ 3000]\n",
      "loss: 0.095251  [  184/ 3000]\n",
      "loss: 0.062667  [  192/ 3000]\n",
      "loss: 0.042606  [  200/ 3000]\n",
      "loss: 0.167264  [  208/ 3000]\n",
      "loss: 0.046281  [  216/ 3000]\n",
      "loss: 0.058852  [  224/ 3000]\n",
      "loss: 0.134777  [  232/ 3000]\n",
      "loss: 0.063356  [  240/ 3000]\n",
      "loss: 0.047309  [  248/ 3000]\n",
      "loss: 0.032950  [  256/ 3000]\n",
      "loss: 0.093726  [  264/ 3000]\n",
      "loss: 0.053038  [  272/ 3000]\n",
      "loss: 0.174269  [  280/ 3000]\n",
      "loss: 0.030144  [  288/ 3000]\n",
      "loss: 0.059652  [  296/ 3000]\n",
      "loss: 0.042647  [  304/ 3000]\n",
      "loss: 0.115465  [  312/ 3000]\n",
      "loss: 0.051176  [  320/ 3000]\n",
      "loss: 0.142456  [  328/ 3000]\n",
      "loss: 0.047638  [  336/ 3000]\n",
      "loss: 0.092272  [  344/ 3000]\n",
      "loss: 0.024808  [  352/ 3000]\n",
      "loss: 0.036446  [  360/ 3000]\n",
      "loss: 0.130206  [  368/ 3000]\n",
      "loss: 0.027647  [  376/ 3000]\n",
      "loss: 0.098117  [  384/ 3000]\n",
      "loss: 0.061693  [  392/ 3000]\n",
      "loss: 0.094128  [  400/ 3000]\n",
      "loss: 0.037226  [  408/ 3000]\n",
      "loss: 0.103840  [  416/ 3000]\n",
      "loss: 0.052581  [  424/ 3000]\n",
      "loss: 0.176247  [  432/ 3000]\n",
      "loss: 0.045142  [  440/ 3000]\n",
      "loss: 0.082111  [  448/ 3000]\n",
      "loss: 0.051808  [  456/ 3000]\n",
      "loss: 0.126883  [  464/ 3000]\n",
      "loss: 0.066158  [  472/ 3000]\n",
      "loss: 0.019734  [  480/ 3000]\n",
      "loss: 0.139434  [  488/ 3000]\n",
      "loss: 0.100063  [  496/ 3000]\n",
      "loss: 0.046228  [  504/ 3000]\n",
      "loss: 0.074234  [  512/ 3000]\n",
      "loss: 0.047403  [  520/ 3000]\n",
      "loss: 0.215166  [  528/ 3000]\n",
      "loss: 0.104725  [  536/ 3000]\n",
      "loss: 0.095272  [  544/ 3000]\n",
      "loss: 0.058312  [  552/ 3000]\n",
      "loss: 0.045013  [  560/ 3000]\n",
      "loss: 0.097549  [  568/ 3000]\n",
      "loss: 0.061759  [  576/ 3000]\n",
      "loss: 0.072467  [  584/ 3000]\n",
      "loss: 0.039095  [  592/ 3000]\n",
      "loss: 0.148181  [  600/ 3000]\n",
      "loss: 0.042671  [  608/ 3000]\n",
      "loss: 0.100606  [  616/ 3000]\n",
      "loss: 0.068061  [  624/ 3000]\n",
      "loss: 0.194706  [  632/ 3000]\n",
      "loss: 0.020421  [  640/ 3000]\n",
      "loss: 0.153981  [  648/ 3000]\n",
      "loss: 0.206267  [  656/ 3000]\n",
      "loss: 0.170168  [  664/ 3000]\n",
      "loss: 0.077105  [  672/ 3000]\n",
      "loss: 0.087818  [  680/ 3000]\n",
      "loss: 0.059661  [  688/ 3000]\n",
      "loss: 0.179358  [  696/ 3000]\n",
      "loss: 0.071975  [  704/ 3000]\n",
      "loss: 0.052638  [  712/ 3000]\n",
      "loss: 0.063248  [  720/ 3000]\n",
      "loss: 0.038006  [  728/ 3000]\n",
      "loss: 0.068046  [  736/ 3000]\n",
      "loss: 0.038634  [  744/ 3000]\n",
      "loss: 0.099315  [  752/ 3000]\n",
      "loss: 0.074158  [  760/ 3000]\n",
      "loss: 0.128622  [  768/ 3000]\n",
      "loss: 0.068453  [  776/ 3000]\n",
      "loss: 0.162392  [  784/ 3000]\n",
      "loss: 0.086425  [  792/ 3000]\n",
      "loss: 0.174341  [  800/ 3000]\n",
      "loss: 0.066402  [  808/ 3000]\n",
      "loss: 0.037277  [  816/ 3000]\n",
      "loss: 0.056209  [  824/ 3000]\n",
      "loss: 0.063934  [  832/ 3000]\n",
      "loss: 0.028581  [  840/ 3000]\n",
      "loss: 0.022637  [  848/ 3000]\n",
      "loss: 0.031081  [  856/ 3000]\n",
      "loss: 0.093539  [  864/ 3000]\n",
      "loss: 0.016578  [  872/ 3000]\n",
      "loss: 0.086087  [  880/ 3000]\n",
      "loss: 0.104867  [  888/ 3000]\n",
      "loss: 0.071600  [  896/ 3000]\n",
      "loss: 0.202000  [  904/ 3000]\n",
      "loss: 0.060692  [  912/ 3000]\n",
      "loss: 0.068312  [  920/ 3000]\n",
      "loss: 0.078848  [  928/ 3000]\n",
      "loss: 0.052874  [  936/ 3000]\n",
      "loss: 0.181741  [  944/ 3000]\n",
      "loss: 0.038740  [  952/ 3000]\n",
      "loss: 0.055487  [  960/ 3000]\n",
      "loss: 0.030696  [  968/ 3000]\n",
      "loss: 0.015406  [  976/ 3000]\n",
      "loss: 0.018477  [  984/ 3000]\n",
      "loss: 0.133413  [  992/ 3000]\n",
      "loss: 0.082129  [ 1000/ 3000]\n",
      "loss: 0.069182  [ 1008/ 3000]\n",
      "loss: 0.127400  [ 1016/ 3000]\n",
      "loss: 0.069159  [ 1024/ 3000]\n",
      "loss: 0.111091  [ 1032/ 3000]\n",
      "loss: 0.020056  [ 1040/ 3000]\n",
      "loss: 0.048152  [ 1048/ 3000]\n",
      "loss: 0.026268  [ 1056/ 3000]\n",
      "loss: 0.082642  [ 1064/ 3000]\n",
      "loss: 0.050286  [ 1072/ 3000]\n",
      "loss: 0.057695  [ 1080/ 3000]\n",
      "loss: 0.113837  [ 1088/ 3000]\n",
      "loss: 0.101221  [ 1096/ 3000]\n",
      "loss: 0.024144  [ 1104/ 3000]\n",
      "loss: 0.112745  [ 1112/ 3000]\n",
      "loss: 0.035975  [ 1120/ 3000]\n",
      "loss: 0.052712  [ 1128/ 3000]\n",
      "loss: 0.053329  [ 1136/ 3000]\n",
      "loss: 0.138888  [ 1144/ 3000]\n",
      "loss: 0.044070  [ 1152/ 3000]\n",
      "loss: 0.033372  [ 1160/ 3000]\n",
      "loss: 0.037701  [ 1168/ 3000]\n",
      "loss: 0.032229  [ 1176/ 3000]\n",
      "loss: 0.181530  [ 1184/ 3000]\n",
      "loss: 0.064573  [ 1192/ 3000]\n",
      "loss: 0.051974  [ 1200/ 3000]\n",
      "loss: 0.042726  [ 1208/ 3000]\n",
      "loss: 0.054964  [ 1216/ 3000]\n",
      "loss: 0.087484  [ 1224/ 3000]\n",
      "loss: 0.099873  [ 1232/ 3000]\n",
      "loss: 0.089145  [ 1240/ 3000]\n",
      "loss: 0.098801  [ 1248/ 3000]\n",
      "loss: 0.014882  [ 1256/ 3000]\n",
      "loss: 0.052583  [ 1264/ 3000]\n",
      "loss: 0.029224  [ 1272/ 3000]\n",
      "loss: 0.038396  [ 1280/ 3000]\n",
      "loss: 0.076762  [ 1288/ 3000]\n",
      "loss: 0.030812  [ 1296/ 3000]\n",
      "loss: 0.005325  [ 1304/ 3000]\n",
      "loss: 0.106675  [ 1312/ 3000]\n",
      "loss: 0.270561  [ 1320/ 3000]\n",
      "loss: 0.107590  [ 1328/ 3000]\n",
      "loss: 0.078143  [ 1336/ 3000]\n",
      "loss: 0.139359  [ 1344/ 3000]\n",
      "loss: 0.087053  [ 1352/ 3000]\n",
      "loss: 0.038545  [ 1360/ 3000]\n",
      "loss: 0.123547  [ 1368/ 3000]\n",
      "loss: 0.140906  [ 1376/ 3000]\n",
      "loss: 0.074484  [ 1384/ 3000]\n",
      "loss: 0.045203  [ 1392/ 3000]\n",
      "loss: 0.094660  [ 1400/ 3000]\n",
      "loss: 0.088156  [ 1408/ 3000]\n",
      "loss: 0.092498  [ 1416/ 3000]\n",
      "loss: 0.130821  [ 1424/ 3000]\n",
      "loss: 0.069525  [ 1432/ 3000]\n",
      "loss: 0.041392  [ 1440/ 3000]\n",
      "loss: 0.040483  [ 1448/ 3000]\n",
      "loss: 0.068519  [ 1456/ 3000]\n",
      "loss: 0.009715  [ 1464/ 3000]\n",
      "loss: 0.050302  [ 1472/ 3000]\n",
      "loss: 0.024785  [ 1480/ 3000]\n",
      "loss: 0.139103  [ 1488/ 3000]\n",
      "loss: 0.033920  [ 1496/ 3000]\n",
      "loss: 0.057164  [ 1504/ 3000]\n",
      "loss: 0.091310  [ 1512/ 3000]\n",
      "loss: 0.083010  [ 1520/ 3000]\n",
      "loss: 0.032976  [ 1528/ 3000]\n",
      "loss: 0.085547  [ 1536/ 3000]\n",
      "loss: 0.039220  [ 1544/ 3000]\n",
      "loss: 0.118098  [ 1552/ 3000]\n",
      "loss: 0.048496  [ 1560/ 3000]\n",
      "loss: 0.043754  [ 1568/ 3000]\n",
      "loss: 0.028390  [ 1576/ 3000]\n",
      "loss: 0.105738  [ 1584/ 3000]\n",
      "loss: 0.058655  [ 1592/ 3000]\n",
      "loss: 0.097031  [ 1600/ 3000]\n",
      "loss: 0.042042  [ 1608/ 3000]\n",
      "loss: 0.139855  [ 1616/ 3000]\n",
      "loss: 0.113492  [ 1624/ 3000]\n",
      "loss: 0.049042  [ 1632/ 3000]\n",
      "loss: 0.051359  [ 1640/ 3000]\n",
      "loss: 0.125667  [ 1648/ 3000]\n",
      "loss: 0.040270  [ 1656/ 3000]\n",
      "loss: 0.127189  [ 1664/ 3000]\n",
      "loss: 0.025429  [ 1672/ 3000]\n",
      "loss: 0.051334  [ 1680/ 3000]\n",
      "loss: 0.065017  [ 1688/ 3000]\n",
      "loss: 0.094812  [ 1696/ 3000]\n",
      "loss: 0.056069  [ 1704/ 3000]\n",
      "loss: 0.026540  [ 1712/ 3000]\n",
      "loss: 0.039998  [ 1720/ 3000]\n",
      "loss: 0.061034  [ 1728/ 3000]\n",
      "loss: 0.089903  [ 1736/ 3000]\n",
      "loss: 0.079820  [ 1744/ 3000]\n",
      "loss: 0.020189  [ 1752/ 3000]\n",
      "loss: 0.010588  [ 1760/ 3000]\n",
      "loss: 0.114115  [ 1768/ 3000]\n",
      "loss: 0.067854  [ 1776/ 3000]\n",
      "loss: 0.030392  [ 1784/ 3000]\n",
      "loss: 0.050498  [ 1792/ 3000]\n",
      "loss: 0.097497  [ 1800/ 3000]\n",
      "loss: 0.133551  [ 1808/ 3000]\n",
      "loss: 0.039120  [ 1816/ 3000]\n",
      "loss: 0.128952  [ 1824/ 3000]\n",
      "loss: 0.007322  [ 1832/ 3000]\n",
      "loss: 0.010784  [ 1840/ 3000]\n",
      "loss: 0.056114  [ 1848/ 3000]\n",
      "loss: 0.080771  [ 1856/ 3000]\n",
      "loss: 0.080298  [ 1864/ 3000]\n",
      "loss: 0.071099  [ 1872/ 3000]\n",
      "loss: 0.014467  [ 1880/ 3000]\n",
      "loss: 0.021936  [ 1888/ 3000]\n",
      "loss: 0.070578  [ 1896/ 3000]\n",
      "loss: 0.033123  [ 1904/ 3000]\n",
      "loss: 0.040504  [ 1912/ 3000]\n",
      "loss: 0.104636  [ 1920/ 3000]\n",
      "loss: 0.083737  [ 1928/ 3000]\n",
      "loss: 0.132159  [ 1936/ 3000]\n",
      "loss: 0.016873  [ 1944/ 3000]\n",
      "loss: 0.093370  [ 1952/ 3000]\n",
      "loss: 0.032977  [ 1960/ 3000]\n",
      "loss: 0.109147  [ 1968/ 3000]\n",
      "loss: 0.034341  [ 1976/ 3000]\n",
      "loss: 0.121536  [ 1984/ 3000]\n",
      "loss: 0.128206  [ 1992/ 3000]\n",
      "loss: 0.069355  [ 2000/ 3000]\n",
      "loss: 0.099898  [ 2008/ 3000]\n",
      "loss: 0.059747  [ 2016/ 3000]\n",
      "loss: 0.059166  [ 2024/ 3000]\n",
      "loss: 0.098945  [ 2032/ 3000]\n",
      "loss: 0.083151  [ 2040/ 3000]\n",
      "loss: 0.038992  [ 2048/ 3000]\n",
      "loss: 0.040061  [ 2056/ 3000]\n",
      "loss: 0.029876  [ 2064/ 3000]\n",
      "loss: 0.114881  [ 2072/ 3000]\n",
      "loss: 0.050090  [ 2080/ 3000]\n",
      "loss: 0.106599  [ 2088/ 3000]\n",
      "loss: 0.077142  [ 2096/ 3000]\n",
      "loss: 0.049617  [ 2104/ 3000]\n",
      "loss: 0.031997  [ 2112/ 3000]\n",
      "loss: 0.017067  [ 2120/ 3000]\n",
      "loss: 0.069248  [ 2128/ 3000]\n",
      "loss: 0.067509  [ 2136/ 3000]\n",
      "loss: 0.105566  [ 2144/ 3000]\n",
      "loss: 0.135313  [ 2152/ 3000]\n",
      "loss: 0.026058  [ 2160/ 3000]\n",
      "loss: 0.066154  [ 2168/ 3000]\n",
      "loss: 0.027976  [ 2176/ 3000]\n",
      "loss: 0.092203  [ 2184/ 3000]\n",
      "loss: 0.073576  [ 2192/ 3000]\n",
      "loss: 0.034189  [ 2200/ 3000]\n",
      "loss: 0.020656  [ 2208/ 3000]\n",
      "loss: 0.038922  [ 2216/ 3000]\n",
      "loss: 0.101430  [ 2224/ 3000]\n",
      "loss: 0.074816  [ 2232/ 3000]\n",
      "loss: 0.121099  [ 2240/ 3000]\n",
      "loss: 0.014157  [ 2248/ 3000]\n",
      "loss: 0.058773  [ 2256/ 3000]\n",
      "loss: 0.022260  [ 2264/ 3000]\n",
      "loss: 0.131287  [ 2272/ 3000]\n",
      "loss: 0.044582  [ 2280/ 3000]\n",
      "loss: 0.118420  [ 2288/ 3000]\n",
      "loss: 0.066920  [ 2296/ 3000]\n",
      "loss: 0.052752  [ 2304/ 3000]\n",
      "loss: 0.029359  [ 2312/ 3000]\n",
      "loss: 0.023491  [ 2320/ 3000]\n",
      "loss: 0.078839  [ 2328/ 3000]\n",
      "loss: 0.015940  [ 2336/ 3000]\n",
      "loss: 0.114124  [ 2344/ 3000]\n",
      "loss: 0.113202  [ 2352/ 3000]\n",
      "loss: 0.102125  [ 2360/ 3000]\n",
      "loss: 0.045631  [ 2368/ 3000]\n",
      "loss: 0.029020  [ 2376/ 3000]\n",
      "loss: 0.055627  [ 2384/ 3000]\n",
      "loss: 0.055964  [ 2392/ 3000]\n",
      "loss: 0.010871  [ 2400/ 3000]\n",
      "loss: 0.122163  [ 2408/ 3000]\n",
      "loss: 0.081564  [ 2416/ 3000]\n",
      "loss: 0.082052  [ 2424/ 3000]\n",
      "loss: 0.094528  [ 2432/ 3000]\n",
      "loss: 0.052929  [ 2440/ 3000]\n",
      "loss: 0.111812  [ 2448/ 3000]\n",
      "loss: 0.116345  [ 2456/ 3000]\n",
      "loss: 0.049992  [ 2464/ 3000]\n",
      "loss: 0.234292  [ 2472/ 3000]\n",
      "loss: 0.028508  [ 2480/ 3000]\n",
      "loss: 0.056436  [ 2488/ 3000]\n",
      "loss: 0.017236  [ 2496/ 3000]\n",
      "loss: 0.037109  [ 2504/ 3000]\n",
      "loss: 0.119227  [ 2512/ 3000]\n",
      "loss: 0.215461  [ 2520/ 3000]\n",
      "loss: 0.034515  [ 2528/ 3000]\n",
      "loss: 0.064002  [ 2536/ 3000]\n",
      "loss: 0.020209  [ 2544/ 3000]\n",
      "loss: 0.094401  [ 2552/ 3000]\n",
      "loss: 0.089894  [ 2560/ 3000]\n",
      "loss: 0.135777  [ 2568/ 3000]\n",
      "loss: 0.114544  [ 2576/ 3000]\n",
      "loss: 0.064857  [ 2584/ 3000]\n",
      "loss: 0.050848  [ 2592/ 3000]\n",
      "loss: 0.072157  [ 2600/ 3000]\n",
      "loss: 0.086782  [ 2608/ 3000]\n",
      "loss: 0.032558  [ 2616/ 3000]\n",
      "loss: 0.034187  [ 2624/ 3000]\n",
      "loss: 0.110744  [ 2632/ 3000]\n",
      "loss: 0.125115  [ 2640/ 3000]\n",
      "loss: 0.081439  [ 2648/ 3000]\n",
      "loss: 0.085640  [ 2656/ 3000]\n",
      "loss: 0.058470  [ 2664/ 3000]\n",
      "loss: 0.107384  [ 2672/ 3000]\n",
      "loss: 0.122480  [ 2680/ 3000]\n",
      "loss: 0.053366  [ 2688/ 3000]\n",
      "loss: 0.041744  [ 2696/ 3000]\n",
      "loss: 0.084007  [ 2704/ 3000]\n",
      "loss: 0.081664  [ 2712/ 3000]\n",
      "loss: 0.059286  [ 2720/ 3000]\n",
      "loss: 0.111072  [ 2728/ 3000]\n",
      "loss: 0.031611  [ 2736/ 3000]\n",
      "loss: 0.070268  [ 2744/ 3000]\n",
      "loss: 0.088034  [ 2752/ 3000]\n",
      "loss: 0.062851  [ 2760/ 3000]\n",
      "loss: 0.022328  [ 2768/ 3000]\n",
      "loss: 0.115640  [ 2776/ 3000]\n",
      "loss: 0.075127  [ 2784/ 3000]\n",
      "loss: 0.044802  [ 2792/ 3000]\n",
      "loss: 0.107067  [ 2800/ 3000]\n",
      "loss: 0.154080  [ 2808/ 3000]\n",
      "loss: 0.067232  [ 2816/ 3000]\n",
      "loss: 0.081145  [ 2824/ 3000]\n",
      "loss: 0.083194  [ 2832/ 3000]\n",
      "loss: 0.059127  [ 2840/ 3000]\n",
      "loss: 0.057452  [ 2848/ 3000]\n",
      "loss: 0.083379  [ 2856/ 3000]\n",
      "loss: 0.035996  [ 2864/ 3000]\n",
      "loss: 0.091825  [ 2872/ 3000]\n",
      "loss: 0.108217  [ 2880/ 3000]\n",
      "loss: 0.017980  [ 2888/ 3000]\n",
      "loss: 0.015824  [ 2896/ 3000]\n",
      "loss: 0.069336  [ 2904/ 3000]\n",
      "loss: 0.096496  [ 2912/ 3000]\n",
      "loss: 0.064130  [ 2920/ 3000]\n",
      "loss: 0.113553  [ 2928/ 3000]\n",
      "loss: 0.171916  [ 2936/ 3000]\n",
      "loss: 0.031862  [ 2944/ 3000]\n",
      "loss: 0.006048  [ 2952/ 3000]\n",
      "loss: 0.032068  [ 2960/ 3000]\n",
      "loss: 0.061065  [ 2968/ 3000]\n",
      "loss: 0.054533  [ 2976/ 3000]\n",
      "loss: 0.066563  [ 2984/ 3000]\n",
      "loss: 0.013071  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.087221 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.030488  [    0/ 3000]\n",
      "loss: 0.073953  [    8/ 3000]\n",
      "loss: 0.025784  [   16/ 3000]\n",
      "loss: 0.033672  [   24/ 3000]\n",
      "loss: 0.111908  [   32/ 3000]\n",
      "loss: 0.020062  [   40/ 3000]\n",
      "loss: 0.024970  [   48/ 3000]\n",
      "loss: 0.078276  [   56/ 3000]\n",
      "loss: 0.155848  [   64/ 3000]\n",
      "loss: 0.023791  [   72/ 3000]\n",
      "loss: 0.150628  [   80/ 3000]\n",
      "loss: 0.082745  [   88/ 3000]\n",
      "loss: 0.105132  [   96/ 3000]\n",
      "loss: 0.054215  [  104/ 3000]\n",
      "loss: 0.167630  [  112/ 3000]\n",
      "loss: 0.039219  [  120/ 3000]\n",
      "loss: 0.035680  [  128/ 3000]\n",
      "loss: 0.088112  [  136/ 3000]\n",
      "loss: 0.082156  [  144/ 3000]\n",
      "loss: 0.046809  [  152/ 3000]\n",
      "loss: 0.022808  [  160/ 3000]\n",
      "loss: 0.015191  [  168/ 3000]\n",
      "loss: 0.034079  [  176/ 3000]\n",
      "loss: 0.093032  [  184/ 3000]\n",
      "loss: 0.060341  [  192/ 3000]\n",
      "loss: 0.041413  [  200/ 3000]\n",
      "loss: 0.164390  [  208/ 3000]\n",
      "loss: 0.044917  [  216/ 3000]\n",
      "loss: 0.057208  [  224/ 3000]\n",
      "loss: 0.131552  [  232/ 3000]\n",
      "loss: 0.061689  [  240/ 3000]\n",
      "loss: 0.045681  [  248/ 3000]\n",
      "loss: 0.031859  [  256/ 3000]\n",
      "loss: 0.090484  [  264/ 3000]\n",
      "loss: 0.052141  [  272/ 3000]\n",
      "loss: 0.171802  [  280/ 3000]\n",
      "loss: 0.029047  [  288/ 3000]\n",
      "loss: 0.058367  [  296/ 3000]\n",
      "loss: 0.041385  [  304/ 3000]\n",
      "loss: 0.113031  [  312/ 3000]\n",
      "loss: 0.049303  [  320/ 3000]\n",
      "loss: 0.137269  [  328/ 3000]\n",
      "loss: 0.045580  [  336/ 3000]\n",
      "loss: 0.091023  [  344/ 3000]\n",
      "loss: 0.023863  [  352/ 3000]\n",
      "loss: 0.035599  [  360/ 3000]\n",
      "loss: 0.127579  [  368/ 3000]\n",
      "loss: 0.026302  [  376/ 3000]\n",
      "loss: 0.096413  [  384/ 3000]\n",
      "loss: 0.059673  [  392/ 3000]\n",
      "loss: 0.091417  [  400/ 3000]\n",
      "loss: 0.036269  [  408/ 3000]\n",
      "loss: 0.100926  [  416/ 3000]\n",
      "loss: 0.050790  [  424/ 3000]\n",
      "loss: 0.172757  [  432/ 3000]\n",
      "loss: 0.043624  [  440/ 3000]\n",
      "loss: 0.080121  [  448/ 3000]\n",
      "loss: 0.050035  [  456/ 3000]\n",
      "loss: 0.123208  [  464/ 3000]\n",
      "loss: 0.064913  [  472/ 3000]\n",
      "loss: 0.019144  [  480/ 3000]\n",
      "loss: 0.136191  [  488/ 3000]\n",
      "loss: 0.098771  [  496/ 3000]\n",
      "loss: 0.044578  [  504/ 3000]\n",
      "loss: 0.072716  [  512/ 3000]\n",
      "loss: 0.046447  [  520/ 3000]\n",
      "loss: 0.210618  [  528/ 3000]\n",
      "loss: 0.102065  [  536/ 3000]\n",
      "loss: 0.092583  [  544/ 3000]\n",
      "loss: 0.056246  [  552/ 3000]\n",
      "loss: 0.043428  [  560/ 3000]\n",
      "loss: 0.095198  [  568/ 3000]\n",
      "loss: 0.059764  [  576/ 3000]\n",
      "loss: 0.069935  [  584/ 3000]\n",
      "loss: 0.037873  [  592/ 3000]\n",
      "loss: 0.144138  [  600/ 3000]\n",
      "loss: 0.041660  [  608/ 3000]\n",
      "loss: 0.097860  [  616/ 3000]\n",
      "loss: 0.066256  [  624/ 3000]\n",
      "loss: 0.190936  [  632/ 3000]\n",
      "loss: 0.019516  [  640/ 3000]\n",
      "loss: 0.150480  [  648/ 3000]\n",
      "loss: 0.201549  [  656/ 3000]\n",
      "loss: 0.167113  [  664/ 3000]\n",
      "loss: 0.075037  [  672/ 3000]\n",
      "loss: 0.085949  [  680/ 3000]\n",
      "loss: 0.058169  [  688/ 3000]\n",
      "loss: 0.175211  [  696/ 3000]\n",
      "loss: 0.070909  [  704/ 3000]\n",
      "loss: 0.051115  [  712/ 3000]\n",
      "loss: 0.061902  [  720/ 3000]\n",
      "loss: 0.036807  [  728/ 3000]\n",
      "loss: 0.066649  [  736/ 3000]\n",
      "loss: 0.036615  [  744/ 3000]\n",
      "loss: 0.096426  [  752/ 3000]\n",
      "loss: 0.071695  [  760/ 3000]\n",
      "loss: 0.126831  [  768/ 3000]\n",
      "loss: 0.066919  [  776/ 3000]\n",
      "loss: 0.158503  [  784/ 3000]\n",
      "loss: 0.083338  [  792/ 3000]\n",
      "loss: 0.172068  [  800/ 3000]\n",
      "loss: 0.064755  [  808/ 3000]\n",
      "loss: 0.036000  [  816/ 3000]\n",
      "loss: 0.054957  [  824/ 3000]\n",
      "loss: 0.062028  [  832/ 3000]\n",
      "loss: 0.027323  [  840/ 3000]\n",
      "loss: 0.021870  [  848/ 3000]\n",
      "loss: 0.030131  [  856/ 3000]\n",
      "loss: 0.091227  [  864/ 3000]\n",
      "loss: 0.015690  [  872/ 3000]\n",
      "loss: 0.084444  [  880/ 3000]\n",
      "loss: 0.102059  [  888/ 3000]\n",
      "loss: 0.070866  [  896/ 3000]\n",
      "loss: 0.197565  [  904/ 3000]\n",
      "loss: 0.059515  [  912/ 3000]\n",
      "loss: 0.066740  [  920/ 3000]\n",
      "loss: 0.077075  [  928/ 3000]\n",
      "loss: 0.050920  [  936/ 3000]\n",
      "loss: 0.177301  [  944/ 3000]\n",
      "loss: 0.037280  [  952/ 3000]\n",
      "loss: 0.054135  [  960/ 3000]\n",
      "loss: 0.029639  [  968/ 3000]\n",
      "loss: 0.014729  [  976/ 3000]\n",
      "loss: 0.017564  [  984/ 3000]\n",
      "loss: 0.130202  [  992/ 3000]\n",
      "loss: 0.079740  [ 1000/ 3000]\n",
      "loss: 0.067488  [ 1008/ 3000]\n",
      "loss: 0.124362  [ 1016/ 3000]\n",
      "loss: 0.067327  [ 1024/ 3000]\n",
      "loss: 0.108153  [ 1032/ 3000]\n",
      "loss: 0.019273  [ 1040/ 3000]\n",
      "loss: 0.046705  [ 1048/ 3000]\n",
      "loss: 0.025298  [ 1056/ 3000]\n",
      "loss: 0.080502  [ 1064/ 3000]\n",
      "loss: 0.048738  [ 1072/ 3000]\n",
      "loss: 0.056116  [ 1080/ 3000]\n",
      "loss: 0.110891  [ 1088/ 3000]\n",
      "loss: 0.098705  [ 1096/ 3000]\n",
      "loss: 0.023035  [ 1104/ 3000]\n",
      "loss: 0.109548  [ 1112/ 3000]\n",
      "loss: 0.034707  [ 1120/ 3000]\n",
      "loss: 0.051765  [ 1128/ 3000]\n",
      "loss: 0.051427  [ 1136/ 3000]\n",
      "loss: 0.134787  [ 1144/ 3000]\n",
      "loss: 0.042808  [ 1152/ 3000]\n",
      "loss: 0.032413  [ 1160/ 3000]\n",
      "loss: 0.036488  [ 1168/ 3000]\n",
      "loss: 0.031005  [ 1176/ 3000]\n",
      "loss: 0.177562  [ 1184/ 3000]\n",
      "loss: 0.062851  [ 1192/ 3000]\n",
      "loss: 0.049546  [ 1200/ 3000]\n",
      "loss: 0.041695  [ 1208/ 3000]\n",
      "loss: 0.052718  [ 1216/ 3000]\n",
      "loss: 0.084764  [ 1224/ 3000]\n",
      "loss: 0.096934  [ 1232/ 3000]\n",
      "loss: 0.086866  [ 1240/ 3000]\n",
      "loss: 0.095755  [ 1248/ 3000]\n",
      "loss: 0.014109  [ 1256/ 3000]\n",
      "loss: 0.051909  [ 1264/ 3000]\n",
      "loss: 0.028314  [ 1272/ 3000]\n",
      "loss: 0.036532  [ 1280/ 3000]\n",
      "loss: 0.073859  [ 1288/ 3000]\n",
      "loss: 0.029381  [ 1296/ 3000]\n",
      "loss: 0.004983  [ 1304/ 3000]\n",
      "loss: 0.103534  [ 1312/ 3000]\n",
      "loss: 0.263543  [ 1320/ 3000]\n",
      "loss: 0.104375  [ 1328/ 3000]\n",
      "loss: 0.076546  [ 1336/ 3000]\n",
      "loss: 0.135638  [ 1344/ 3000]\n",
      "loss: 0.085208  [ 1352/ 3000]\n",
      "loss: 0.036679  [ 1360/ 3000]\n",
      "loss: 0.121111  [ 1368/ 3000]\n",
      "loss: 0.138574  [ 1376/ 3000]\n",
      "loss: 0.071863  [ 1384/ 3000]\n",
      "loss: 0.043425  [ 1392/ 3000]\n",
      "loss: 0.092179  [ 1400/ 3000]\n",
      "loss: 0.086160  [ 1408/ 3000]\n",
      "loss: 0.090118  [ 1416/ 3000]\n",
      "loss: 0.128845  [ 1424/ 3000]\n",
      "loss: 0.067396  [ 1432/ 3000]\n",
      "loss: 0.040223  [ 1440/ 3000]\n",
      "loss: 0.039032  [ 1448/ 3000]\n",
      "loss: 0.066282  [ 1456/ 3000]\n",
      "loss: 0.009311  [ 1464/ 3000]\n",
      "loss: 0.049282  [ 1472/ 3000]\n",
      "loss: 0.024285  [ 1480/ 3000]\n",
      "loss: 0.136869  [ 1488/ 3000]\n",
      "loss: 0.032745  [ 1496/ 3000]\n",
      "loss: 0.055139  [ 1504/ 3000]\n",
      "loss: 0.089671  [ 1512/ 3000]\n",
      "loss: 0.080615  [ 1520/ 3000]\n",
      "loss: 0.031504  [ 1528/ 3000]\n",
      "loss: 0.083517  [ 1536/ 3000]\n",
      "loss: 0.037397  [ 1544/ 3000]\n",
      "loss: 0.115142  [ 1552/ 3000]\n",
      "loss: 0.046976  [ 1560/ 3000]\n",
      "loss: 0.042225  [ 1568/ 3000]\n",
      "loss: 0.027138  [ 1576/ 3000]\n",
      "loss: 0.103500  [ 1584/ 3000]\n",
      "loss: 0.057544  [ 1592/ 3000]\n",
      "loss: 0.094385  [ 1600/ 3000]\n",
      "loss: 0.040815  [ 1608/ 3000]\n",
      "loss: 0.137350  [ 1616/ 3000]\n",
      "loss: 0.111120  [ 1624/ 3000]\n",
      "loss: 0.047683  [ 1632/ 3000]\n",
      "loss: 0.049810  [ 1640/ 3000]\n",
      "loss: 0.122983  [ 1648/ 3000]\n",
      "loss: 0.039397  [ 1656/ 3000]\n",
      "loss: 0.122308  [ 1664/ 3000]\n",
      "loss: 0.024123  [ 1672/ 3000]\n",
      "loss: 0.050190  [ 1680/ 3000]\n",
      "loss: 0.063211  [ 1688/ 3000]\n",
      "loss: 0.092667  [ 1696/ 3000]\n",
      "loss: 0.054211  [ 1704/ 3000]\n",
      "loss: 0.025800  [ 1712/ 3000]\n",
      "loss: 0.037972  [ 1720/ 3000]\n",
      "loss: 0.059498  [ 1728/ 3000]\n",
      "loss: 0.087948  [ 1736/ 3000]\n",
      "loss: 0.077955  [ 1744/ 3000]\n",
      "loss: 0.019531  [ 1752/ 3000]\n",
      "loss: 0.010025  [ 1760/ 3000]\n",
      "loss: 0.110262  [ 1768/ 3000]\n",
      "loss: 0.065463  [ 1776/ 3000]\n",
      "loss: 0.029333  [ 1784/ 3000]\n",
      "loss: 0.049128  [ 1792/ 3000]\n",
      "loss: 0.094578  [ 1800/ 3000]\n",
      "loss: 0.130436  [ 1808/ 3000]\n",
      "loss: 0.037857  [ 1816/ 3000]\n",
      "loss: 0.125783  [ 1824/ 3000]\n",
      "loss: 0.006759  [ 1832/ 3000]\n",
      "loss: 0.010418  [ 1840/ 3000]\n",
      "loss: 0.054120  [ 1848/ 3000]\n",
      "loss: 0.078765  [ 1856/ 3000]\n",
      "loss: 0.077897  [ 1864/ 3000]\n",
      "loss: 0.069393  [ 1872/ 3000]\n",
      "loss: 0.013593  [ 1880/ 3000]\n",
      "loss: 0.020701  [ 1888/ 3000]\n",
      "loss: 0.067939  [ 1896/ 3000]\n",
      "loss: 0.032710  [ 1904/ 3000]\n",
      "loss: 0.038928  [ 1912/ 3000]\n",
      "loss: 0.102626  [ 1920/ 3000]\n",
      "loss: 0.081301  [ 1928/ 3000]\n",
      "loss: 0.128610  [ 1936/ 3000]\n",
      "loss: 0.016069  [ 1944/ 3000]\n",
      "loss: 0.091424  [ 1952/ 3000]\n",
      "loss: 0.032027  [ 1960/ 3000]\n",
      "loss: 0.106632  [ 1968/ 3000]\n",
      "loss: 0.033199  [ 1976/ 3000]\n",
      "loss: 0.119009  [ 1984/ 3000]\n",
      "loss: 0.125575  [ 1992/ 3000]\n",
      "loss: 0.066925  [ 2000/ 3000]\n",
      "loss: 0.097259  [ 2008/ 3000]\n",
      "loss: 0.057306  [ 2016/ 3000]\n",
      "loss: 0.058000  [ 2024/ 3000]\n",
      "loss: 0.096768  [ 2032/ 3000]\n",
      "loss: 0.081410  [ 2040/ 3000]\n",
      "loss: 0.037950  [ 2048/ 3000]\n",
      "loss: 0.038732  [ 2056/ 3000]\n",
      "loss: 0.028559  [ 2064/ 3000]\n",
      "loss: 0.111917  [ 2072/ 3000]\n",
      "loss: 0.048570  [ 2080/ 3000]\n",
      "loss: 0.103469  [ 2088/ 3000]\n",
      "loss: 0.075307  [ 2096/ 3000]\n",
      "loss: 0.048457  [ 2104/ 3000]\n",
      "loss: 0.031543  [ 2112/ 3000]\n",
      "loss: 0.016421  [ 2120/ 3000]\n",
      "loss: 0.068152  [ 2128/ 3000]\n",
      "loss: 0.066002  [ 2136/ 3000]\n",
      "loss: 0.103218  [ 2144/ 3000]\n",
      "loss: 0.133355  [ 2152/ 3000]\n",
      "loss: 0.024992  [ 2160/ 3000]\n",
      "loss: 0.064228  [ 2168/ 3000]\n",
      "loss: 0.026939  [ 2176/ 3000]\n",
      "loss: 0.090147  [ 2184/ 3000]\n",
      "loss: 0.070184  [ 2192/ 3000]\n",
      "loss: 0.033320  [ 2200/ 3000]\n",
      "loss: 0.019801  [ 2208/ 3000]\n",
      "loss: 0.037862  [ 2216/ 3000]\n",
      "loss: 0.099038  [ 2224/ 3000]\n",
      "loss: 0.072748  [ 2232/ 3000]\n",
      "loss: 0.118513  [ 2240/ 3000]\n",
      "loss: 0.013631  [ 2248/ 3000]\n",
      "loss: 0.056266  [ 2256/ 3000]\n",
      "loss: 0.021282  [ 2264/ 3000]\n",
      "loss: 0.128702  [ 2272/ 3000]\n",
      "loss: 0.043413  [ 2280/ 3000]\n",
      "loss: 0.114465  [ 2288/ 3000]\n",
      "loss: 0.065197  [ 2296/ 3000]\n",
      "loss: 0.051457  [ 2304/ 3000]\n",
      "loss: 0.028399  [ 2312/ 3000]\n",
      "loss: 0.022506  [ 2320/ 3000]\n",
      "loss: 0.076625  [ 2328/ 3000]\n",
      "loss: 0.015383  [ 2336/ 3000]\n",
      "loss: 0.111587  [ 2344/ 3000]\n",
      "loss: 0.109303  [ 2352/ 3000]\n",
      "loss: 0.100332  [ 2360/ 3000]\n",
      "loss: 0.044199  [ 2368/ 3000]\n",
      "loss: 0.028111  [ 2376/ 3000]\n",
      "loss: 0.054327  [ 2384/ 3000]\n",
      "loss: 0.054320  [ 2392/ 3000]\n",
      "loss: 0.010254  [ 2400/ 3000]\n",
      "loss: 0.120035  [ 2408/ 3000]\n",
      "loss: 0.080113  [ 2416/ 3000]\n",
      "loss: 0.079383  [ 2424/ 3000]\n",
      "loss: 0.092239  [ 2432/ 3000]\n",
      "loss: 0.051737  [ 2440/ 3000]\n",
      "loss: 0.108425  [ 2448/ 3000]\n",
      "loss: 0.113701  [ 2456/ 3000]\n",
      "loss: 0.048450  [ 2464/ 3000]\n",
      "loss: 0.230928  [ 2472/ 3000]\n",
      "loss: 0.027946  [ 2480/ 3000]\n",
      "loss: 0.054690  [ 2488/ 3000]\n",
      "loss: 0.016311  [ 2496/ 3000]\n",
      "loss: 0.035786  [ 2504/ 3000]\n",
      "loss: 0.116205  [ 2512/ 3000]\n",
      "loss: 0.212141  [ 2520/ 3000]\n",
      "loss: 0.033108  [ 2528/ 3000]\n",
      "loss: 0.062587  [ 2536/ 3000]\n",
      "loss: 0.019335  [ 2544/ 3000]\n",
      "loss: 0.091676  [ 2552/ 3000]\n",
      "loss: 0.088102  [ 2560/ 3000]\n",
      "loss: 0.133808  [ 2568/ 3000]\n",
      "loss: 0.111067  [ 2576/ 3000]\n",
      "loss: 0.062782  [ 2584/ 3000]\n",
      "loss: 0.049348  [ 2592/ 3000]\n",
      "loss: 0.071127  [ 2600/ 3000]\n",
      "loss: 0.084796  [ 2608/ 3000]\n",
      "loss: 0.031341  [ 2616/ 3000]\n",
      "loss: 0.032764  [ 2624/ 3000]\n",
      "loss: 0.108474  [ 2632/ 3000]\n",
      "loss: 0.122611  [ 2640/ 3000]\n",
      "loss: 0.079548  [ 2648/ 3000]\n",
      "loss: 0.083410  [ 2656/ 3000]\n",
      "loss: 0.056952  [ 2664/ 3000]\n",
      "loss: 0.104383  [ 2672/ 3000]\n",
      "loss: 0.119282  [ 2680/ 3000]\n",
      "loss: 0.052041  [ 2688/ 3000]\n",
      "loss: 0.040553  [ 2696/ 3000]\n",
      "loss: 0.082589  [ 2704/ 3000]\n",
      "loss: 0.078652  [ 2712/ 3000]\n",
      "loss: 0.057131  [ 2720/ 3000]\n",
      "loss: 0.107466  [ 2728/ 3000]\n",
      "loss: 0.030799  [ 2736/ 3000]\n",
      "loss: 0.068399  [ 2744/ 3000]\n",
      "loss: 0.085368  [ 2752/ 3000]\n",
      "loss: 0.061392  [ 2760/ 3000]\n",
      "loss: 0.021458  [ 2768/ 3000]\n",
      "loss: 0.112137  [ 2776/ 3000]\n",
      "loss: 0.073256  [ 2784/ 3000]\n",
      "loss: 0.043276  [ 2792/ 3000]\n",
      "loss: 0.104680  [ 2800/ 3000]\n",
      "loss: 0.150902  [ 2808/ 3000]\n",
      "loss: 0.064671  [ 2816/ 3000]\n",
      "loss: 0.079150  [ 2824/ 3000]\n",
      "loss: 0.081153  [ 2832/ 3000]\n",
      "loss: 0.057465  [ 2840/ 3000]\n",
      "loss: 0.055376  [ 2848/ 3000]\n",
      "loss: 0.081016  [ 2856/ 3000]\n",
      "loss: 0.034688  [ 2864/ 3000]\n",
      "loss: 0.090290  [ 2872/ 3000]\n",
      "loss: 0.105035  [ 2880/ 3000]\n",
      "loss: 0.016877  [ 2888/ 3000]\n",
      "loss: 0.015190  [ 2896/ 3000]\n",
      "loss: 0.066720  [ 2904/ 3000]\n",
      "loss: 0.094345  [ 2912/ 3000]\n",
      "loss: 0.061863  [ 2920/ 3000]\n",
      "loss: 0.110611  [ 2928/ 3000]\n",
      "loss: 0.166970  [ 2936/ 3000]\n",
      "loss: 0.030903  [ 2944/ 3000]\n",
      "loss: 0.005804  [ 2952/ 3000]\n",
      "loss: 0.031162  [ 2960/ 3000]\n",
      "loss: 0.059526  [ 2968/ 3000]\n",
      "loss: 0.053414  [ 2976/ 3000]\n",
      "loss: 0.065267  [ 2984/ 3000]\n",
      "loss: 0.012388  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.086816 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.029522  [    0/ 3000]\n",
      "loss: 0.072113  [    8/ 3000]\n",
      "loss: 0.024350  [   16/ 3000]\n",
      "loss: 0.032232  [   24/ 3000]\n",
      "loss: 0.108271  [   32/ 3000]\n",
      "loss: 0.019048  [   40/ 3000]\n",
      "loss: 0.024165  [   48/ 3000]\n",
      "loss: 0.076678  [   56/ 3000]\n",
      "loss: 0.151791  [   64/ 3000]\n",
      "loss: 0.023267  [   72/ 3000]\n",
      "loss: 0.148002  [   80/ 3000]\n",
      "loss: 0.079996  [   88/ 3000]\n",
      "loss: 0.102289  [   96/ 3000]\n",
      "loss: 0.051311  [  104/ 3000]\n",
      "loss: 0.164436  [  112/ 3000]\n",
      "loss: 0.037916  [  120/ 3000]\n",
      "loss: 0.035011  [  128/ 3000]\n",
      "loss: 0.085029  [  136/ 3000]\n",
      "loss: 0.080071  [  144/ 3000]\n",
      "loss: 0.045326  [  152/ 3000]\n",
      "loss: 0.021993  [  160/ 3000]\n",
      "loss: 0.014599  [  168/ 3000]\n",
      "loss: 0.032623  [  176/ 3000]\n",
      "loss: 0.090798  [  184/ 3000]\n",
      "loss: 0.058031  [  192/ 3000]\n",
      "loss: 0.040238  [  200/ 3000]\n",
      "loss: 0.161397  [  208/ 3000]\n",
      "loss: 0.043564  [  216/ 3000]\n",
      "loss: 0.055621  [  224/ 3000]\n",
      "loss: 0.128432  [  232/ 3000]\n",
      "loss: 0.060273  [  240/ 3000]\n",
      "loss: 0.044061  [  248/ 3000]\n",
      "loss: 0.030853  [  256/ 3000]\n",
      "loss: 0.087245  [  264/ 3000]\n",
      "loss: 0.051274  [  272/ 3000]\n",
      "loss: 0.169219  [  280/ 3000]\n",
      "loss: 0.028024  [  288/ 3000]\n",
      "loss: 0.057131  [  296/ 3000]\n",
      "loss: 0.040169  [  304/ 3000]\n",
      "loss: 0.110527  [  312/ 3000]\n",
      "loss: 0.047486  [  320/ 3000]\n",
      "loss: 0.132381  [  328/ 3000]\n",
      "loss: 0.043607  [  336/ 3000]\n",
      "loss: 0.089633  [  344/ 3000]\n",
      "loss: 0.022958  [  352/ 3000]\n",
      "loss: 0.034719  [  360/ 3000]\n",
      "loss: 0.124909  [  368/ 3000]\n",
      "loss: 0.024981  [  376/ 3000]\n",
      "loss: 0.094721  [  384/ 3000]\n",
      "loss: 0.057726  [  392/ 3000]\n",
      "loss: 0.088811  [  400/ 3000]\n",
      "loss: 0.035348  [  408/ 3000]\n",
      "loss: 0.098155  [  416/ 3000]\n",
      "loss: 0.049154  [  424/ 3000]\n",
      "loss: 0.169238  [  432/ 3000]\n",
      "loss: 0.042134  [  440/ 3000]\n",
      "loss: 0.078075  [  448/ 3000]\n",
      "loss: 0.048247  [  456/ 3000]\n",
      "loss: 0.119528  [  464/ 3000]\n",
      "loss: 0.063690  [  472/ 3000]\n",
      "loss: 0.018560  [  480/ 3000]\n",
      "loss: 0.132932  [  488/ 3000]\n",
      "loss: 0.097438  [  496/ 3000]\n",
      "loss: 0.043017  [  504/ 3000]\n",
      "loss: 0.071369  [  512/ 3000]\n",
      "loss: 0.045537  [  520/ 3000]\n",
      "loss: 0.206116  [  528/ 3000]\n",
      "loss: 0.099434  [  536/ 3000]\n",
      "loss: 0.089948  [  544/ 3000]\n",
      "loss: 0.054259  [  552/ 3000]\n",
      "loss: 0.041878  [  560/ 3000]\n",
      "loss: 0.092931  [  568/ 3000]\n",
      "loss: 0.057846  [  576/ 3000]\n",
      "loss: 0.067502  [  584/ 3000]\n",
      "loss: 0.036659  [  592/ 3000]\n",
      "loss: 0.140142  [  600/ 3000]\n",
      "loss: 0.040612  [  608/ 3000]\n",
      "loss: 0.095217  [  616/ 3000]\n",
      "loss: 0.064474  [  624/ 3000]\n",
      "loss: 0.187272  [  632/ 3000]\n",
      "loss: 0.018668  [  640/ 3000]\n",
      "loss: 0.146895  [  648/ 3000]\n",
      "loss: 0.196851  [  656/ 3000]\n",
      "loss: 0.164065  [  664/ 3000]\n",
      "loss: 0.073027  [  672/ 3000]\n",
      "loss: 0.084088  [  680/ 3000]\n",
      "loss: 0.056721  [  688/ 3000]\n",
      "loss: 0.171269  [  696/ 3000]\n",
      "loss: 0.069740  [  704/ 3000]\n",
      "loss: 0.049647  [  712/ 3000]\n",
      "loss: 0.060587  [  720/ 3000]\n",
      "loss: 0.035680  [  728/ 3000]\n",
      "loss: 0.065288  [  736/ 3000]\n",
      "loss: 0.034742  [  744/ 3000]\n",
      "loss: 0.093693  [  752/ 3000]\n",
      "loss: 0.069396  [  760/ 3000]\n",
      "loss: 0.124968  [  768/ 3000]\n",
      "loss: 0.065434  [  776/ 3000]\n",
      "loss: 0.154591  [  784/ 3000]\n",
      "loss: 0.080360  [  792/ 3000]\n",
      "loss: 0.169826  [  800/ 3000]\n",
      "loss: 0.063224  [  808/ 3000]\n",
      "loss: 0.034770  [  816/ 3000]\n",
      "loss: 0.053692  [  824/ 3000]\n",
      "loss: 0.060225  [  832/ 3000]\n",
      "loss: 0.026150  [  840/ 3000]\n",
      "loss: 0.021164  [  848/ 3000]\n",
      "loss: 0.029244  [  856/ 3000]\n",
      "loss: 0.089005  [  864/ 3000]\n",
      "loss: 0.014912  [  872/ 3000]\n",
      "loss: 0.082914  [  880/ 3000]\n",
      "loss: 0.099409  [  888/ 3000]\n",
      "loss: 0.070134  [  896/ 3000]\n",
      "loss: 0.193145  [  904/ 3000]\n",
      "loss: 0.058467  [  912/ 3000]\n",
      "loss: 0.065188  [  920/ 3000]\n",
      "loss: 0.075310  [  928/ 3000]\n",
      "loss: 0.049064  [  936/ 3000]\n",
      "loss: 0.173066  [  944/ 3000]\n",
      "loss: 0.035863  [  952/ 3000]\n",
      "loss: 0.052838  [  960/ 3000]\n",
      "loss: 0.028623  [  968/ 3000]\n",
      "loss: 0.014114  [  976/ 3000]\n",
      "loss: 0.016728  [  984/ 3000]\n",
      "loss: 0.127091  [  992/ 3000]\n",
      "loss: 0.077411  [ 1000/ 3000]\n",
      "loss: 0.065925  [ 1008/ 3000]\n",
      "loss: 0.121301  [ 1016/ 3000]\n",
      "loss: 0.065475  [ 1024/ 3000]\n",
      "loss: 0.105315  [ 1032/ 3000]\n",
      "loss: 0.018510  [ 1040/ 3000]\n",
      "loss: 0.045297  [ 1048/ 3000]\n",
      "loss: 0.024365  [ 1056/ 3000]\n",
      "loss: 0.078350  [ 1064/ 3000]\n",
      "loss: 0.047184  [ 1072/ 3000]\n",
      "loss: 0.054630  [ 1080/ 3000]\n",
      "loss: 0.108038  [ 1088/ 3000]\n",
      "loss: 0.096196  [ 1096/ 3000]\n",
      "loss: 0.022040  [ 1104/ 3000]\n",
      "loss: 0.106311  [ 1112/ 3000]\n",
      "loss: 0.033527  [ 1120/ 3000]\n",
      "loss: 0.050850  [ 1128/ 3000]\n",
      "loss: 0.049685  [ 1136/ 3000]\n",
      "loss: 0.130764  [ 1144/ 3000]\n",
      "loss: 0.041586  [ 1152/ 3000]\n",
      "loss: 0.031455  [ 1160/ 3000]\n",
      "loss: 0.035326  [ 1168/ 3000]\n",
      "loss: 0.029875  [ 1176/ 3000]\n",
      "loss: 0.173597  [ 1184/ 3000]\n",
      "loss: 0.061312  [ 1192/ 3000]\n",
      "loss: 0.047222  [ 1200/ 3000]\n",
      "loss: 0.040767  [ 1208/ 3000]\n",
      "loss: 0.050526  [ 1216/ 3000]\n",
      "loss: 0.082122  [ 1224/ 3000]\n",
      "loss: 0.094095  [ 1232/ 3000]\n",
      "loss: 0.084560  [ 1240/ 3000]\n",
      "loss: 0.092705  [ 1248/ 3000]\n",
      "loss: 0.013377  [ 1256/ 3000]\n",
      "loss: 0.051227  [ 1264/ 3000]\n",
      "loss: 0.027376  [ 1272/ 3000]\n",
      "loss: 0.034766  [ 1280/ 3000]\n",
      "loss: 0.071046  [ 1288/ 3000]\n",
      "loss: 0.028026  [ 1296/ 3000]\n",
      "loss: 0.004671  [ 1304/ 3000]\n",
      "loss: 0.100516  [ 1312/ 3000]\n",
      "loss: 0.256508  [ 1320/ 3000]\n",
      "loss: 0.101298  [ 1328/ 3000]\n",
      "loss: 0.075026  [ 1336/ 3000]\n",
      "loss: 0.132103  [ 1344/ 3000]\n",
      "loss: 0.083443  [ 1352/ 3000]\n",
      "loss: 0.034980  [ 1360/ 3000]\n",
      "loss: 0.118614  [ 1368/ 3000]\n",
      "loss: 0.136275  [ 1376/ 3000]\n",
      "loss: 0.069301  [ 1384/ 3000]\n",
      "loss: 0.041723  [ 1392/ 3000]\n",
      "loss: 0.089826  [ 1400/ 3000]\n",
      "loss: 0.084181  [ 1408/ 3000]\n",
      "loss: 0.087717  [ 1416/ 3000]\n",
      "loss: 0.126850  [ 1424/ 3000]\n",
      "loss: 0.065376  [ 1432/ 3000]\n",
      "loss: 0.039108  [ 1440/ 3000]\n",
      "loss: 0.037664  [ 1448/ 3000]\n",
      "loss: 0.064113  [ 1456/ 3000]\n",
      "loss: 0.008938  [ 1464/ 3000]\n",
      "loss: 0.048371  [ 1472/ 3000]\n",
      "loss: 0.023832  [ 1480/ 3000]\n",
      "loss: 0.134522  [ 1488/ 3000]\n",
      "loss: 0.031593  [ 1496/ 3000]\n",
      "loss: 0.053275  [ 1504/ 3000]\n",
      "loss: 0.087867  [ 1512/ 3000]\n",
      "loss: 0.078281  [ 1520/ 3000]\n",
      "loss: 0.030056  [ 1528/ 3000]\n",
      "loss: 0.081469  [ 1536/ 3000]\n",
      "loss: 0.035635  [ 1544/ 3000]\n",
      "loss: 0.112324  [ 1552/ 3000]\n",
      "loss: 0.045511  [ 1560/ 3000]\n",
      "loss: 0.040762  [ 1568/ 3000]\n",
      "loss: 0.026007  [ 1576/ 3000]\n",
      "loss: 0.101420  [ 1584/ 3000]\n",
      "loss: 0.056420  [ 1592/ 3000]\n",
      "loss: 0.091700  [ 1600/ 3000]\n",
      "loss: 0.039650  [ 1608/ 3000]\n",
      "loss: 0.134879  [ 1616/ 3000]\n",
      "loss: 0.108823  [ 1624/ 3000]\n",
      "loss: 0.046278  [ 1632/ 3000]\n",
      "loss: 0.048319  [ 1640/ 3000]\n",
      "loss: 0.120409  [ 1648/ 3000]\n",
      "loss: 0.038495  [ 1656/ 3000]\n",
      "loss: 0.117462  [ 1664/ 3000]\n",
      "loss: 0.022841  [ 1672/ 3000]\n",
      "loss: 0.049117  [ 1680/ 3000]\n",
      "loss: 0.061380  [ 1688/ 3000]\n",
      "loss: 0.090526  [ 1696/ 3000]\n",
      "loss: 0.052295  [ 1704/ 3000]\n",
      "loss: 0.025081  [ 1712/ 3000]\n",
      "loss: 0.036105  [ 1720/ 3000]\n",
      "loss: 0.058048  [ 1728/ 3000]\n",
      "loss: 0.085955  [ 1736/ 3000]\n",
      "loss: 0.076113  [ 1744/ 3000]\n",
      "loss: 0.018950  [ 1752/ 3000]\n",
      "loss: 0.009535  [ 1760/ 3000]\n",
      "loss: 0.106565  [ 1768/ 3000]\n",
      "loss: 0.063114  [ 1776/ 3000]\n",
      "loss: 0.028319  [ 1784/ 3000]\n",
      "loss: 0.047684  [ 1792/ 3000]\n",
      "loss: 0.091746  [ 1800/ 3000]\n",
      "loss: 0.127174  [ 1808/ 3000]\n",
      "loss: 0.036647  [ 1816/ 3000]\n",
      "loss: 0.122536  [ 1824/ 3000]\n",
      "loss: 0.006246  [ 1832/ 3000]\n",
      "loss: 0.010100  [ 1840/ 3000]\n",
      "loss: 0.052261  [ 1848/ 3000]\n",
      "loss: 0.076855  [ 1856/ 3000]\n",
      "loss: 0.075394  [ 1864/ 3000]\n",
      "loss: 0.067785  [ 1872/ 3000]\n",
      "loss: 0.012696  [ 1880/ 3000]\n",
      "loss: 0.019512  [ 1888/ 3000]\n",
      "loss: 0.065378  [ 1896/ 3000]\n",
      "loss: 0.032313  [ 1904/ 3000]\n",
      "loss: 0.037350  [ 1912/ 3000]\n",
      "loss: 0.100741  [ 1920/ 3000]\n",
      "loss: 0.079095  [ 1928/ 3000]\n",
      "loss: 0.125150  [ 1936/ 3000]\n",
      "loss: 0.015320  [ 1944/ 3000]\n",
      "loss: 0.089425  [ 1952/ 3000]\n",
      "loss: 0.031014  [ 1960/ 3000]\n",
      "loss: 0.104163  [ 1968/ 3000]\n",
      "loss: 0.032117  [ 1976/ 3000]\n",
      "loss: 0.116441  [ 1984/ 3000]\n",
      "loss: 0.122983  [ 1992/ 3000]\n",
      "loss: 0.064584  [ 2000/ 3000]\n",
      "loss: 0.094620  [ 2008/ 3000]\n",
      "loss: 0.054963  [ 2016/ 3000]\n",
      "loss: 0.056760  [ 2024/ 3000]\n",
      "loss: 0.094673  [ 2032/ 3000]\n",
      "loss: 0.079687  [ 2040/ 3000]\n",
      "loss: 0.036938  [ 2048/ 3000]\n",
      "loss: 0.037461  [ 2056/ 3000]\n",
      "loss: 0.027281  [ 2064/ 3000]\n",
      "loss: 0.109030  [ 2072/ 3000]\n",
      "loss: 0.047070  [ 2080/ 3000]\n",
      "loss: 0.100327  [ 2088/ 3000]\n",
      "loss: 0.073488  [ 2096/ 3000]\n",
      "loss: 0.047347  [ 2104/ 3000]\n",
      "loss: 0.031054  [ 2112/ 3000]\n",
      "loss: 0.015812  [ 2120/ 3000]\n",
      "loss: 0.067028  [ 2128/ 3000]\n",
      "loss: 0.064494  [ 2136/ 3000]\n",
      "loss: 0.100921  [ 2144/ 3000]\n",
      "loss: 0.131367  [ 2152/ 3000]\n",
      "loss: 0.023980  [ 2160/ 3000]\n",
      "loss: 0.062431  [ 2168/ 3000]\n",
      "loss: 0.025971  [ 2176/ 3000]\n",
      "loss: 0.088077  [ 2184/ 3000]\n",
      "loss: 0.066779  [ 2192/ 3000]\n",
      "loss: 0.032479  [ 2200/ 3000]\n",
      "loss: 0.018937  [ 2208/ 3000]\n",
      "loss: 0.036806  [ 2216/ 3000]\n",
      "loss: 0.096495  [ 2224/ 3000]\n",
      "loss: 0.070697  [ 2232/ 3000]\n",
      "loss: 0.115992  [ 2240/ 3000]\n",
      "loss: 0.013114  [ 2248/ 3000]\n",
      "loss: 0.053887  [ 2256/ 3000]\n",
      "loss: 0.020290  [ 2264/ 3000]\n",
      "loss: 0.126068  [ 2272/ 3000]\n",
      "loss: 0.042341  [ 2280/ 3000]\n",
      "loss: 0.110610  [ 2288/ 3000]\n",
      "loss: 0.063538  [ 2296/ 3000]\n",
      "loss: 0.050161  [ 2304/ 3000]\n",
      "loss: 0.027530  [ 2312/ 3000]\n",
      "loss: 0.021520  [ 2320/ 3000]\n",
      "loss: 0.074402  [ 2328/ 3000]\n",
      "loss: 0.014850  [ 2336/ 3000]\n",
      "loss: 0.108994  [ 2344/ 3000]\n",
      "loss: 0.105595  [ 2352/ 3000]\n",
      "loss: 0.098365  [ 2360/ 3000]\n",
      "loss: 0.042846  [ 2368/ 3000]\n",
      "loss: 0.027203  [ 2376/ 3000]\n",
      "loss: 0.053065  [ 2384/ 3000]\n",
      "loss: 0.052692  [ 2392/ 3000]\n",
      "loss: 0.009673  [ 2400/ 3000]\n",
      "loss: 0.117953  [ 2408/ 3000]\n",
      "loss: 0.078714  [ 2416/ 3000]\n",
      "loss: 0.076777  [ 2424/ 3000]\n",
      "loss: 0.090158  [ 2432/ 3000]\n",
      "loss: 0.050541  [ 2440/ 3000]\n",
      "loss: 0.105005  [ 2448/ 3000]\n",
      "loss: 0.111195  [ 2456/ 3000]\n",
      "loss: 0.046964  [ 2464/ 3000]\n",
      "loss: 0.227444  [ 2472/ 3000]\n",
      "loss: 0.027423  [ 2480/ 3000]\n",
      "loss: 0.053020  [ 2488/ 3000]\n",
      "loss: 0.015492  [ 2496/ 3000]\n",
      "loss: 0.034525  [ 2504/ 3000]\n",
      "loss: 0.113278  [ 2512/ 3000]\n",
      "loss: 0.208663  [ 2520/ 3000]\n",
      "loss: 0.031758  [ 2528/ 3000]\n",
      "loss: 0.061160  [ 2536/ 3000]\n",
      "loss: 0.018534  [ 2544/ 3000]\n",
      "loss: 0.089007  [ 2552/ 3000]\n",
      "loss: 0.086225  [ 2560/ 3000]\n",
      "loss: 0.131780  [ 2568/ 3000]\n",
      "loss: 0.107603  [ 2576/ 3000]\n",
      "loss: 0.060799  [ 2584/ 3000]\n",
      "loss: 0.047935  [ 2592/ 3000]\n",
      "loss: 0.070166  [ 2600/ 3000]\n",
      "loss: 0.082873  [ 2608/ 3000]\n",
      "loss: 0.030182  [ 2616/ 3000]\n",
      "loss: 0.031367  [ 2624/ 3000]\n",
      "loss: 0.106175  [ 2632/ 3000]\n",
      "loss: 0.120105  [ 2640/ 3000]\n",
      "loss: 0.077758  [ 2648/ 3000]\n",
      "loss: 0.081245  [ 2656/ 3000]\n",
      "loss: 0.055508  [ 2664/ 3000]\n",
      "loss: 0.101484  [ 2672/ 3000]\n",
      "loss: 0.116035  [ 2680/ 3000]\n",
      "loss: 0.050742  [ 2688/ 3000]\n",
      "loss: 0.039389  [ 2696/ 3000]\n",
      "loss: 0.081179  [ 2704/ 3000]\n",
      "loss: 0.075751  [ 2712/ 3000]\n",
      "loss: 0.054993  [ 2720/ 3000]\n",
      "loss: 0.103951  [ 2728/ 3000]\n",
      "loss: 0.029976  [ 2736/ 3000]\n",
      "loss: 0.066480  [ 2744/ 3000]\n",
      "loss: 0.082786  [ 2752/ 3000]\n",
      "loss: 0.060015  [ 2760/ 3000]\n",
      "loss: 0.020584  [ 2768/ 3000]\n",
      "loss: 0.108630  [ 2776/ 3000]\n",
      "loss: 0.071381  [ 2784/ 3000]\n",
      "loss: 0.041892  [ 2792/ 3000]\n",
      "loss: 0.102206  [ 2800/ 3000]\n",
      "loss: 0.147530  [ 2808/ 3000]\n",
      "loss: 0.062195  [ 2816/ 3000]\n",
      "loss: 0.077125  [ 2824/ 3000]\n",
      "loss: 0.079108  [ 2832/ 3000]\n",
      "loss: 0.055808  [ 2840/ 3000]\n",
      "loss: 0.053314  [ 2848/ 3000]\n",
      "loss: 0.078777  [ 2856/ 3000]\n",
      "loss: 0.033434  [ 2864/ 3000]\n",
      "loss: 0.088750  [ 2872/ 3000]\n",
      "loss: 0.101969  [ 2880/ 3000]\n",
      "loss: 0.015875  [ 2888/ 3000]\n",
      "loss: 0.014648  [ 2896/ 3000]\n",
      "loss: 0.064295  [ 2904/ 3000]\n",
      "loss: 0.092230  [ 2912/ 3000]\n",
      "loss: 0.059532  [ 2920/ 3000]\n",
      "loss: 0.107690  [ 2928/ 3000]\n",
      "loss: 0.161954  [ 2936/ 3000]\n",
      "loss: 0.030034  [ 2944/ 3000]\n",
      "loss: 0.005576  [ 2952/ 3000]\n",
      "loss: 0.030205  [ 2960/ 3000]\n",
      "loss: 0.057977  [ 2968/ 3000]\n",
      "loss: 0.052295  [ 2976/ 3000]\n",
      "loss: 0.063947  [ 2984/ 3000]\n",
      "loss: 0.011765  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.086468 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.028652  [    0/ 3000]\n",
      "loss: 0.070337  [    8/ 3000]\n",
      "loss: 0.023155  [   16/ 3000]\n",
      "loss: 0.030913  [   24/ 3000]\n",
      "loss: 0.104901  [   32/ 3000]\n",
      "loss: 0.018099  [   40/ 3000]\n",
      "loss: 0.023349  [   48/ 3000]\n",
      "loss: 0.075203  [   56/ 3000]\n",
      "loss: 0.147836  [   64/ 3000]\n",
      "loss: 0.022743  [   72/ 3000]\n",
      "loss: 0.145349  [   80/ 3000]\n",
      "loss: 0.077406  [   88/ 3000]\n",
      "loss: 0.099542  [   96/ 3000]\n",
      "loss: 0.048385  [  104/ 3000]\n",
      "loss: 0.161146  [  112/ 3000]\n",
      "loss: 0.036616  [  120/ 3000]\n",
      "loss: 0.034461  [  128/ 3000]\n",
      "loss: 0.082095  [  136/ 3000]\n",
      "loss: 0.077968  [  144/ 3000]\n",
      "loss: 0.043781  [  152/ 3000]\n",
      "loss: 0.021224  [  160/ 3000]\n",
      "loss: 0.014073  [  168/ 3000]\n",
      "loss: 0.031234  [  176/ 3000]\n",
      "loss: 0.088491  [  184/ 3000]\n",
      "loss: 0.055730  [  192/ 3000]\n",
      "loss: 0.039078  [  200/ 3000]\n",
      "loss: 0.158291  [  208/ 3000]\n",
      "loss: 0.042159  [  216/ 3000]\n",
      "loss: 0.054026  [  224/ 3000]\n",
      "loss: 0.125421  [  232/ 3000]\n",
      "loss: 0.058851  [  240/ 3000]\n",
      "loss: 0.042473  [  248/ 3000]\n",
      "loss: 0.029889  [  256/ 3000]\n",
      "loss: 0.084028  [  264/ 3000]\n",
      "loss: 0.050422  [  272/ 3000]\n",
      "loss: 0.166603  [  280/ 3000]\n",
      "loss: 0.027040  [  288/ 3000]\n",
      "loss: 0.055893  [  296/ 3000]\n",
      "loss: 0.038974  [  304/ 3000]\n",
      "loss: 0.107885  [  312/ 3000]\n",
      "loss: 0.045774  [  320/ 3000]\n",
      "loss: 0.127587  [  328/ 3000]\n",
      "loss: 0.041752  [  336/ 3000]\n",
      "loss: 0.088116  [  344/ 3000]\n",
      "loss: 0.022073  [  352/ 3000]\n",
      "loss: 0.033852  [  360/ 3000]\n",
      "loss: 0.122293  [  368/ 3000]\n",
      "loss: 0.023710  [  376/ 3000]\n",
      "loss: 0.093209  [  384/ 3000]\n",
      "loss: 0.055723  [  392/ 3000]\n",
      "loss: 0.086370  [  400/ 3000]\n",
      "loss: 0.034528  [  408/ 3000]\n",
      "loss: 0.095502  [  416/ 3000]\n",
      "loss: 0.047531  [  424/ 3000]\n",
      "loss: 0.165655  [  432/ 3000]\n",
      "loss: 0.040693  [  440/ 3000]\n",
      "loss: 0.076108  [  448/ 3000]\n",
      "loss: 0.046531  [  456/ 3000]\n",
      "loss: 0.115997  [  464/ 3000]\n",
      "loss: 0.062572  [  472/ 3000]\n",
      "loss: 0.017980  [  480/ 3000]\n",
      "loss: 0.129788  [  488/ 3000]\n",
      "loss: 0.096028  [  496/ 3000]\n",
      "loss: 0.041599  [  504/ 3000]\n",
      "loss: 0.069895  [  512/ 3000]\n",
      "loss: 0.044576  [  520/ 3000]\n",
      "loss: 0.201496  [  528/ 3000]\n",
      "loss: 0.096851  [  536/ 3000]\n",
      "loss: 0.087298  [  544/ 3000]\n",
      "loss: 0.052354  [  552/ 3000]\n",
      "loss: 0.040528  [  560/ 3000]\n",
      "loss: 0.090713  [  568/ 3000]\n",
      "loss: 0.055984  [  576/ 3000]\n",
      "loss: 0.065182  [  584/ 3000]\n",
      "loss: 0.035496  [  592/ 3000]\n",
      "loss: 0.136355  [  600/ 3000]\n",
      "loss: 0.039529  [  608/ 3000]\n",
      "loss: 0.092564  [  616/ 3000]\n",
      "loss: 0.062727  [  624/ 3000]\n",
      "loss: 0.183482  [  632/ 3000]\n",
      "loss: 0.017948  [  640/ 3000]\n",
      "loss: 0.143376  [  648/ 3000]\n",
      "loss: 0.192117  [  656/ 3000]\n",
      "loss: 0.160940  [  664/ 3000]\n",
      "loss: 0.071044  [  672/ 3000]\n",
      "loss: 0.082264  [  680/ 3000]\n",
      "loss: 0.055262  [  688/ 3000]\n",
      "loss: 0.167331  [  696/ 3000]\n",
      "loss: 0.068629  [  704/ 3000]\n",
      "loss: 0.048223  [  712/ 3000]\n",
      "loss: 0.059243  [  720/ 3000]\n",
      "loss: 0.034578  [  728/ 3000]\n",
      "loss: 0.063812  [  736/ 3000]\n",
      "loss: 0.032965  [  744/ 3000]\n",
      "loss: 0.090925  [  752/ 3000]\n",
      "loss: 0.067230  [  760/ 3000]\n",
      "loss: 0.123006  [  768/ 3000]\n",
      "loss: 0.064043  [  776/ 3000]\n",
      "loss: 0.150844  [  784/ 3000]\n",
      "loss: 0.077332  [  792/ 3000]\n",
      "loss: 0.167603  [  800/ 3000]\n",
      "loss: 0.061767  [  808/ 3000]\n",
      "loss: 0.033659  [  816/ 3000]\n",
      "loss: 0.052461  [  824/ 3000]\n",
      "loss: 0.058479  [  832/ 3000]\n",
      "loss: 0.025024  [  840/ 3000]\n",
      "loss: 0.020541  [  848/ 3000]\n",
      "loss: 0.028345  [  856/ 3000]\n",
      "loss: 0.086797  [  864/ 3000]\n",
      "loss: 0.014175  [  872/ 3000]\n",
      "loss: 0.081234  [  880/ 3000]\n",
      "loss: 0.096788  [  888/ 3000]\n",
      "loss: 0.069421  [  896/ 3000]\n",
      "loss: 0.188717  [  904/ 3000]\n",
      "loss: 0.057473  [  912/ 3000]\n",
      "loss: 0.063700  [  920/ 3000]\n",
      "loss: 0.073458  [  928/ 3000]\n",
      "loss: 0.047197  [  936/ 3000]\n",
      "loss: 0.168777  [  944/ 3000]\n",
      "loss: 0.034422  [  952/ 3000]\n",
      "loss: 0.051666  [  960/ 3000]\n",
      "loss: 0.027593  [  968/ 3000]\n",
      "loss: 0.013498  [  976/ 3000]\n",
      "loss: 0.015932  [  984/ 3000]\n",
      "loss: 0.123957  [  992/ 3000]\n",
      "loss: 0.075133  [ 1000/ 3000]\n",
      "loss: 0.064339  [ 1008/ 3000]\n",
      "loss: 0.118247  [ 1016/ 3000]\n",
      "loss: 0.063629  [ 1024/ 3000]\n",
      "loss: 0.102547  [ 1032/ 3000]\n",
      "loss: 0.017800  [ 1040/ 3000]\n",
      "loss: 0.043972  [ 1048/ 3000]\n",
      "loss: 0.023465  [ 1056/ 3000]\n",
      "loss: 0.076180  [ 1064/ 3000]\n",
      "loss: 0.045684  [ 1072/ 3000]\n",
      "loss: 0.053104  [ 1080/ 3000]\n",
      "loss: 0.105317  [ 1088/ 3000]\n",
      "loss: 0.093622  [ 1096/ 3000]\n",
      "loss: 0.021090  [ 1104/ 3000]\n",
      "loss: 0.102967  [ 1112/ 3000]\n",
      "loss: 0.032313  [ 1120/ 3000]\n",
      "loss: 0.049907  [ 1128/ 3000]\n",
      "loss: 0.047952  [ 1136/ 3000]\n",
      "loss: 0.126539  [ 1144/ 3000]\n",
      "loss: 0.040417  [ 1152/ 3000]\n",
      "loss: 0.030528  [ 1160/ 3000]\n",
      "loss: 0.034197  [ 1168/ 3000]\n",
      "loss: 0.028764  [ 1176/ 3000]\n",
      "loss: 0.169442  [ 1184/ 3000]\n",
      "loss: 0.059730  [ 1192/ 3000]\n",
      "loss: 0.045005  [ 1200/ 3000]\n",
      "loss: 0.039892  [ 1208/ 3000]\n",
      "loss: 0.048322  [ 1216/ 3000]\n",
      "loss: 0.079685  [ 1224/ 3000]\n",
      "loss: 0.091240  [ 1232/ 3000]\n",
      "loss: 0.082258  [ 1240/ 3000]\n",
      "loss: 0.089629  [ 1248/ 3000]\n",
      "loss: 0.012705  [ 1256/ 3000]\n",
      "loss: 0.050453  [ 1264/ 3000]\n",
      "loss: 0.026482  [ 1272/ 3000]\n",
      "loss: 0.033146  [ 1280/ 3000]\n",
      "loss: 0.068372  [ 1288/ 3000]\n",
      "loss: 0.026732  [ 1296/ 3000]\n",
      "loss: 0.004397  [ 1304/ 3000]\n",
      "loss: 0.097476  [ 1312/ 3000]\n",
      "loss: 0.249471  [ 1320/ 3000]\n",
      "loss: 0.098411  [ 1328/ 3000]\n",
      "loss: 0.073618  [ 1336/ 3000]\n",
      "loss: 0.128598  [ 1344/ 3000]\n",
      "loss: 0.081740  [ 1352/ 3000]\n",
      "loss: 0.033307  [ 1360/ 3000]\n",
      "loss: 0.116181  [ 1368/ 3000]\n",
      "loss: 0.133973  [ 1376/ 3000]\n",
      "loss: 0.066807  [ 1384/ 3000]\n",
      "loss: 0.040045  [ 1392/ 3000]\n",
      "loss: 0.087520  [ 1400/ 3000]\n",
      "loss: 0.082033  [ 1408/ 3000]\n",
      "loss: 0.085443  [ 1416/ 3000]\n",
      "loss: 0.124616  [ 1424/ 3000]\n",
      "loss: 0.063328  [ 1432/ 3000]\n",
      "loss: 0.037934  [ 1440/ 3000]\n",
      "loss: 0.036312  [ 1448/ 3000]\n",
      "loss: 0.062106  [ 1456/ 3000]\n",
      "loss: 0.008589  [ 1464/ 3000]\n",
      "loss: 0.047370  [ 1472/ 3000]\n",
      "loss: 0.023425  [ 1480/ 3000]\n",
      "loss: 0.131985  [ 1488/ 3000]\n",
      "loss: 0.030473  [ 1496/ 3000]\n",
      "loss: 0.051456  [ 1504/ 3000]\n",
      "loss: 0.085996  [ 1512/ 3000]\n",
      "loss: 0.076000  [ 1520/ 3000]\n",
      "loss: 0.028747  [ 1528/ 3000]\n",
      "loss: 0.079573  [ 1536/ 3000]\n",
      "loss: 0.033936  [ 1544/ 3000]\n",
      "loss: 0.109432  [ 1552/ 3000]\n",
      "loss: 0.044120  [ 1560/ 3000]\n",
      "loss: 0.039352  [ 1568/ 3000]\n",
      "loss: 0.024944  [ 1576/ 3000]\n",
      "loss: 0.099306  [ 1584/ 3000]\n",
      "loss: 0.055358  [ 1592/ 3000]\n",
      "loss: 0.089069  [ 1600/ 3000]\n",
      "loss: 0.038535  [ 1608/ 3000]\n",
      "loss: 0.132351  [ 1616/ 3000]\n",
      "loss: 0.106394  [ 1624/ 3000]\n",
      "loss: 0.044862  [ 1632/ 3000]\n",
      "loss: 0.046791  [ 1640/ 3000]\n",
      "loss: 0.117670  [ 1648/ 3000]\n",
      "loss: 0.037575  [ 1656/ 3000]\n",
      "loss: 0.112721  [ 1664/ 3000]\n",
      "loss: 0.021667  [ 1672/ 3000]\n",
      "loss: 0.048065  [ 1680/ 3000]\n",
      "loss: 0.059526  [ 1688/ 3000]\n",
      "loss: 0.088516  [ 1696/ 3000]\n",
      "loss: 0.050428  [ 1704/ 3000]\n",
      "loss: 0.024365  [ 1712/ 3000]\n",
      "loss: 0.034338  [ 1720/ 3000]\n",
      "loss: 0.056551  [ 1728/ 3000]\n",
      "loss: 0.083895  [ 1736/ 3000]\n",
      "loss: 0.074260  [ 1744/ 3000]\n",
      "loss: 0.018394  [ 1752/ 3000]\n",
      "loss: 0.009094  [ 1760/ 3000]\n",
      "loss: 0.102952  [ 1768/ 3000]\n",
      "loss: 0.060724  [ 1776/ 3000]\n",
      "loss: 0.027372  [ 1784/ 3000]\n",
      "loss: 0.046230  [ 1792/ 3000]\n",
      "loss: 0.089113  [ 1800/ 3000]\n",
      "loss: 0.124085  [ 1808/ 3000]\n",
      "loss: 0.035420  [ 1816/ 3000]\n",
      "loss: 0.119290  [ 1824/ 3000]\n",
      "loss: 0.005801  [ 1832/ 3000]\n",
      "loss: 0.009771  [ 1840/ 3000]\n",
      "loss: 0.050429  [ 1848/ 3000]\n",
      "loss: 0.074887  [ 1856/ 3000]\n",
      "loss: 0.073001  [ 1864/ 3000]\n",
      "loss: 0.066242  [ 1872/ 3000]\n",
      "loss: 0.011890  [ 1880/ 3000]\n",
      "loss: 0.018440  [ 1888/ 3000]\n",
      "loss: 0.062969  [ 1896/ 3000]\n",
      "loss: 0.031897  [ 1904/ 3000]\n",
      "loss: 0.035887  [ 1912/ 3000]\n",
      "loss: 0.098806  [ 1920/ 3000]\n",
      "loss: 0.076749  [ 1928/ 3000]\n",
      "loss: 0.121701  [ 1936/ 3000]\n",
      "loss: 0.014630  [ 1944/ 3000]\n",
      "loss: 0.087510  [ 1952/ 3000]\n",
      "loss: 0.030002  [ 1960/ 3000]\n",
      "loss: 0.101757  [ 1968/ 3000]\n",
      "loss: 0.031063  [ 1976/ 3000]\n",
      "loss: 0.113749  [ 1984/ 3000]\n",
      "loss: 0.120285  [ 1992/ 3000]\n",
      "loss: 0.062403  [ 2000/ 3000]\n",
      "loss: 0.092067  [ 2008/ 3000]\n",
      "loss: 0.052687  [ 2016/ 3000]\n",
      "loss: 0.055581  [ 2024/ 3000]\n",
      "loss: 0.092645  [ 2032/ 3000]\n",
      "loss: 0.077966  [ 2040/ 3000]\n",
      "loss: 0.035975  [ 2048/ 3000]\n",
      "loss: 0.036207  [ 2056/ 3000]\n",
      "loss: 0.026039  [ 2064/ 3000]\n",
      "loss: 0.106228  [ 2072/ 3000]\n",
      "loss: 0.045609  [ 2080/ 3000]\n",
      "loss: 0.097279  [ 2088/ 3000]\n",
      "loss: 0.071636  [ 2096/ 3000]\n",
      "loss: 0.046194  [ 2104/ 3000]\n",
      "loss: 0.030577  [ 2112/ 3000]\n",
      "loss: 0.015204  [ 2120/ 3000]\n",
      "loss: 0.065867  [ 2128/ 3000]\n",
      "loss: 0.063007  [ 2136/ 3000]\n",
      "loss: 0.098550  [ 2144/ 3000]\n",
      "loss: 0.129346  [ 2152/ 3000]\n",
      "loss: 0.023043  [ 2160/ 3000]\n",
      "loss: 0.060618  [ 2168/ 3000]\n",
      "loss: 0.025064  [ 2176/ 3000]\n",
      "loss: 0.085912  [ 2184/ 3000]\n",
      "loss: 0.063590  [ 2192/ 3000]\n",
      "loss: 0.031599  [ 2200/ 3000]\n",
      "loss: 0.018093  [ 2208/ 3000]\n",
      "loss: 0.035782  [ 2216/ 3000]\n",
      "loss: 0.093916  [ 2224/ 3000]\n",
      "loss: 0.068659  [ 2232/ 3000]\n",
      "loss: 0.113445  [ 2240/ 3000]\n",
      "loss: 0.012604  [ 2248/ 3000]\n",
      "loss: 0.051650  [ 2256/ 3000]\n",
      "loss: 0.019372  [ 2264/ 3000]\n",
      "loss: 0.123378  [ 2272/ 3000]\n",
      "loss: 0.041277  [ 2280/ 3000]\n",
      "loss: 0.106897  [ 2288/ 3000]\n",
      "loss: 0.061874  [ 2296/ 3000]\n",
      "loss: 0.048859  [ 2304/ 3000]\n",
      "loss: 0.026613  [ 2312/ 3000]\n",
      "loss: 0.020561  [ 2320/ 3000]\n",
      "loss: 0.072258  [ 2328/ 3000]\n",
      "loss: 0.014318  [ 2336/ 3000]\n",
      "loss: 0.106578  [ 2344/ 3000]\n",
      "loss: 0.102003  [ 2352/ 3000]\n",
      "loss: 0.096442  [ 2360/ 3000]\n",
      "loss: 0.041638  [ 2368/ 3000]\n",
      "loss: 0.026332  [ 2376/ 3000]\n",
      "loss: 0.051791  [ 2384/ 3000]\n",
      "loss: 0.050967  [ 2392/ 3000]\n",
      "loss: 0.009133  [ 2400/ 3000]\n",
      "loss: 0.115951  [ 2408/ 3000]\n",
      "loss: 0.077114  [ 2416/ 3000]\n",
      "loss: 0.074143  [ 2424/ 3000]\n",
      "loss: 0.088073  [ 2432/ 3000]\n",
      "loss: 0.049341  [ 2440/ 3000]\n",
      "loss: 0.101607  [ 2448/ 3000]\n",
      "loss: 0.108674  [ 2456/ 3000]\n",
      "loss: 0.045596  [ 2464/ 3000]\n",
      "loss: 0.223705  [ 2472/ 3000]\n",
      "loss: 0.026928  [ 2480/ 3000]\n",
      "loss: 0.051456  [ 2488/ 3000]\n",
      "loss: 0.014708  [ 2496/ 3000]\n",
      "loss: 0.033274  [ 2504/ 3000]\n",
      "loss: 0.110416  [ 2512/ 3000]\n",
      "loss: 0.205022  [ 2520/ 3000]\n",
      "loss: 0.030451  [ 2528/ 3000]\n",
      "loss: 0.059802  [ 2536/ 3000]\n",
      "loss: 0.017797  [ 2544/ 3000]\n",
      "loss: 0.086356  [ 2552/ 3000]\n",
      "loss: 0.084189  [ 2560/ 3000]\n",
      "loss: 0.129848  [ 2568/ 3000]\n",
      "loss: 0.104054  [ 2576/ 3000]\n",
      "loss: 0.058923  [ 2584/ 3000]\n",
      "loss: 0.046569  [ 2592/ 3000]\n",
      "loss: 0.069257  [ 2600/ 3000]\n",
      "loss: 0.080945  [ 2608/ 3000]\n",
      "loss: 0.029137  [ 2616/ 3000]\n",
      "loss: 0.030042  [ 2624/ 3000]\n",
      "loss: 0.103833  [ 2632/ 3000]\n",
      "loss: 0.117662  [ 2640/ 3000]\n",
      "loss: 0.075942  [ 2648/ 3000]\n",
      "loss: 0.079119  [ 2656/ 3000]\n",
      "loss: 0.054060  [ 2664/ 3000]\n",
      "loss: 0.098542  [ 2672/ 3000]\n",
      "loss: 0.112986  [ 2680/ 3000]\n",
      "loss: 0.049442  [ 2688/ 3000]\n",
      "loss: 0.038306  [ 2696/ 3000]\n",
      "loss: 0.079678  [ 2704/ 3000]\n",
      "loss: 0.072945  [ 2712/ 3000]\n",
      "loss: 0.052883  [ 2720/ 3000]\n",
      "loss: 0.100357  [ 2728/ 3000]\n",
      "loss: 0.029195  [ 2736/ 3000]\n",
      "loss: 0.064637  [ 2744/ 3000]\n",
      "loss: 0.080327  [ 2752/ 3000]\n",
      "loss: 0.058644  [ 2760/ 3000]\n",
      "loss: 0.019856  [ 2768/ 3000]\n",
      "loss: 0.105135  [ 2776/ 3000]\n",
      "loss: 0.069547  [ 2784/ 3000]\n",
      "loss: 0.040477  [ 2792/ 3000]\n",
      "loss: 0.099879  [ 2800/ 3000]\n",
      "loss: 0.144283  [ 2808/ 3000]\n",
      "loss: 0.059857  [ 2816/ 3000]\n",
      "loss: 0.075121  [ 2824/ 3000]\n",
      "loss: 0.077071  [ 2832/ 3000]\n",
      "loss: 0.054186  [ 2840/ 3000]\n",
      "loss: 0.051344  [ 2848/ 3000]\n",
      "loss: 0.076617  [ 2856/ 3000]\n",
      "loss: 0.032261  [ 2864/ 3000]\n",
      "loss: 0.087149  [ 2872/ 3000]\n",
      "loss: 0.098907  [ 2880/ 3000]\n",
      "loss: 0.014946  [ 2888/ 3000]\n",
      "loss: 0.014149  [ 2896/ 3000]\n",
      "loss: 0.061957  [ 2904/ 3000]\n",
      "loss: 0.090182  [ 2912/ 3000]\n",
      "loss: 0.057092  [ 2920/ 3000]\n",
      "loss: 0.104829  [ 2928/ 3000]\n",
      "loss: 0.157051  [ 2936/ 3000]\n",
      "loss: 0.029180  [ 2944/ 3000]\n",
      "loss: 0.005364  [ 2952/ 3000]\n",
      "loss: 0.029265  [ 2960/ 3000]\n",
      "loss: 0.056359  [ 2968/ 3000]\n",
      "loss: 0.051193  [ 2976/ 3000]\n",
      "loss: 0.062581  [ 2984/ 3000]\n",
      "loss: 0.011202  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.086173 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.027879  [    0/ 3000]\n",
      "loss: 0.068663  [    8/ 3000]\n",
      "loss: 0.022022  [   16/ 3000]\n",
      "loss: 0.029653  [   24/ 3000]\n",
      "loss: 0.101564  [   32/ 3000]\n",
      "loss: 0.017240  [   40/ 3000]\n",
      "loss: 0.022551  [   48/ 3000]\n",
      "loss: 0.073664  [   56/ 3000]\n",
      "loss: 0.143784  [   64/ 3000]\n",
      "loss: 0.022228  [   72/ 3000]\n",
      "loss: 0.142563  [   80/ 3000]\n",
      "loss: 0.074935  [   88/ 3000]\n",
      "loss: 0.096985  [   96/ 3000]\n",
      "loss: 0.045636  [  104/ 3000]\n",
      "loss: 0.157855  [  112/ 3000]\n",
      "loss: 0.035432  [  120/ 3000]\n",
      "loss: 0.033975  [  128/ 3000]\n",
      "loss: 0.079305  [  136/ 3000]\n",
      "loss: 0.075845  [  144/ 3000]\n",
      "loss: 0.042308  [  152/ 3000]\n",
      "loss: 0.020536  [  160/ 3000]\n",
      "loss: 0.013553  [  168/ 3000]\n",
      "loss: 0.029864  [  176/ 3000]\n",
      "loss: 0.086219  [  184/ 3000]\n",
      "loss: 0.053452  [  192/ 3000]\n",
      "loss: 0.037930  [  200/ 3000]\n",
      "loss: 0.155240  [  208/ 3000]\n",
      "loss: 0.040752  [  216/ 3000]\n",
      "loss: 0.052430  [  224/ 3000]\n",
      "loss: 0.122566  [  232/ 3000]\n",
      "loss: 0.057547  [  240/ 3000]\n",
      "loss: 0.040929  [  248/ 3000]\n",
      "loss: 0.028977  [  256/ 3000]\n",
      "loss: 0.080931  [  264/ 3000]\n",
      "loss: 0.049650  [  272/ 3000]\n",
      "loss: 0.163858  [  280/ 3000]\n",
      "loss: 0.026102  [  288/ 3000]\n",
      "loss: 0.054684  [  296/ 3000]\n",
      "loss: 0.037827  [  304/ 3000]\n",
      "loss: 0.105125  [  312/ 3000]\n",
      "loss: 0.044046  [  320/ 3000]\n",
      "loss: 0.122791  [  328/ 3000]\n",
      "loss: 0.040005  [  336/ 3000]\n",
      "loss: 0.086484  [  344/ 3000]\n",
      "loss: 0.021329  [  352/ 3000]\n",
      "loss: 0.032903  [  360/ 3000]\n",
      "loss: 0.119481  [  368/ 3000]\n",
      "loss: 0.022528  [  376/ 3000]\n",
      "loss: 0.091716  [  384/ 3000]\n",
      "loss: 0.053751  [  392/ 3000]\n",
      "loss: 0.083960  [  400/ 3000]\n",
      "loss: 0.033759  [  408/ 3000]\n",
      "loss: 0.092912  [  416/ 3000]\n",
      "loss: 0.045958  [  424/ 3000]\n",
      "loss: 0.162262  [  432/ 3000]\n",
      "loss: 0.039202  [  440/ 3000]\n",
      "loss: 0.074173  [  448/ 3000]\n",
      "loss: 0.044989  [  456/ 3000]\n",
      "loss: 0.112248  [  464/ 3000]\n",
      "loss: 0.061421  [  472/ 3000]\n",
      "loss: 0.017415  [  480/ 3000]\n",
      "loss: 0.126631  [  488/ 3000]\n",
      "loss: 0.094466  [  496/ 3000]\n",
      "loss: 0.040243  [  504/ 3000]\n",
      "loss: 0.068456  [  512/ 3000]\n",
      "loss: 0.043657  [  520/ 3000]\n",
      "loss: 0.196689  [  528/ 3000]\n",
      "loss: 0.094353  [  536/ 3000]\n",
      "loss: 0.084770  [  544/ 3000]\n",
      "loss: 0.050645  [  552/ 3000]\n",
      "loss: 0.039163  [  560/ 3000]\n",
      "loss: 0.088437  [  568/ 3000]\n",
      "loss: 0.054239  [  576/ 3000]\n",
      "loss: 0.062954  [  584/ 3000]\n",
      "loss: 0.034342  [  592/ 3000]\n",
      "loss: 0.132626  [  600/ 3000]\n",
      "loss: 0.038366  [  608/ 3000]\n",
      "loss: 0.089993  [  616/ 3000]\n",
      "loss: 0.060998  [  624/ 3000]\n",
      "loss: 0.179602  [  632/ 3000]\n",
      "loss: 0.017301  [  640/ 3000]\n",
      "loss: 0.139845  [  648/ 3000]\n",
      "loss: 0.187489  [  656/ 3000]\n",
      "loss: 0.157703  [  664/ 3000]\n",
      "loss: 0.069051  [  672/ 3000]\n",
      "loss: 0.080460  [  680/ 3000]\n",
      "loss: 0.053818  [  688/ 3000]\n",
      "loss: 0.163373  [  696/ 3000]\n",
      "loss: 0.067500  [  704/ 3000]\n",
      "loss: 0.046865  [  712/ 3000]\n",
      "loss: 0.057926  [  720/ 3000]\n",
      "loss: 0.033485  [  728/ 3000]\n",
      "loss: 0.062300  [  736/ 3000]\n",
      "loss: 0.031322  [  744/ 3000]\n",
      "loss: 0.088187  [  752/ 3000]\n",
      "loss: 0.065188  [  760/ 3000]\n",
      "loss: 0.121030  [  768/ 3000]\n",
      "loss: 0.062646  [  776/ 3000]\n",
      "loss: 0.147194  [  784/ 3000]\n",
      "loss: 0.074319  [  792/ 3000]\n",
      "loss: 0.165397  [  800/ 3000]\n",
      "loss: 0.060245  [  808/ 3000]\n",
      "loss: 0.032581  [  816/ 3000]\n",
      "loss: 0.051274  [  824/ 3000]\n",
      "loss: 0.056797  [  832/ 3000]\n",
      "loss: 0.023944  [  840/ 3000]\n",
      "loss: 0.019919  [  848/ 3000]\n",
      "loss: 0.027470  [  856/ 3000]\n",
      "loss: 0.084628  [  864/ 3000]\n",
      "loss: 0.013492  [  872/ 3000]\n",
      "loss: 0.079516  [  880/ 3000]\n",
      "loss: 0.094199  [  888/ 3000]\n",
      "loss: 0.068662  [  896/ 3000]\n",
      "loss: 0.184169  [  904/ 3000]\n",
      "loss: 0.056545  [  912/ 3000]\n",
      "loss: 0.062221  [  920/ 3000]\n",
      "loss: 0.071646  [  928/ 3000]\n",
      "loss: 0.045371  [  936/ 3000]\n",
      "loss: 0.164513  [  944/ 3000]\n",
      "loss: 0.033004  [  952/ 3000]\n",
      "loss: 0.050500  [  960/ 3000]\n",
      "loss: 0.026578  [  968/ 3000]\n",
      "loss: 0.012951  [  976/ 3000]\n",
      "loss: 0.015191  [  984/ 3000]\n",
      "loss: 0.120897  [  992/ 3000]\n",
      "loss: 0.072820  [ 1000/ 3000]\n",
      "loss: 0.062707  [ 1008/ 3000]\n",
      "loss: 0.115116  [ 1016/ 3000]\n",
      "loss: 0.061830  [ 1024/ 3000]\n",
      "loss: 0.099885  [ 1032/ 3000]\n",
      "loss: 0.017143  [ 1040/ 3000]\n",
      "loss: 0.042517  [ 1048/ 3000]\n",
      "loss: 0.022540  [ 1056/ 3000]\n",
      "loss: 0.074031  [ 1064/ 3000]\n",
      "loss: 0.044174  [ 1072/ 3000]\n",
      "loss: 0.051531  [ 1080/ 3000]\n",
      "loss: 0.102492  [ 1088/ 3000]\n",
      "loss: 0.091045  [ 1096/ 3000]\n",
      "loss: 0.020208  [ 1104/ 3000]\n",
      "loss: 0.099845  [ 1112/ 3000]\n",
      "loss: 0.031148  [ 1120/ 3000]\n",
      "loss: 0.049008  [ 1128/ 3000]\n",
      "loss: 0.046288  [ 1136/ 3000]\n",
      "loss: 0.122278  [ 1144/ 3000]\n",
      "loss: 0.039248  [ 1152/ 3000]\n",
      "loss: 0.029605  [ 1160/ 3000]\n",
      "loss: 0.033093  [ 1168/ 3000]\n",
      "loss: 0.027670  [ 1176/ 3000]\n",
      "loss: 0.165276  [ 1184/ 3000]\n",
      "loss: 0.058190  [ 1192/ 3000]\n",
      "loss: 0.042945  [ 1200/ 3000]\n",
      "loss: 0.039042  [ 1208/ 3000]\n",
      "loss: 0.046208  [ 1216/ 3000]\n",
      "loss: 0.077231  [ 1224/ 3000]\n",
      "loss: 0.088450  [ 1232/ 3000]\n",
      "loss: 0.080011  [ 1240/ 3000]\n",
      "loss: 0.086634  [ 1248/ 3000]\n",
      "loss: 0.012063  [ 1256/ 3000]\n",
      "loss: 0.049692  [ 1264/ 3000]\n",
      "loss: 0.025572  [ 1272/ 3000]\n",
      "loss: 0.031627  [ 1280/ 3000]\n",
      "loss: 0.065711  [ 1288/ 3000]\n",
      "loss: 0.025461  [ 1296/ 3000]\n",
      "loss: 0.004149  [ 1304/ 3000]\n",
      "loss: 0.094597  [ 1312/ 3000]\n",
      "loss: 0.242402  [ 1320/ 3000]\n",
      "loss: 0.095560  [ 1328/ 3000]\n",
      "loss: 0.072215  [ 1336/ 3000]\n",
      "loss: 0.125117  [ 1344/ 3000]\n",
      "loss: 0.080018  [ 1352/ 3000]\n",
      "loss: 0.031829  [ 1360/ 3000]\n",
      "loss: 0.113790  [ 1368/ 3000]\n",
      "loss: 0.131599  [ 1376/ 3000]\n",
      "loss: 0.064313  [ 1384/ 3000]\n",
      "loss: 0.038416  [ 1392/ 3000]\n",
      "loss: 0.085210  [ 1400/ 3000]\n",
      "loss: 0.079964  [ 1408/ 3000]\n",
      "loss: 0.083135  [ 1416/ 3000]\n",
      "loss: 0.122430  [ 1424/ 3000]\n",
      "loss: 0.061225  [ 1432/ 3000]\n",
      "loss: 0.036785  [ 1440/ 3000]\n",
      "loss: 0.034965  [ 1448/ 3000]\n",
      "loss: 0.060095  [ 1456/ 3000]\n",
      "loss: 0.008292  [ 1464/ 3000]\n",
      "loss: 0.046355  [ 1472/ 3000]\n",
      "loss: 0.023001  [ 1480/ 3000]\n",
      "loss: 0.129321  [ 1488/ 3000]\n",
      "loss: 0.029402  [ 1496/ 3000]\n",
      "loss: 0.049716  [ 1504/ 3000]\n",
      "loss: 0.084016  [ 1512/ 3000]\n",
      "loss: 0.073754  [ 1520/ 3000]\n",
      "loss: 0.027521  [ 1528/ 3000]\n",
      "loss: 0.077663  [ 1536/ 3000]\n",
      "loss: 0.032220  [ 1544/ 3000]\n",
      "loss: 0.106547  [ 1552/ 3000]\n",
      "loss: 0.042682  [ 1560/ 3000]\n",
      "loss: 0.038008  [ 1568/ 3000]\n",
      "loss: 0.023980  [ 1576/ 3000]\n",
      "loss: 0.097259  [ 1584/ 3000]\n",
      "loss: 0.054262  [ 1592/ 3000]\n",
      "loss: 0.086444  [ 1600/ 3000]\n",
      "loss: 0.037471  [ 1608/ 3000]\n",
      "loss: 0.129718  [ 1616/ 3000]\n",
      "loss: 0.104112  [ 1624/ 3000]\n",
      "loss: 0.043447  [ 1632/ 3000]\n",
      "loss: 0.045397  [ 1640/ 3000]\n",
      "loss: 0.114927  [ 1648/ 3000]\n",
      "loss: 0.036631  [ 1656/ 3000]\n",
      "loss: 0.108003  [ 1664/ 3000]\n",
      "loss: 0.020560  [ 1672/ 3000]\n",
      "loss: 0.047037  [ 1680/ 3000]\n",
      "loss: 0.057726  [ 1688/ 3000]\n",
      "loss: 0.086583  [ 1696/ 3000]\n",
      "loss: 0.048572  [ 1704/ 3000]\n",
      "loss: 0.023617  [ 1712/ 3000]\n",
      "loss: 0.032684  [ 1720/ 3000]\n",
      "loss: 0.055094  [ 1728/ 3000]\n",
      "loss: 0.081800  [ 1736/ 3000]\n",
      "loss: 0.072472  [ 1744/ 3000]\n",
      "loss: 0.017849  [ 1752/ 3000]\n",
      "loss: 0.008664  [ 1760/ 3000]\n",
      "loss: 0.099335  [ 1768/ 3000]\n",
      "loss: 0.058326  [ 1776/ 3000]\n",
      "loss: 0.026421  [ 1784/ 3000]\n",
      "loss: 0.044800  [ 1792/ 3000]\n",
      "loss: 0.086556  [ 1800/ 3000]\n",
      "loss: 0.120886  [ 1808/ 3000]\n",
      "loss: 0.034287  [ 1816/ 3000]\n",
      "loss: 0.115931  [ 1824/ 3000]\n",
      "loss: 0.005412  [ 1832/ 3000]\n",
      "loss: 0.009463  [ 1840/ 3000]\n",
      "loss: 0.048695  [ 1848/ 3000]\n",
      "loss: 0.072872  [ 1856/ 3000]\n",
      "loss: 0.070670  [ 1864/ 3000]\n",
      "loss: 0.064669  [ 1872/ 3000]\n",
      "loss: 0.011150  [ 1880/ 3000]\n",
      "loss: 0.017413  [ 1888/ 3000]\n",
      "loss: 0.060658  [ 1896/ 3000]\n",
      "loss: 0.031455  [ 1904/ 3000]\n",
      "loss: 0.034531  [ 1912/ 3000]\n",
      "loss: 0.096885  [ 1920/ 3000]\n",
      "loss: 0.074532  [ 1928/ 3000]\n",
      "loss: 0.118286  [ 1936/ 3000]\n",
      "loss: 0.013961  [ 1944/ 3000]\n",
      "loss: 0.085656  [ 1952/ 3000]\n",
      "loss: 0.028967  [ 1960/ 3000]\n",
      "loss: 0.099357  [ 1968/ 3000]\n",
      "loss: 0.030051  [ 1976/ 3000]\n",
      "loss: 0.111072  [ 1984/ 3000]\n",
      "loss: 0.117716  [ 1992/ 3000]\n",
      "loss: 0.060242  [ 2000/ 3000]\n",
      "loss: 0.089551  [ 2008/ 3000]\n",
      "loss: 0.050437  [ 2016/ 3000]\n",
      "loss: 0.054381  [ 2024/ 3000]\n",
      "loss: 0.090600  [ 2032/ 3000]\n",
      "loss: 0.076250  [ 2040/ 3000]\n",
      "loss: 0.034996  [ 2048/ 3000]\n",
      "loss: 0.035003  [ 2056/ 3000]\n",
      "loss: 0.024768  [ 2064/ 3000]\n",
      "loss: 0.103621  [ 2072/ 3000]\n",
      "loss: 0.044213  [ 2080/ 3000]\n",
      "loss: 0.094227  [ 2088/ 3000]\n",
      "loss: 0.069826  [ 2096/ 3000]\n",
      "loss: 0.045085  [ 2104/ 3000]\n",
      "loss: 0.030091  [ 2112/ 3000]\n",
      "loss: 0.014626  [ 2120/ 3000]\n",
      "loss: 0.064827  [ 2128/ 3000]\n",
      "loss: 0.061525  [ 2136/ 3000]\n",
      "loss: 0.096316  [ 2144/ 3000]\n",
      "loss: 0.127240  [ 2152/ 3000]\n",
      "loss: 0.022160  [ 2160/ 3000]\n",
      "loss: 0.058883  [ 2168/ 3000]\n",
      "loss: 0.024245  [ 2176/ 3000]\n",
      "loss: 0.083735  [ 2184/ 3000]\n",
      "loss: 0.060454  [ 2192/ 3000]\n",
      "loss: 0.030694  [ 2200/ 3000]\n",
      "loss: 0.017289  [ 2208/ 3000]\n",
      "loss: 0.034722  [ 2216/ 3000]\n",
      "loss: 0.091317  [ 2224/ 3000]\n",
      "loss: 0.066624  [ 2232/ 3000]\n",
      "loss: 0.110946  [ 2240/ 3000]\n",
      "loss: 0.012132  [ 2248/ 3000]\n",
      "loss: 0.049571  [ 2256/ 3000]\n",
      "loss: 0.018456  [ 2264/ 3000]\n",
      "loss: 0.120555  [ 2272/ 3000]\n",
      "loss: 0.040228  [ 2280/ 3000]\n",
      "loss: 0.103359  [ 2288/ 3000]\n",
      "loss: 0.060177  [ 2296/ 3000]\n",
      "loss: 0.047439  [ 2304/ 3000]\n",
      "loss: 0.025714  [ 2312/ 3000]\n",
      "loss: 0.019634  [ 2320/ 3000]\n",
      "loss: 0.070131  [ 2328/ 3000]\n",
      "loss: 0.013828  [ 2336/ 3000]\n",
      "loss: 0.104119  [ 2344/ 3000]\n",
      "loss: 0.098439  [ 2352/ 3000]\n",
      "loss: 0.094383  [ 2360/ 3000]\n",
      "loss: 0.040461  [ 2368/ 3000]\n",
      "loss: 0.025485  [ 2376/ 3000]\n",
      "loss: 0.050591  [ 2384/ 3000]\n",
      "loss: 0.049203  [ 2392/ 3000]\n",
      "loss: 0.008670  [ 2400/ 3000]\n",
      "loss: 0.113800  [ 2408/ 3000]\n",
      "loss: 0.075570  [ 2416/ 3000]\n",
      "loss: 0.071479  [ 2424/ 3000]\n",
      "loss: 0.086026  [ 2432/ 3000]\n",
      "loss: 0.048105  [ 2440/ 3000]\n",
      "loss: 0.098215  [ 2448/ 3000]\n",
      "loss: 0.106309  [ 2456/ 3000]\n",
      "loss: 0.044207  [ 2464/ 3000]\n",
      "loss: 0.219859  [ 2472/ 3000]\n",
      "loss: 0.026476  [ 2480/ 3000]\n",
      "loss: 0.049939  [ 2488/ 3000]\n",
      "loss: 0.014000  [ 2496/ 3000]\n",
      "loss: 0.032065  [ 2504/ 3000]\n",
      "loss: 0.107614  [ 2512/ 3000]\n",
      "loss: 0.201344  [ 2520/ 3000]\n",
      "loss: 0.029201  [ 2528/ 3000]\n",
      "loss: 0.058340  [ 2536/ 3000]\n",
      "loss: 0.017131  [ 2544/ 3000]\n",
      "loss: 0.083620  [ 2552/ 3000]\n",
      "loss: 0.082103  [ 2560/ 3000]\n",
      "loss: 0.127895  [ 2568/ 3000]\n",
      "loss: 0.100440  [ 2576/ 3000]\n",
      "loss: 0.057043  [ 2584/ 3000]\n",
      "loss: 0.045244  [ 2592/ 3000]\n",
      "loss: 0.068328  [ 2600/ 3000]\n",
      "loss: 0.079069  [ 2608/ 3000]\n",
      "loss: 0.028185  [ 2616/ 3000]\n",
      "loss: 0.028804  [ 2624/ 3000]\n",
      "loss: 0.101256  [ 2632/ 3000]\n",
      "loss: 0.115347  [ 2640/ 3000]\n",
      "loss: 0.074247  [ 2648/ 3000]\n",
      "loss: 0.077085  [ 2656/ 3000]\n",
      "loss: 0.052591  [ 2664/ 3000]\n",
      "loss: 0.095589  [ 2672/ 3000]\n",
      "loss: 0.109806  [ 2680/ 3000]\n",
      "loss: 0.048174  [ 2688/ 3000]\n",
      "loss: 0.037255  [ 2696/ 3000]\n",
      "loss: 0.078178  [ 2704/ 3000]\n",
      "loss: 0.070159  [ 2712/ 3000]\n",
      "loss: 0.050841  [ 2720/ 3000]\n",
      "loss: 0.096929  [ 2728/ 3000]\n",
      "loss: 0.028426  [ 2736/ 3000]\n",
      "loss: 0.062963  [ 2744/ 3000]\n",
      "loss: 0.077970  [ 2752/ 3000]\n",
      "loss: 0.057169  [ 2760/ 3000]\n",
      "loss: 0.019115  [ 2768/ 3000]\n",
      "loss: 0.101614  [ 2776/ 3000]\n",
      "loss: 0.067739  [ 2784/ 3000]\n",
      "loss: 0.039184  [ 2792/ 3000]\n",
      "loss: 0.097459  [ 2800/ 3000]\n",
      "loss: 0.140935  [ 2808/ 3000]\n",
      "loss: 0.057620  [ 2816/ 3000]\n",
      "loss: 0.073143  [ 2824/ 3000]\n",
      "loss: 0.075155  [ 2832/ 3000]\n",
      "loss: 0.052606  [ 2840/ 3000]\n",
      "loss: 0.049401  [ 2848/ 3000]\n",
      "loss: 0.074497  [ 2856/ 3000]\n",
      "loss: 0.031139  [ 2864/ 3000]\n",
      "loss: 0.085541  [ 2872/ 3000]\n",
      "loss: 0.096052  [ 2880/ 3000]\n",
      "loss: 0.014125  [ 2888/ 3000]\n",
      "loss: 0.013695  [ 2896/ 3000]\n",
      "loss: 0.059824  [ 2904/ 3000]\n",
      "loss: 0.088090  [ 2912/ 3000]\n",
      "loss: 0.054714  [ 2920/ 3000]\n",
      "loss: 0.101957  [ 2928/ 3000]\n",
      "loss: 0.152114  [ 2936/ 3000]\n",
      "loss: 0.028354  [ 2944/ 3000]\n",
      "loss: 0.005175  [ 2952/ 3000]\n",
      "loss: 0.028296  [ 2960/ 3000]\n",
      "loss: 0.054709  [ 2968/ 3000]\n",
      "loss: 0.050028  [ 2976/ 3000]\n",
      "loss: 0.061152  [ 2984/ 3000]\n",
      "loss: 0.010693  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085928 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.027140  [    0/ 3000]\n",
      "loss: 0.067009  [    8/ 3000]\n",
      "loss: 0.020993  [   16/ 3000]\n",
      "loss: 0.028420  [   24/ 3000]\n",
      "loss: 0.098410  [   32/ 3000]\n",
      "loss: 0.016454  [   40/ 3000]\n",
      "loss: 0.021805  [   48/ 3000]\n",
      "loss: 0.072131  [   56/ 3000]\n",
      "loss: 0.139651  [   64/ 3000]\n",
      "loss: 0.021738  [   72/ 3000]\n",
      "loss: 0.139748  [   80/ 3000]\n",
      "loss: 0.072491  [   88/ 3000]\n",
      "loss: 0.094678  [   96/ 3000]\n",
      "loss: 0.043062  [  104/ 3000]\n",
      "loss: 0.154595  [  112/ 3000]\n",
      "loss: 0.034303  [  120/ 3000]\n",
      "loss: 0.033590  [  128/ 3000]\n",
      "loss: 0.076516  [  136/ 3000]\n",
      "loss: 0.073622  [  144/ 3000]\n",
      "loss: 0.040917  [  152/ 3000]\n",
      "loss: 0.019848  [  160/ 3000]\n",
      "loss: 0.013113  [  168/ 3000]\n",
      "loss: 0.028575  [  176/ 3000]\n",
      "loss: 0.083921  [  184/ 3000]\n",
      "loss: 0.051235  [  192/ 3000]\n",
      "loss: 0.036790  [  200/ 3000]\n",
      "loss: 0.152006  [  208/ 3000]\n",
      "loss: 0.039308  [  216/ 3000]\n",
      "loss: 0.050891  [  224/ 3000]\n",
      "loss: 0.119901  [  232/ 3000]\n",
      "loss: 0.056223  [  240/ 3000]\n",
      "loss: 0.039330  [  248/ 3000]\n",
      "loss: 0.028038  [  256/ 3000]\n",
      "loss: 0.077854  [  264/ 3000]\n",
      "loss: 0.048878  [  272/ 3000]\n",
      "loss: 0.161104  [  280/ 3000]\n",
      "loss: 0.025204  [  288/ 3000]\n",
      "loss: 0.053534  [  296/ 3000]\n",
      "loss: 0.036677  [  304/ 3000]\n",
      "loss: 0.102277  [  312/ 3000]\n",
      "loss: 0.042391  [  320/ 3000]\n",
      "loss: 0.118114  [  328/ 3000]\n",
      "loss: 0.038339  [  336/ 3000]\n",
      "loss: 0.084834  [  344/ 3000]\n",
      "loss: 0.020600  [  352/ 3000]\n",
      "loss: 0.031944  [  360/ 3000]\n",
      "loss: 0.116563  [  368/ 3000]\n",
      "loss: 0.021358  [  376/ 3000]\n",
      "loss: 0.090364  [  384/ 3000]\n",
      "loss: 0.051805  [  392/ 3000]\n",
      "loss: 0.081597  [  400/ 3000]\n",
      "loss: 0.033033  [  408/ 3000]\n",
      "loss: 0.090307  [  416/ 3000]\n",
      "loss: 0.044401  [  424/ 3000]\n",
      "loss: 0.158733  [  432/ 3000]\n",
      "loss: 0.037759  [  440/ 3000]\n",
      "loss: 0.072241  [  448/ 3000]\n",
      "loss: 0.043498  [  456/ 3000]\n",
      "loss: 0.108457  [  464/ 3000]\n",
      "loss: 0.060233  [  472/ 3000]\n",
      "loss: 0.016880  [  480/ 3000]\n",
      "loss: 0.123537  [  488/ 3000]\n",
      "loss: 0.092818  [  496/ 3000]\n",
      "loss: 0.038956  [  504/ 3000]\n",
      "loss: 0.067047  [  512/ 3000]\n",
      "loss: 0.042711  [  520/ 3000]\n",
      "loss: 0.192050  [  528/ 3000]\n",
      "loss: 0.091718  [  536/ 3000]\n",
      "loss: 0.082142  [  544/ 3000]\n",
      "loss: 0.048877  [  552/ 3000]\n",
      "loss: 0.037908  [  560/ 3000]\n",
      "loss: 0.086213  [  568/ 3000]\n",
      "loss: 0.052624  [  576/ 3000]\n",
      "loss: 0.060782  [  584/ 3000]\n",
      "loss: 0.033222  [  592/ 3000]\n",
      "loss: 0.129098  [  600/ 3000]\n",
      "loss: 0.037258  [  608/ 3000]\n",
      "loss: 0.087409  [  616/ 3000]\n",
      "loss: 0.059248  [  624/ 3000]\n",
      "loss: 0.175449  [  632/ 3000]\n",
      "loss: 0.016734  [  640/ 3000]\n",
      "loss: 0.136331  [  648/ 3000]\n",
      "loss: 0.182957  [  656/ 3000]\n",
      "loss: 0.154414  [  664/ 3000]\n",
      "loss: 0.067108  [  672/ 3000]\n",
      "loss: 0.078621  [  680/ 3000]\n",
      "loss: 0.052400  [  688/ 3000]\n",
      "loss: 0.159524  [  696/ 3000]\n",
      "loss: 0.066388  [  704/ 3000]\n",
      "loss: 0.045551  [  712/ 3000]\n",
      "loss: 0.056613  [  720/ 3000]\n",
      "loss: 0.032400  [  728/ 3000]\n",
      "loss: 0.060731  [  736/ 3000]\n",
      "loss: 0.029720  [  744/ 3000]\n",
      "loss: 0.085562  [  752/ 3000]\n",
      "loss: 0.063225  [  760/ 3000]\n",
      "loss: 0.118984  [  768/ 3000]\n",
      "loss: 0.061263  [  776/ 3000]\n",
      "loss: 0.143571  [  784/ 3000]\n",
      "loss: 0.071427  [  792/ 3000]\n",
      "loss: 0.163085  [  800/ 3000]\n",
      "loss: 0.058919  [  808/ 3000]\n",
      "loss: 0.031637  [  816/ 3000]\n",
      "loss: 0.050053  [  824/ 3000]\n",
      "loss: 0.055150  [  832/ 3000]\n",
      "loss: 0.022920  [  840/ 3000]\n",
      "loss: 0.019338  [  848/ 3000]\n",
      "loss: 0.026572  [  856/ 3000]\n",
      "loss: 0.082483  [  864/ 3000]\n",
      "loss: 0.012821  [  872/ 3000]\n",
      "loss: 0.077821  [  880/ 3000]\n",
      "loss: 0.091528  [  888/ 3000]\n",
      "loss: 0.067919  [  896/ 3000]\n",
      "loss: 0.179675  [  904/ 3000]\n",
      "loss: 0.055722  [  912/ 3000]\n",
      "loss: 0.060708  [  920/ 3000]\n",
      "loss: 0.069825  [  928/ 3000]\n",
      "loss: 0.043602  [  936/ 3000]\n",
      "loss: 0.160397  [  944/ 3000]\n",
      "loss: 0.031633  [  952/ 3000]\n",
      "loss: 0.049362  [  960/ 3000]\n",
      "loss: 0.025588  [  968/ 3000]\n",
      "loss: 0.012407  [  976/ 3000]\n",
      "loss: 0.014470  [  984/ 3000]\n",
      "loss: 0.117942  [  992/ 3000]\n",
      "loss: 0.070429  [ 1000/ 3000]\n",
      "loss: 0.061005  [ 1008/ 3000]\n",
      "loss: 0.111959  [ 1016/ 3000]\n",
      "loss: 0.060081  [ 1024/ 3000]\n",
      "loss: 0.097332  [ 1032/ 3000]\n",
      "loss: 0.016540  [ 1040/ 3000]\n",
      "loss: 0.041162  [ 1048/ 3000]\n",
      "loss: 0.021604  [ 1056/ 3000]\n",
      "loss: 0.071911  [ 1064/ 3000]\n",
      "loss: 0.042753  [ 1072/ 3000]\n",
      "loss: 0.049920  [ 1080/ 3000]\n",
      "loss: 0.099626  [ 1088/ 3000]\n",
      "loss: 0.088365  [ 1096/ 3000]\n",
      "loss: 0.019374  [ 1104/ 3000]\n",
      "loss: 0.096602  [ 1112/ 3000]\n",
      "loss: 0.030011  [ 1120/ 3000]\n",
      "loss: 0.048074  [ 1128/ 3000]\n",
      "loss: 0.044654  [ 1136/ 3000]\n",
      "loss: 0.118150  [ 1144/ 3000]\n",
      "loss: 0.038086  [ 1152/ 3000]\n",
      "loss: 0.028651  [ 1160/ 3000]\n",
      "loss: 0.031988  [ 1168/ 3000]\n",
      "loss: 0.026633  [ 1176/ 3000]\n",
      "loss: 0.161162  [ 1184/ 3000]\n",
      "loss: 0.056644  [ 1192/ 3000]\n",
      "loss: 0.040984  [ 1200/ 3000]\n",
      "loss: 0.038230  [ 1208/ 3000]\n",
      "loss: 0.044197  [ 1216/ 3000]\n",
      "loss: 0.074928  [ 1224/ 3000]\n",
      "loss: 0.085731  [ 1232/ 3000]\n",
      "loss: 0.077674  [ 1240/ 3000]\n",
      "loss: 0.083647  [ 1248/ 3000]\n",
      "loss: 0.011418  [ 1256/ 3000]\n",
      "loss: 0.048914  [ 1264/ 3000]\n",
      "loss: 0.024748  [ 1272/ 3000]\n",
      "loss: 0.030251  [ 1280/ 3000]\n",
      "loss: 0.063194  [ 1288/ 3000]\n",
      "loss: 0.024254  [ 1296/ 3000]\n",
      "loss: 0.003926  [ 1304/ 3000]\n",
      "loss: 0.091771  [ 1312/ 3000]\n",
      "loss: 0.235328  [ 1320/ 3000]\n",
      "loss: 0.092895  [ 1328/ 3000]\n",
      "loss: 0.070791  [ 1336/ 3000]\n",
      "loss: 0.121765  [ 1344/ 3000]\n",
      "loss: 0.078425  [ 1352/ 3000]\n",
      "loss: 0.030346  [ 1360/ 3000]\n",
      "loss: 0.111570  [ 1368/ 3000]\n",
      "loss: 0.129245  [ 1376/ 3000]\n",
      "loss: 0.061864  [ 1384/ 3000]\n",
      "loss: 0.036823  [ 1392/ 3000]\n",
      "loss: 0.082944  [ 1400/ 3000]\n",
      "loss: 0.077990  [ 1408/ 3000]\n",
      "loss: 0.080866  [ 1416/ 3000]\n",
      "loss: 0.120273  [ 1424/ 3000]\n",
      "loss: 0.059236  [ 1432/ 3000]\n",
      "loss: 0.035615  [ 1440/ 3000]\n",
      "loss: 0.033649  [ 1448/ 3000]\n",
      "loss: 0.058171  [ 1456/ 3000]\n",
      "loss: 0.008006  [ 1464/ 3000]\n",
      "loss: 0.045377  [ 1472/ 3000]\n",
      "loss: 0.022597  [ 1480/ 3000]\n",
      "loss: 0.126461  [ 1488/ 3000]\n",
      "loss: 0.028388  [ 1496/ 3000]\n",
      "loss: 0.048022  [ 1504/ 3000]\n",
      "loss: 0.081892  [ 1512/ 3000]\n",
      "loss: 0.071589  [ 1520/ 3000]\n",
      "loss: 0.026345  [ 1528/ 3000]\n",
      "loss: 0.075836  [ 1536/ 3000]\n",
      "loss: 0.030546  [ 1544/ 3000]\n",
      "loss: 0.103746  [ 1552/ 3000]\n",
      "loss: 0.041370  [ 1560/ 3000]\n",
      "loss: 0.036692  [ 1568/ 3000]\n",
      "loss: 0.023062  [ 1576/ 3000]\n",
      "loss: 0.095236  [ 1584/ 3000]\n",
      "loss: 0.053153  [ 1592/ 3000]\n",
      "loss: 0.083944  [ 1600/ 3000]\n",
      "loss: 0.036338  [ 1608/ 3000]\n",
      "loss: 0.127117  [ 1616/ 3000]\n",
      "loss: 0.101777  [ 1624/ 3000]\n",
      "loss: 0.042013  [ 1632/ 3000]\n",
      "loss: 0.043883  [ 1640/ 3000]\n",
      "loss: 0.112193  [ 1648/ 3000]\n",
      "loss: 0.035661  [ 1656/ 3000]\n",
      "loss: 0.103667  [ 1664/ 3000]\n",
      "loss: 0.019496  [ 1672/ 3000]\n",
      "loss: 0.046046  [ 1680/ 3000]\n",
      "loss: 0.055969  [ 1688/ 3000]\n",
      "loss: 0.084666  [ 1696/ 3000]\n",
      "loss: 0.046852  [ 1704/ 3000]\n",
      "loss: 0.022883  [ 1712/ 3000]\n",
      "loss: 0.031180  [ 1720/ 3000]\n",
      "loss: 0.053664  [ 1728/ 3000]\n",
      "loss: 0.079692  [ 1736/ 3000]\n",
      "loss: 0.070686  [ 1744/ 3000]\n",
      "loss: 0.017341  [ 1752/ 3000]\n",
      "loss: 0.008279  [ 1760/ 3000]\n",
      "loss: 0.095738  [ 1768/ 3000]\n",
      "loss: 0.055901  [ 1776/ 3000]\n",
      "loss: 0.025490  [ 1784/ 3000]\n",
      "loss: 0.043342  [ 1792/ 3000]\n",
      "loss: 0.084034  [ 1800/ 3000]\n",
      "loss: 0.117784  [ 1808/ 3000]\n",
      "loss: 0.033149  [ 1816/ 3000]\n",
      "loss: 0.112688  [ 1824/ 3000]\n",
      "loss: 0.005054  [ 1832/ 3000]\n",
      "loss: 0.009156  [ 1840/ 3000]\n",
      "loss: 0.046994  [ 1848/ 3000]\n",
      "loss: 0.070903  [ 1856/ 3000]\n",
      "loss: 0.068284  [ 1864/ 3000]\n",
      "loss: 0.063088  [ 1872/ 3000]\n",
      "loss: 0.010398  [ 1880/ 3000]\n",
      "loss: 0.016475  [ 1888/ 3000]\n",
      "loss: 0.058463  [ 1896/ 3000]\n",
      "loss: 0.030993  [ 1904/ 3000]\n",
      "loss: 0.033202  [ 1912/ 3000]\n",
      "loss: 0.095016  [ 1920/ 3000]\n",
      "loss: 0.072289  [ 1928/ 3000]\n",
      "loss: 0.114939  [ 1936/ 3000]\n",
      "loss: 0.013350  [ 1944/ 3000]\n",
      "loss: 0.083768  [ 1952/ 3000]\n",
      "loss: 0.027998  [ 1960/ 3000]\n",
      "loss: 0.097038  [ 1968/ 3000]\n",
      "loss: 0.029087  [ 1976/ 3000]\n",
      "loss: 0.108378  [ 1984/ 3000]\n",
      "loss: 0.115035  [ 1992/ 3000]\n",
      "loss: 0.058118  [ 2000/ 3000]\n",
      "loss: 0.087083  [ 2008/ 3000]\n",
      "loss: 0.048373  [ 2016/ 3000]\n",
      "loss: 0.053130  [ 2024/ 3000]\n",
      "loss: 0.088529  [ 2032/ 3000]\n",
      "loss: 0.074485  [ 2040/ 3000]\n",
      "loss: 0.034000  [ 2048/ 3000]\n",
      "loss: 0.033797  [ 2056/ 3000]\n",
      "loss: 0.023650  [ 2064/ 3000]\n",
      "loss: 0.101014  [ 2072/ 3000]\n",
      "loss: 0.042757  [ 2080/ 3000]\n",
      "loss: 0.091252  [ 2088/ 3000]\n",
      "loss: 0.068047  [ 2096/ 3000]\n",
      "loss: 0.044024  [ 2104/ 3000]\n",
      "loss: 0.029567  [ 2112/ 3000]\n",
      "loss: 0.014080  [ 2120/ 3000]\n",
      "loss: 0.063661  [ 2128/ 3000]\n",
      "loss: 0.060070  [ 2136/ 3000]\n",
      "loss: 0.093869  [ 2144/ 3000]\n",
      "loss: 0.125140  [ 2152/ 3000]\n",
      "loss: 0.021348  [ 2160/ 3000]\n",
      "loss: 0.057161  [ 2168/ 3000]\n",
      "loss: 0.023511  [ 2176/ 3000]\n",
      "loss: 0.081547  [ 2184/ 3000]\n",
      "loss: 0.057471  [ 2192/ 3000]\n",
      "loss: 0.029800  [ 2200/ 3000]\n",
      "loss: 0.016419  [ 2208/ 3000]\n",
      "loss: 0.033725  [ 2216/ 3000]\n",
      "loss: 0.088654  [ 2224/ 3000]\n",
      "loss: 0.064547  [ 2232/ 3000]\n",
      "loss: 0.108533  [ 2240/ 3000]\n",
      "loss: 0.011674  [ 2248/ 3000]\n",
      "loss: 0.047519  [ 2256/ 3000]\n",
      "loss: 0.017583  [ 2264/ 3000]\n",
      "loss: 0.117641  [ 2272/ 3000]\n",
      "loss: 0.039292  [ 2280/ 3000]\n",
      "loss: 0.099889  [ 2288/ 3000]\n",
      "loss: 0.058477  [ 2296/ 3000]\n",
      "loss: 0.046103  [ 2304/ 3000]\n",
      "loss: 0.024879  [ 2312/ 3000]\n",
      "loss: 0.018750  [ 2320/ 3000]\n",
      "loss: 0.068121  [ 2328/ 3000]\n",
      "loss: 0.013322  [ 2336/ 3000]\n",
      "loss: 0.101652  [ 2344/ 3000]\n",
      "loss: 0.094860  [ 2352/ 3000]\n",
      "loss: 0.092185  [ 2360/ 3000]\n",
      "loss: 0.039370  [ 2368/ 3000]\n",
      "loss: 0.024655  [ 2376/ 3000]\n",
      "loss: 0.049363  [ 2384/ 3000]\n",
      "loss: 0.047451  [ 2392/ 3000]\n",
      "loss: 0.008257  [ 2400/ 3000]\n",
      "loss: 0.111725  [ 2408/ 3000]\n",
      "loss: 0.074014  [ 2416/ 3000]\n",
      "loss: 0.069015  [ 2424/ 3000]\n",
      "loss: 0.083971  [ 2432/ 3000]\n",
      "loss: 0.046903  [ 2440/ 3000]\n",
      "loss: 0.094968  [ 2448/ 3000]\n",
      "loss: 0.103944  [ 2456/ 3000]\n",
      "loss: 0.042837  [ 2464/ 3000]\n",
      "loss: 0.215910  [ 2472/ 3000]\n",
      "loss: 0.026008  [ 2480/ 3000]\n",
      "loss: 0.048455  [ 2488/ 3000]\n",
      "loss: 0.013311  [ 2496/ 3000]\n",
      "loss: 0.030892  [ 2504/ 3000]\n",
      "loss: 0.104939  [ 2512/ 3000]\n",
      "loss: 0.197488  [ 2520/ 3000]\n",
      "loss: 0.027997  [ 2528/ 3000]\n",
      "loss: 0.056965  [ 2536/ 3000]\n",
      "loss: 0.016503  [ 2544/ 3000]\n",
      "loss: 0.081074  [ 2552/ 3000]\n",
      "loss: 0.079991  [ 2560/ 3000]\n",
      "loss: 0.125839  [ 2568/ 3000]\n",
      "loss: 0.096786  [ 2576/ 3000]\n",
      "loss: 0.055241  [ 2584/ 3000]\n",
      "loss: 0.043963  [ 2592/ 3000]\n",
      "loss: 0.067368  [ 2600/ 3000]\n",
      "loss: 0.077161  [ 2608/ 3000]\n",
      "loss: 0.027225  [ 2616/ 3000]\n",
      "loss: 0.027640  [ 2624/ 3000]\n",
      "loss: 0.098862  [ 2632/ 3000]\n",
      "loss: 0.113010  [ 2640/ 3000]\n",
      "loss: 0.072475  [ 2648/ 3000]\n",
      "loss: 0.075059  [ 2656/ 3000]\n",
      "loss: 0.051174  [ 2664/ 3000]\n",
      "loss: 0.092672  [ 2672/ 3000]\n",
      "loss: 0.106802  [ 2680/ 3000]\n",
      "loss: 0.046845  [ 2688/ 3000]\n",
      "loss: 0.036210  [ 2696/ 3000]\n",
      "loss: 0.076685  [ 2704/ 3000]\n",
      "loss: 0.067398  [ 2712/ 3000]\n",
      "loss: 0.048839  [ 2720/ 3000]\n",
      "loss: 0.093484  [ 2728/ 3000]\n",
      "loss: 0.027757  [ 2736/ 3000]\n",
      "loss: 0.061217  [ 2744/ 3000]\n",
      "loss: 0.075734  [ 2752/ 3000]\n",
      "loss: 0.055755  [ 2760/ 3000]\n",
      "loss: 0.018420  [ 2768/ 3000]\n",
      "loss: 0.098076  [ 2776/ 3000]\n",
      "loss: 0.065846  [ 2784/ 3000]\n",
      "loss: 0.037864  [ 2792/ 3000]\n",
      "loss: 0.095220  [ 2800/ 3000]\n",
      "loss: 0.137594  [ 2808/ 3000]\n",
      "loss: 0.055487  [ 2816/ 3000]\n",
      "loss: 0.071145  [ 2824/ 3000]\n",
      "loss: 0.073211  [ 2832/ 3000]\n",
      "loss: 0.051094  [ 2840/ 3000]\n",
      "loss: 0.047499  [ 2848/ 3000]\n",
      "loss: 0.072453  [ 2856/ 3000]\n",
      "loss: 0.030056  [ 2864/ 3000]\n",
      "loss: 0.083987  [ 2872/ 3000]\n",
      "loss: 0.093121  [ 2880/ 3000]\n",
      "loss: 0.013370  [ 2888/ 3000]\n",
      "loss: 0.013328  [ 2896/ 3000]\n",
      "loss: 0.057818  [ 2904/ 3000]\n",
      "loss: 0.085929  [ 2912/ 3000]\n",
      "loss: 0.052296  [ 2920/ 3000]\n",
      "loss: 0.099158  [ 2928/ 3000]\n",
      "loss: 0.147264  [ 2936/ 3000]\n",
      "loss: 0.027654  [ 2944/ 3000]\n",
      "loss: 0.004991  [ 2952/ 3000]\n",
      "loss: 0.027322  [ 2960/ 3000]\n",
      "loss: 0.052941  [ 2968/ 3000]\n",
      "loss: 0.048881  [ 2976/ 3000]\n",
      "loss: 0.059706  [ 2984/ 3000]\n",
      "loss: 0.010204  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085732 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.026499  [    0/ 3000]\n",
      "loss: 0.065438  [    8/ 3000]\n",
      "loss: 0.020077  [   16/ 3000]\n",
      "loss: 0.027265  [   24/ 3000]\n",
      "loss: 0.095303  [   32/ 3000]\n",
      "loss: 0.015690  [   40/ 3000]\n",
      "loss: 0.021094  [   48/ 3000]\n",
      "loss: 0.070648  [   56/ 3000]\n",
      "loss: 0.135555  [   64/ 3000]\n",
      "loss: 0.021182  [   72/ 3000]\n",
      "loss: 0.136828  [   80/ 3000]\n",
      "loss: 0.070080  [   88/ 3000]\n",
      "loss: 0.092466  [   96/ 3000]\n",
      "loss: 0.040627  [  104/ 3000]\n",
      "loss: 0.151242  [  112/ 3000]\n",
      "loss: 0.033263  [  120/ 3000]\n",
      "loss: 0.033230  [  128/ 3000]\n",
      "loss: 0.073865  [  136/ 3000]\n",
      "loss: 0.071512  [  144/ 3000]\n",
      "loss: 0.039478  [  152/ 3000]\n",
      "loss: 0.019180  [  160/ 3000]\n",
      "loss: 0.012669  [  168/ 3000]\n",
      "loss: 0.027341  [  176/ 3000]\n",
      "loss: 0.081606  [  184/ 3000]\n",
      "loss: 0.049058  [  192/ 3000]\n",
      "loss: 0.035729  [  200/ 3000]\n",
      "loss: 0.148720  [  208/ 3000]\n",
      "loss: 0.037761  [  216/ 3000]\n",
      "loss: 0.049245  [  224/ 3000]\n",
      "loss: 0.117332  [  232/ 3000]\n",
      "loss: 0.054973  [  240/ 3000]\n",
      "loss: 0.037718  [  248/ 3000]\n",
      "loss: 0.027169  [  256/ 3000]\n",
      "loss: 0.074805  [  264/ 3000]\n",
      "loss: 0.048197  [  272/ 3000]\n",
      "loss: 0.158195  [  280/ 3000]\n",
      "loss: 0.024356  [  288/ 3000]\n",
      "loss: 0.052450  [  296/ 3000]\n",
      "loss: 0.035612  [  304/ 3000]\n",
      "loss: 0.099431  [  312/ 3000]\n",
      "loss: 0.040746  [  320/ 3000]\n",
      "loss: 0.113539  [  328/ 3000]\n",
      "loss: 0.036798  [  336/ 3000]\n",
      "loss: 0.083074  [  344/ 3000]\n",
      "loss: 0.019859  [  352/ 3000]\n",
      "loss: 0.030943  [  360/ 3000]\n",
      "loss: 0.113629  [  368/ 3000]\n",
      "loss: 0.020289  [  376/ 3000]\n",
      "loss: 0.088913  [  384/ 3000]\n",
      "loss: 0.049959  [  392/ 3000]\n",
      "loss: 0.079419  [  400/ 3000]\n",
      "loss: 0.032333  [  408/ 3000]\n",
      "loss: 0.087805  [  416/ 3000]\n",
      "loss: 0.042882  [  424/ 3000]\n",
      "loss: 0.155072  [  432/ 3000]\n",
      "loss: 0.036342  [  440/ 3000]\n",
      "loss: 0.070440  [  448/ 3000]\n",
      "loss: 0.042097  [  456/ 3000]\n",
      "loss: 0.104824  [  464/ 3000]\n",
      "loss: 0.059117  [  472/ 3000]\n",
      "loss: 0.016349  [  480/ 3000]\n",
      "loss: 0.120408  [  488/ 3000]\n",
      "loss: 0.091223  [  496/ 3000]\n",
      "loss: 0.037732  [  504/ 3000]\n",
      "loss: 0.065542  [  512/ 3000]\n",
      "loss: 0.041740  [  520/ 3000]\n",
      "loss: 0.187329  [  528/ 3000]\n",
      "loss: 0.089243  [  536/ 3000]\n",
      "loss: 0.079678  [  544/ 3000]\n",
      "loss: 0.047229  [  552/ 3000]\n",
      "loss: 0.036550  [  560/ 3000]\n",
      "loss: 0.083993  [  568/ 3000]\n",
      "loss: 0.051025  [  576/ 3000]\n",
      "loss: 0.058715  [  584/ 3000]\n",
      "loss: 0.032039  [  592/ 3000]\n",
      "loss: 0.125691  [  600/ 3000]\n",
      "loss: 0.036062  [  608/ 3000]\n",
      "loss: 0.084904  [  616/ 3000]\n",
      "loss: 0.057483  [  624/ 3000]\n",
      "loss: 0.171279  [  632/ 3000]\n",
      "loss: 0.016231  [  640/ 3000]\n",
      "loss: 0.132821  [  648/ 3000]\n",
      "loss: 0.178631  [  656/ 3000]\n",
      "loss: 0.151157  [  664/ 3000]\n",
      "loss: 0.065158  [  672/ 3000]\n",
      "loss: 0.076838  [  680/ 3000]\n",
      "loss: 0.050997  [  688/ 3000]\n",
      "loss: 0.155680  [  696/ 3000]\n",
      "loss: 0.065235  [  704/ 3000]\n",
      "loss: 0.044326  [  712/ 3000]\n",
      "loss: 0.055309  [  720/ 3000]\n",
      "loss: 0.031407  [  728/ 3000]\n",
      "loss: 0.059127  [  736/ 3000]\n",
      "loss: 0.028218  [  744/ 3000]\n",
      "loss: 0.083012  [  752/ 3000]\n",
      "loss: 0.061449  [  760/ 3000]\n",
      "loss: 0.116932  [  768/ 3000]\n",
      "loss: 0.059895  [  776/ 3000]\n",
      "loss: 0.140111  [  784/ 3000]\n",
      "loss: 0.068605  [  792/ 3000]\n",
      "loss: 0.160734  [  800/ 3000]\n",
      "loss: 0.057600  [  808/ 3000]\n",
      "loss: 0.030711  [  816/ 3000]\n",
      "loss: 0.048843  [  824/ 3000]\n",
      "loss: 0.053574  [  832/ 3000]\n",
      "loss: 0.021998  [  840/ 3000]\n",
      "loss: 0.018786  [  848/ 3000]\n",
      "loss: 0.025616  [  856/ 3000]\n",
      "loss: 0.080441  [  864/ 3000]\n",
      "loss: 0.012225  [  872/ 3000]\n",
      "loss: 0.076154  [  880/ 3000]\n",
      "loss: 0.089071  [  888/ 3000]\n",
      "loss: 0.067121  [  896/ 3000]\n",
      "loss: 0.175212  [  904/ 3000]\n",
      "loss: 0.054869  [  912/ 3000]\n",
      "loss: 0.059298  [  920/ 3000]\n",
      "loss: 0.068186  [  928/ 3000]\n",
      "loss: 0.041836  [  936/ 3000]\n",
      "loss: 0.156246  [  944/ 3000]\n",
      "loss: 0.030366  [  952/ 3000]\n",
      "loss: 0.048269  [  960/ 3000]\n",
      "loss: 0.024647  [  968/ 3000]\n",
      "loss: 0.011936  [  976/ 3000]\n",
      "loss: 0.013834  [  984/ 3000]\n",
      "loss: 0.114915  [  992/ 3000]\n",
      "loss: 0.068282  [ 1000/ 3000]\n",
      "loss: 0.059476  [ 1008/ 3000]\n",
      "loss: 0.108883  [ 1016/ 3000]\n",
      "loss: 0.058350  [ 1024/ 3000]\n",
      "loss: 0.094729  [ 1032/ 3000]\n",
      "loss: 0.015923  [ 1040/ 3000]\n",
      "loss: 0.039788  [ 1048/ 3000]\n",
      "loss: 0.020734  [ 1056/ 3000]\n",
      "loss: 0.069732  [ 1064/ 3000]\n",
      "loss: 0.041370  [ 1072/ 3000]\n",
      "loss: 0.048373  [ 1080/ 3000]\n",
      "loss: 0.096814  [ 1088/ 3000]\n",
      "loss: 0.085722  [ 1096/ 3000]\n",
      "loss: 0.018583  [ 1104/ 3000]\n",
      "loss: 0.093487  [ 1112/ 3000]\n",
      "loss: 0.028938  [ 1120/ 3000]\n",
      "loss: 0.047148  [ 1128/ 3000]\n",
      "loss: 0.043093  [ 1136/ 3000]\n",
      "loss: 0.113991  [ 1144/ 3000]\n",
      "loss: 0.037001  [ 1152/ 3000]\n",
      "loss: 0.027706  [ 1160/ 3000]\n",
      "loss: 0.030944  [ 1168/ 3000]\n",
      "loss: 0.025623  [ 1176/ 3000]\n",
      "loss: 0.156838  [ 1184/ 3000]\n",
      "loss: 0.055127  [ 1192/ 3000]\n",
      "loss: 0.039037  [ 1200/ 3000]\n",
      "loss: 0.037418  [ 1208/ 3000]\n",
      "loss: 0.042222  [ 1216/ 3000]\n",
      "loss: 0.072665  [ 1224/ 3000]\n",
      "loss: 0.083112  [ 1232/ 3000]\n",
      "loss: 0.075462  [ 1240/ 3000]\n",
      "loss: 0.080667  [ 1248/ 3000]\n",
      "loss: 0.010822  [ 1256/ 3000]\n",
      "loss: 0.048109  [ 1264/ 3000]\n",
      "loss: 0.023906  [ 1272/ 3000]\n",
      "loss: 0.028914  [ 1280/ 3000]\n",
      "loss: 0.060772  [ 1288/ 3000]\n",
      "loss: 0.023060  [ 1296/ 3000]\n",
      "loss: 0.003729  [ 1304/ 3000]\n",
      "loss: 0.089005  [ 1312/ 3000]\n",
      "loss: 0.228384  [ 1320/ 3000]\n",
      "loss: 0.090222  [ 1328/ 3000]\n",
      "loss: 0.069380  [ 1336/ 3000]\n",
      "loss: 0.118399  [ 1344/ 3000]\n",
      "loss: 0.076865  [ 1352/ 3000]\n",
      "loss: 0.028971  [ 1360/ 3000]\n",
      "loss: 0.109249  [ 1368/ 3000]\n",
      "loss: 0.126881  [ 1376/ 3000]\n",
      "loss: 0.059518  [ 1384/ 3000]\n",
      "loss: 0.035262  [ 1392/ 3000]\n",
      "loss: 0.080686  [ 1400/ 3000]\n",
      "loss: 0.075996  [ 1408/ 3000]\n",
      "loss: 0.078659  [ 1416/ 3000]\n",
      "loss: 0.118057  [ 1424/ 3000]\n",
      "loss: 0.057204  [ 1432/ 3000]\n",
      "loss: 0.034480  [ 1440/ 3000]\n",
      "loss: 0.032348  [ 1448/ 3000]\n",
      "loss: 0.056314  [ 1456/ 3000]\n",
      "loss: 0.007730  [ 1464/ 3000]\n",
      "loss: 0.044417  [ 1472/ 3000]\n",
      "loss: 0.022218  [ 1480/ 3000]\n",
      "loss: 0.123415  [ 1488/ 3000]\n",
      "loss: 0.027420  [ 1496/ 3000]\n",
      "loss: 0.046409  [ 1504/ 3000]\n",
      "loss: 0.079799  [ 1512/ 3000]\n",
      "loss: 0.069507  [ 1520/ 3000]\n",
      "loss: 0.025252  [ 1528/ 3000]\n",
      "loss: 0.074041  [ 1536/ 3000]\n",
      "loss: 0.028914  [ 1544/ 3000]\n",
      "loss: 0.100852  [ 1552/ 3000]\n",
      "loss: 0.040041  [ 1560/ 3000]\n",
      "loss: 0.035408  [ 1568/ 3000]\n",
      "loss: 0.022184  [ 1576/ 3000]\n",
      "loss: 0.093206  [ 1584/ 3000]\n",
      "loss: 0.052058  [ 1592/ 3000]\n",
      "loss: 0.081438  [ 1600/ 3000]\n",
      "loss: 0.035262  [ 1608/ 3000]\n",
      "loss: 0.124464  [ 1616/ 3000]\n",
      "loss: 0.099437  [ 1624/ 3000]\n",
      "loss: 0.040519  [ 1632/ 3000]\n",
      "loss: 0.042372  [ 1640/ 3000]\n",
      "loss: 0.109372  [ 1648/ 3000]\n",
      "loss: 0.034646  [ 1656/ 3000]\n",
      "loss: 0.099345  [ 1664/ 3000]\n",
      "loss: 0.018507  [ 1672/ 3000]\n",
      "loss: 0.045066  [ 1680/ 3000]\n",
      "loss: 0.054225  [ 1688/ 3000]\n",
      "loss: 0.082749  [ 1696/ 3000]\n",
      "loss: 0.045086  [ 1704/ 3000]\n",
      "loss: 0.022179  [ 1712/ 3000]\n",
      "loss: 0.029734  [ 1720/ 3000]\n",
      "loss: 0.052227  [ 1728/ 3000]\n",
      "loss: 0.077560  [ 1736/ 3000]\n",
      "loss: 0.068967  [ 1744/ 3000]\n",
      "loss: 0.016881  [ 1752/ 3000]\n",
      "loss: 0.007928  [ 1760/ 3000]\n",
      "loss: 0.092139  [ 1768/ 3000]\n",
      "loss: 0.053607  [ 1776/ 3000]\n",
      "loss: 0.024600  [ 1784/ 3000]\n",
      "loss: 0.041821  [ 1792/ 3000]\n",
      "loss: 0.081618  [ 1800/ 3000]\n",
      "loss: 0.114669  [ 1808/ 3000]\n",
      "loss: 0.032072  [ 1816/ 3000]\n",
      "loss: 0.109351  [ 1824/ 3000]\n",
      "loss: 0.004721  [ 1832/ 3000]\n",
      "loss: 0.008893  [ 1840/ 3000]\n",
      "loss: 0.045357  [ 1848/ 3000]\n",
      "loss: 0.069014  [ 1856/ 3000]\n",
      "loss: 0.065928  [ 1864/ 3000]\n",
      "loss: 0.061504  [ 1872/ 3000]\n",
      "loss: 0.009723  [ 1880/ 3000]\n",
      "loss: 0.015603  [ 1888/ 3000]\n",
      "loss: 0.056225  [ 1896/ 3000]\n",
      "loss: 0.030514  [ 1904/ 3000]\n",
      "loss: 0.031869  [ 1912/ 3000]\n",
      "loss: 0.093097  [ 1920/ 3000]\n",
      "loss: 0.070090  [ 1928/ 3000]\n",
      "loss: 0.111788  [ 1936/ 3000]\n",
      "loss: 0.012745  [ 1944/ 3000]\n",
      "loss: 0.081968  [ 1952/ 3000]\n",
      "loss: 0.026954  [ 1960/ 3000]\n",
      "loss: 0.094778  [ 1968/ 3000]\n",
      "loss: 0.028106  [ 1976/ 3000]\n",
      "loss: 0.105799  [ 1984/ 3000]\n",
      "loss: 0.112394  [ 1992/ 3000]\n",
      "loss: 0.056021  [ 2000/ 3000]\n",
      "loss: 0.084575  [ 2008/ 3000]\n",
      "loss: 0.046464  [ 2016/ 3000]\n",
      "loss: 0.051876  [ 2024/ 3000]\n",
      "loss: 0.086396  [ 2032/ 3000]\n",
      "loss: 0.072708  [ 2040/ 3000]\n",
      "loss: 0.033058  [ 2048/ 3000]\n",
      "loss: 0.032542  [ 2056/ 3000]\n",
      "loss: 0.022502  [ 2064/ 3000]\n",
      "loss: 0.098559  [ 2072/ 3000]\n",
      "loss: 0.041301  [ 2080/ 3000]\n",
      "loss: 0.088380  [ 2088/ 3000]\n",
      "loss: 0.066301  [ 2096/ 3000]\n",
      "loss: 0.042964  [ 2104/ 3000]\n",
      "loss: 0.029057  [ 2112/ 3000]\n",
      "loss: 0.013586  [ 2120/ 3000]\n",
      "loss: 0.062465  [ 2128/ 3000]\n",
      "loss: 0.058593  [ 2136/ 3000]\n",
      "loss: 0.091560  [ 2144/ 3000]\n",
      "loss: 0.122850  [ 2152/ 3000]\n",
      "loss: 0.020574  [ 2160/ 3000]\n",
      "loss: 0.055531  [ 2168/ 3000]\n",
      "loss: 0.022842  [ 2176/ 3000]\n",
      "loss: 0.079386  [ 2184/ 3000]\n",
      "loss: 0.054628  [ 2192/ 3000]\n",
      "loss: 0.028934  [ 2200/ 3000]\n",
      "loss: 0.015598  [ 2208/ 3000]\n",
      "loss: 0.032777  [ 2216/ 3000]\n",
      "loss: 0.085903  [ 2224/ 3000]\n",
      "loss: 0.062518  [ 2232/ 3000]\n",
      "loss: 0.106162  [ 2240/ 3000]\n",
      "loss: 0.011215  [ 2248/ 3000]\n",
      "loss: 0.045597  [ 2256/ 3000]\n",
      "loss: 0.016723  [ 2264/ 3000]\n",
      "loss: 0.114649  [ 2272/ 3000]\n",
      "loss: 0.038305  [ 2280/ 3000]\n",
      "loss: 0.096457  [ 2288/ 3000]\n",
      "loss: 0.056854  [ 2296/ 3000]\n",
      "loss: 0.044706  [ 2304/ 3000]\n",
      "loss: 0.024034  [ 2312/ 3000]\n",
      "loss: 0.017839  [ 2320/ 3000]\n",
      "loss: 0.066162  [ 2328/ 3000]\n",
      "loss: 0.012860  [ 2336/ 3000]\n",
      "loss: 0.099336  [ 2344/ 3000]\n",
      "loss: 0.091464  [ 2352/ 3000]\n",
      "loss: 0.089942  [ 2360/ 3000]\n",
      "loss: 0.038266  [ 2368/ 3000]\n",
      "loss: 0.023855  [ 2376/ 3000]\n",
      "loss: 0.048145  [ 2384/ 3000]\n",
      "loss: 0.045730  [ 2392/ 3000]\n",
      "loss: 0.007896  [ 2400/ 3000]\n",
      "loss: 0.109652  [ 2408/ 3000]\n",
      "loss: 0.072419  [ 2416/ 3000]\n",
      "loss: 0.066522  [ 2424/ 3000]\n",
      "loss: 0.082039  [ 2432/ 3000]\n",
      "loss: 0.045818  [ 2440/ 3000]\n",
      "loss: 0.091652  [ 2448/ 3000]\n",
      "loss: 0.101588  [ 2456/ 3000]\n",
      "loss: 0.041520  [ 2464/ 3000]\n",
      "loss: 0.211759  [ 2472/ 3000]\n",
      "loss: 0.025635  [ 2480/ 3000]\n",
      "loss: 0.047018  [ 2488/ 3000]\n",
      "loss: 0.012666  [ 2496/ 3000]\n",
      "loss: 0.029769  [ 2504/ 3000]\n",
      "loss: 0.102266  [ 2512/ 3000]\n",
      "loss: 0.193807  [ 2520/ 3000]\n",
      "loss: 0.026825  [ 2528/ 3000]\n",
      "loss: 0.055584  [ 2536/ 3000]\n",
      "loss: 0.015899  [ 2544/ 3000]\n",
      "loss: 0.078601  [ 2552/ 3000]\n",
      "loss: 0.077793  [ 2560/ 3000]\n",
      "loss: 0.123772  [ 2568/ 3000]\n",
      "loss: 0.093161  [ 2576/ 3000]\n",
      "loss: 0.053421  [ 2584/ 3000]\n",
      "loss: 0.042742  [ 2592/ 3000]\n",
      "loss: 0.066421  [ 2600/ 3000]\n",
      "loss: 0.075198  [ 2608/ 3000]\n",
      "loss: 0.026381  [ 2616/ 3000]\n",
      "loss: 0.026475  [ 2624/ 3000]\n",
      "loss: 0.096303  [ 2632/ 3000]\n",
      "loss: 0.110650  [ 2640/ 3000]\n",
      "loss: 0.070774  [ 2648/ 3000]\n",
      "loss: 0.073069  [ 2656/ 3000]\n",
      "loss: 0.049820  [ 2664/ 3000]\n",
      "loss: 0.089677  [ 2672/ 3000]\n",
      "loss: 0.103863  [ 2680/ 3000]\n",
      "loss: 0.045528  [ 2688/ 3000]\n",
      "loss: 0.035199  [ 2696/ 3000]\n",
      "loss: 0.075166  [ 2704/ 3000]\n",
      "loss: 0.064737  [ 2712/ 3000]\n",
      "loss: 0.046888  [ 2720/ 3000]\n",
      "loss: 0.090093  [ 2728/ 3000]\n",
      "loss: 0.027043  [ 2736/ 3000]\n",
      "loss: 0.059611  [ 2744/ 3000]\n",
      "loss: 0.073580  [ 2752/ 3000]\n",
      "loss: 0.054283  [ 2760/ 3000]\n",
      "loss: 0.017762  [ 2768/ 3000]\n",
      "loss: 0.094614  [ 2776/ 3000]\n",
      "loss: 0.063998  [ 2784/ 3000]\n",
      "loss: 0.036627  [ 2792/ 3000]\n",
      "loss: 0.092865  [ 2800/ 3000]\n",
      "loss: 0.134202  [ 2808/ 3000]\n",
      "loss: 0.053421  [ 2816/ 3000]\n",
      "loss: 0.069029  [ 2824/ 3000]\n",
      "loss: 0.071349  [ 2832/ 3000]\n",
      "loss: 0.049565  [ 2840/ 3000]\n",
      "loss: 0.045574  [ 2848/ 3000]\n",
      "loss: 0.070371  [ 2856/ 3000]\n",
      "loss: 0.029016  [ 2864/ 3000]\n",
      "loss: 0.082355  [ 2872/ 3000]\n",
      "loss: 0.090154  [ 2880/ 3000]\n",
      "loss: 0.012695  [ 2888/ 3000]\n",
      "loss: 0.012975  [ 2896/ 3000]\n",
      "loss: 0.055962  [ 2904/ 3000]\n",
      "loss: 0.083730  [ 2912/ 3000]\n",
      "loss: 0.049982  [ 2920/ 3000]\n",
      "loss: 0.096332  [ 2928/ 3000]\n",
      "loss: 0.142305  [ 2936/ 3000]\n",
      "loss: 0.026898  [ 2944/ 3000]\n",
      "loss: 0.004824  [ 2952/ 3000]\n",
      "loss: 0.026388  [ 2960/ 3000]\n",
      "loss: 0.051203  [ 2968/ 3000]\n",
      "loss: 0.047795  [ 2976/ 3000]\n",
      "loss: 0.058213  [ 2984/ 3000]\n",
      "loss: 0.009744  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085564 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.025875  [    0/ 3000]\n",
      "loss: 0.063887  [    8/ 3000]\n",
      "loss: 0.019220  [   16/ 3000]\n",
      "loss: 0.026144  [   24/ 3000]\n",
      "loss: 0.092304  [   32/ 3000]\n",
      "loss: 0.015006  [   40/ 3000]\n",
      "loss: 0.020391  [   48/ 3000]\n",
      "loss: 0.069127  [   56/ 3000]\n",
      "loss: 0.131349  [   64/ 3000]\n",
      "loss: 0.020695  [   72/ 3000]\n",
      "loss: 0.133692  [   80/ 3000]\n",
      "loss: 0.067725  [   88/ 3000]\n",
      "loss: 0.090336  [   96/ 3000]\n",
      "loss: 0.038270  [  104/ 3000]\n",
      "loss: 0.148044  [  112/ 3000]\n",
      "loss: 0.032239  [  120/ 3000]\n",
      "loss: 0.032891  [  128/ 3000]\n",
      "loss: 0.071255  [  136/ 3000]\n",
      "loss: 0.069300  [  144/ 3000]\n",
      "loss: 0.038146  [  152/ 3000]\n",
      "loss: 0.018603  [  160/ 3000]\n",
      "loss: 0.012263  [  168/ 3000]\n",
      "loss: 0.026130  [  176/ 3000]\n",
      "loss: 0.079216  [  184/ 3000]\n",
      "loss: 0.047008  [  192/ 3000]\n",
      "loss: 0.034697  [  200/ 3000]\n",
      "loss: 0.145390  [  208/ 3000]\n",
      "loss: 0.036342  [  216/ 3000]\n",
      "loss: 0.047691  [  224/ 3000]\n",
      "loss: 0.114798  [  232/ 3000]\n",
      "loss: 0.053719  [  240/ 3000]\n",
      "loss: 0.036161  [  248/ 3000]\n",
      "loss: 0.026322  [  256/ 3000]\n",
      "loss: 0.071939  [  264/ 3000]\n",
      "loss: 0.047439  [  272/ 3000]\n",
      "loss: 0.155310  [  280/ 3000]\n",
      "loss: 0.023562  [  288/ 3000]\n",
      "loss: 0.051381  [  296/ 3000]\n",
      "loss: 0.034603  [  304/ 3000]\n",
      "loss: 0.096453  [  312/ 3000]\n",
      "loss: 0.039167  [  320/ 3000]\n",
      "loss: 0.109151  [  328/ 3000]\n",
      "loss: 0.035406  [  336/ 3000]\n",
      "loss: 0.081184  [  344/ 3000]\n",
      "loss: 0.019196  [  352/ 3000]\n",
      "loss: 0.029933  [  360/ 3000]\n",
      "loss: 0.110760  [  368/ 3000]\n",
      "loss: 0.019288  [  376/ 3000]\n",
      "loss: 0.087469  [  384/ 3000]\n",
      "loss: 0.048159  [  392/ 3000]\n",
      "loss: 0.077268  [  400/ 3000]\n",
      "loss: 0.031617  [  408/ 3000]\n",
      "loss: 0.085351  [  416/ 3000]\n",
      "loss: 0.041414  [  424/ 3000]\n",
      "loss: 0.151468  [  432/ 3000]\n",
      "loss: 0.035008  [  440/ 3000]\n",
      "loss: 0.068647  [  448/ 3000]\n",
      "loss: 0.040782  [  456/ 3000]\n",
      "loss: 0.101268  [  464/ 3000]\n",
      "loss: 0.058101  [  472/ 3000]\n",
      "loss: 0.015862  [  480/ 3000]\n",
      "loss: 0.117142  [  488/ 3000]\n",
      "loss: 0.089539  [  496/ 3000]\n",
      "loss: 0.036533  [  504/ 3000]\n",
      "loss: 0.064059  [  512/ 3000]\n",
      "loss: 0.040790  [  520/ 3000]\n",
      "loss: 0.182567  [  528/ 3000]\n",
      "loss: 0.086844  [  536/ 3000]\n",
      "loss: 0.077224  [  544/ 3000]\n",
      "loss: 0.045646  [  552/ 3000]\n",
      "loss: 0.035339  [  560/ 3000]\n",
      "loss: 0.081766  [  568/ 3000]\n",
      "loss: 0.049493  [  576/ 3000]\n",
      "loss: 0.056680  [  584/ 3000]\n",
      "loss: 0.030876  [  592/ 3000]\n",
      "loss: 0.122374  [  600/ 3000]\n",
      "loss: 0.034837  [  608/ 3000]\n",
      "loss: 0.082366  [  616/ 3000]\n",
      "loss: 0.055779  [  624/ 3000]\n",
      "loss: 0.166980  [  632/ 3000]\n",
      "loss: 0.015749  [  640/ 3000]\n",
      "loss: 0.129431  [  648/ 3000]\n",
      "loss: 0.174159  [  656/ 3000]\n",
      "loss: 0.147798  [  664/ 3000]\n",
      "loss: 0.063295  [  672/ 3000]\n",
      "loss: 0.075013  [  680/ 3000]\n",
      "loss: 0.049599  [  688/ 3000]\n",
      "loss: 0.151911  [  696/ 3000]\n",
      "loss: 0.064064  [  704/ 3000]\n",
      "loss: 0.043113  [  712/ 3000]\n",
      "loss: 0.054002  [  720/ 3000]\n",
      "loss: 0.030399  [  728/ 3000]\n",
      "loss: 0.057591  [  736/ 3000]\n",
      "loss: 0.026824  [  744/ 3000]\n",
      "loss: 0.080505  [  752/ 3000]\n",
      "loss: 0.059672  [  760/ 3000]\n",
      "loss: 0.114767  [  768/ 3000]\n",
      "loss: 0.058576  [  776/ 3000]\n",
      "loss: 0.136585  [  784/ 3000]\n",
      "loss: 0.065817  [  792/ 3000]\n",
      "loss: 0.158345  [  800/ 3000]\n",
      "loss: 0.056369  [  808/ 3000]\n",
      "loss: 0.029773  [  816/ 3000]\n",
      "loss: 0.047641  [  824/ 3000]\n",
      "loss: 0.052050  [  832/ 3000]\n",
      "loss: 0.021162  [  840/ 3000]\n",
      "loss: 0.018294  [  848/ 3000]\n",
      "loss: 0.024670  [  856/ 3000]\n",
      "loss: 0.078377  [  864/ 3000]\n",
      "loss: 0.011657  [  872/ 3000]\n",
      "loss: 0.074418  [  880/ 3000]\n",
      "loss: 0.086451  [  888/ 3000]\n",
      "loss: 0.066310  [  896/ 3000]\n",
      "loss: 0.170755  [  904/ 3000]\n",
      "loss: 0.054064  [  912/ 3000]\n",
      "loss: 0.057875  [  920/ 3000]\n",
      "loss: 0.066475  [  928/ 3000]\n",
      "loss: 0.040135  [  936/ 3000]\n",
      "loss: 0.151972  [  944/ 3000]\n",
      "loss: 0.029094  [  952/ 3000]\n",
      "loss: 0.047220  [  960/ 3000]\n",
      "loss: 0.023725  [  968/ 3000]\n",
      "loss: 0.011475  [  976/ 3000]\n",
      "loss: 0.013222  [  984/ 3000]\n",
      "loss: 0.111934  [  992/ 3000]\n",
      "loss: 0.066149  [ 1000/ 3000]\n",
      "loss: 0.057905  [ 1008/ 3000]\n",
      "loss: 0.105792  [ 1016/ 3000]\n",
      "loss: 0.056653  [ 1024/ 3000]\n",
      "loss: 0.092291  [ 1032/ 3000]\n",
      "loss: 0.015386  [ 1040/ 3000]\n",
      "loss: 0.038486  [ 1048/ 3000]\n",
      "loss: 0.019907  [ 1056/ 3000]\n",
      "loss: 0.067424  [ 1064/ 3000]\n",
      "loss: 0.039976  [ 1072/ 3000]\n",
      "loss: 0.046815  [ 1080/ 3000]\n",
      "loss: 0.094054  [ 1088/ 3000]\n",
      "loss: 0.082946  [ 1096/ 3000]\n",
      "loss: 0.017841  [ 1104/ 3000]\n",
      "loss: 0.090385  [ 1112/ 3000]\n",
      "loss: 0.027894  [ 1120/ 3000]\n",
      "loss: 0.046275  [ 1128/ 3000]\n",
      "loss: 0.041612  [ 1136/ 3000]\n",
      "loss: 0.109737  [ 1144/ 3000]\n",
      "loss: 0.035936  [ 1152/ 3000]\n",
      "loss: 0.026808  [ 1160/ 3000]\n",
      "loss: 0.029903  [ 1168/ 3000]\n",
      "loss: 0.024648  [ 1176/ 3000]\n",
      "loss: 0.152479  [ 1184/ 3000]\n",
      "loss: 0.053706  [ 1192/ 3000]\n",
      "loss: 0.037277  [ 1200/ 3000]\n",
      "loss: 0.036649  [ 1208/ 3000]\n",
      "loss: 0.040438  [ 1216/ 3000]\n",
      "loss: 0.070461  [ 1224/ 3000]\n",
      "loss: 0.080602  [ 1232/ 3000]\n",
      "loss: 0.073168  [ 1240/ 3000]\n",
      "loss: 0.077704  [ 1248/ 3000]\n",
      "loss: 0.010229  [ 1256/ 3000]\n",
      "loss: 0.047255  [ 1264/ 3000]\n",
      "loss: 0.023115  [ 1272/ 3000]\n",
      "loss: 0.027642  [ 1280/ 3000]\n",
      "loss: 0.058409  [ 1288/ 3000]\n",
      "loss: 0.021897  [ 1296/ 3000]\n",
      "loss: 0.003535  [ 1304/ 3000]\n",
      "loss: 0.086156  [ 1312/ 3000]\n",
      "loss: 0.221549  [ 1320/ 3000]\n",
      "loss: 0.087644  [ 1328/ 3000]\n",
      "loss: 0.068140  [ 1336/ 3000]\n",
      "loss: 0.115018  [ 1344/ 3000]\n",
      "loss: 0.075178  [ 1352/ 3000]\n",
      "loss: 0.027561  [ 1360/ 3000]\n",
      "loss: 0.106924  [ 1368/ 3000]\n",
      "loss: 0.124432  [ 1376/ 3000]\n",
      "loss: 0.057135  [ 1384/ 3000]\n",
      "loss: 0.033696  [ 1392/ 3000]\n",
      "loss: 0.078480  [ 1400/ 3000]\n",
      "loss: 0.074062  [ 1408/ 3000]\n",
      "loss: 0.076451  [ 1416/ 3000]\n",
      "loss: 0.115834  [ 1424/ 3000]\n",
      "loss: 0.055190  [ 1432/ 3000]\n",
      "loss: 0.033335  [ 1440/ 3000]\n",
      "loss: 0.031087  [ 1448/ 3000]\n",
      "loss: 0.054556  [ 1456/ 3000]\n",
      "loss: 0.007475  [ 1464/ 3000]\n",
      "loss: 0.043473  [ 1472/ 3000]\n",
      "loss: 0.021861  [ 1480/ 3000]\n",
      "loss: 0.120290  [ 1488/ 3000]\n",
      "loss: 0.026483  [ 1496/ 3000]\n",
      "loss: 0.044825  [ 1504/ 3000]\n",
      "loss: 0.077614  [ 1512/ 3000]\n",
      "loss: 0.067450  [ 1520/ 3000]\n",
      "loss: 0.024236  [ 1528/ 3000]\n",
      "loss: 0.072126  [ 1536/ 3000]\n",
      "loss: 0.027348  [ 1544/ 3000]\n",
      "loss: 0.098026  [ 1552/ 3000]\n",
      "loss: 0.038765  [ 1560/ 3000]\n",
      "loss: 0.034207  [ 1568/ 3000]\n",
      "loss: 0.021315  [ 1576/ 3000]\n",
      "loss: 0.091145  [ 1584/ 3000]\n",
      "loss: 0.050962  [ 1592/ 3000]\n",
      "loss: 0.079065  [ 1600/ 3000]\n",
      "loss: 0.034182  [ 1608/ 3000]\n",
      "loss: 0.121790  [ 1616/ 3000]\n",
      "loss: 0.097032  [ 1624/ 3000]\n",
      "loss: 0.039091  [ 1632/ 3000]\n",
      "loss: 0.040849  [ 1640/ 3000]\n",
      "loss: 0.106481  [ 1648/ 3000]\n",
      "loss: 0.033651  [ 1656/ 3000]\n",
      "loss: 0.095095  [ 1664/ 3000]\n",
      "loss: 0.017567  [ 1672/ 3000]\n",
      "loss: 0.044119  [ 1680/ 3000]\n",
      "loss: 0.052528  [ 1688/ 3000]\n",
      "loss: 0.080818  [ 1696/ 3000]\n",
      "loss: 0.043344  [ 1704/ 3000]\n",
      "loss: 0.021455  [ 1712/ 3000]\n",
      "loss: 0.028365  [ 1720/ 3000]\n",
      "loss: 0.050826  [ 1728/ 3000]\n",
      "loss: 0.075448  [ 1736/ 3000]\n",
      "loss: 0.067190  [ 1744/ 3000]\n",
      "loss: 0.016471  [ 1752/ 3000]\n",
      "loss: 0.007606  [ 1760/ 3000]\n",
      "loss: 0.088775  [ 1768/ 3000]\n",
      "loss: 0.051395  [ 1776/ 3000]\n",
      "loss: 0.023815  [ 1784/ 3000]\n",
      "loss: 0.040342  [ 1792/ 3000]\n",
      "loss: 0.079184  [ 1800/ 3000]\n",
      "loss: 0.111529  [ 1808/ 3000]\n",
      "loss: 0.031114  [ 1816/ 3000]\n",
      "loss: 0.106014  [ 1824/ 3000]\n",
      "loss: 0.004436  [ 1832/ 3000]\n",
      "loss: 0.008607  [ 1840/ 3000]\n",
      "loss: 0.043717  [ 1848/ 3000]\n",
      "loss: 0.067098  [ 1856/ 3000]\n",
      "loss: 0.063703  [ 1864/ 3000]\n",
      "loss: 0.059932  [ 1872/ 3000]\n",
      "loss: 0.009104  [ 1880/ 3000]\n",
      "loss: 0.014779  [ 1888/ 3000]\n",
      "loss: 0.054151  [ 1896/ 3000]\n",
      "loss: 0.030021  [ 1904/ 3000]\n",
      "loss: 0.030635  [ 1912/ 3000]\n",
      "loss: 0.091206  [ 1920/ 3000]\n",
      "loss: 0.067925  [ 1928/ 3000]\n",
      "loss: 0.108647  [ 1936/ 3000]\n",
      "loss: 0.012196  [ 1944/ 3000]\n",
      "loss: 0.080076  [ 1952/ 3000]\n",
      "loss: 0.025950  [ 1960/ 3000]\n",
      "loss: 0.092540  [ 1968/ 3000]\n",
      "loss: 0.027236  [ 1976/ 3000]\n",
      "loss: 0.103191  [ 1984/ 3000]\n",
      "loss: 0.109671  [ 1992/ 3000]\n",
      "loss: 0.054043  [ 2000/ 3000]\n",
      "loss: 0.082014  [ 2008/ 3000]\n",
      "loss: 0.044537  [ 2016/ 3000]\n",
      "loss: 0.050609  [ 2024/ 3000]\n",
      "loss: 0.084369  [ 2032/ 3000]\n",
      "loss: 0.070981  [ 2040/ 3000]\n",
      "loss: 0.032156  [ 2048/ 3000]\n",
      "loss: 0.031347  [ 2056/ 3000]\n",
      "loss: 0.021459  [ 2064/ 3000]\n",
      "loss: 0.096146  [ 2072/ 3000]\n",
      "loss: 0.039862  [ 2080/ 3000]\n",
      "loss: 0.085433  [ 2088/ 3000]\n",
      "loss: 0.064634  [ 2096/ 3000]\n",
      "loss: 0.041890  [ 2104/ 3000]\n",
      "loss: 0.028556  [ 2112/ 3000]\n",
      "loss: 0.013053  [ 2120/ 3000]\n",
      "loss: 0.061344  [ 2128/ 3000]\n",
      "loss: 0.057083  [ 2136/ 3000]\n",
      "loss: 0.089085  [ 2144/ 3000]\n",
      "loss: 0.120574  [ 2152/ 3000]\n",
      "loss: 0.019779  [ 2160/ 3000]\n",
      "loss: 0.053951  [ 2168/ 3000]\n",
      "loss: 0.022198  [ 2176/ 3000]\n",
      "loss: 0.077161  [ 2184/ 3000]\n",
      "loss: 0.051861  [ 2192/ 3000]\n",
      "loss: 0.028029  [ 2200/ 3000]\n",
      "loss: 0.014761  [ 2208/ 3000]\n",
      "loss: 0.031840  [ 2216/ 3000]\n",
      "loss: 0.083183  [ 2224/ 3000]\n",
      "loss: 0.060552  [ 2232/ 3000]\n",
      "loss: 0.103729  [ 2240/ 3000]\n",
      "loss: 0.010801  [ 2248/ 3000]\n",
      "loss: 0.043745  [ 2256/ 3000]\n",
      "loss: 0.015930  [ 2264/ 3000]\n",
      "loss: 0.111665  [ 2272/ 3000]\n",
      "loss: 0.037339  [ 2280/ 3000]\n",
      "loss: 0.093058  [ 2288/ 3000]\n",
      "loss: 0.055107  [ 2296/ 3000]\n",
      "loss: 0.043310  [ 2304/ 3000]\n",
      "loss: 0.023159  [ 2312/ 3000]\n",
      "loss: 0.017010  [ 2320/ 3000]\n",
      "loss: 0.064141  [ 2328/ 3000]\n",
      "loss: 0.012413  [ 2336/ 3000]\n",
      "loss: 0.096947  [ 2344/ 3000]\n",
      "loss: 0.088357  [ 2352/ 3000]\n",
      "loss: 0.087572  [ 2360/ 3000]\n",
      "loss: 0.037292  [ 2368/ 3000]\n",
      "loss: 0.023090  [ 2376/ 3000]\n",
      "loss: 0.046981  [ 2384/ 3000]\n",
      "loss: 0.043985  [ 2392/ 3000]\n",
      "loss: 0.007575  [ 2400/ 3000]\n",
      "loss: 0.107412  [ 2408/ 3000]\n",
      "loss: 0.070787  [ 2416/ 3000]\n",
      "loss: 0.064084  [ 2424/ 3000]\n",
      "loss: 0.080038  [ 2432/ 3000]\n",
      "loss: 0.044606  [ 2440/ 3000]\n",
      "loss: 0.088346  [ 2448/ 3000]\n",
      "loss: 0.099099  [ 2456/ 3000]\n",
      "loss: 0.040175  [ 2464/ 3000]\n",
      "loss: 0.207386  [ 2472/ 3000]\n",
      "loss: 0.025254  [ 2480/ 3000]\n",
      "loss: 0.045600  [ 2488/ 3000]\n",
      "loss: 0.012099  [ 2496/ 3000]\n",
      "loss: 0.028690  [ 2504/ 3000]\n",
      "loss: 0.099653  [ 2512/ 3000]\n",
      "loss: 0.189821  [ 2520/ 3000]\n",
      "loss: 0.025681  [ 2528/ 3000]\n",
      "loss: 0.054265  [ 2536/ 3000]\n",
      "loss: 0.015343  [ 2544/ 3000]\n",
      "loss: 0.076086  [ 2552/ 3000]\n",
      "loss: 0.075693  [ 2560/ 3000]\n",
      "loss: 0.121835  [ 2568/ 3000]\n",
      "loss: 0.089531  [ 2576/ 3000]\n",
      "loss: 0.051707  [ 2584/ 3000]\n",
      "loss: 0.041534  [ 2592/ 3000]\n",
      "loss: 0.065386  [ 2600/ 3000]\n",
      "loss: 0.073352  [ 2608/ 3000]\n",
      "loss: 0.025586  [ 2616/ 3000]\n",
      "loss: 0.025411  [ 2624/ 3000]\n",
      "loss: 0.093825  [ 2632/ 3000]\n",
      "loss: 0.108351  [ 2640/ 3000]\n",
      "loss: 0.069039  [ 2648/ 3000]\n",
      "loss: 0.071104  [ 2656/ 3000]\n",
      "loss: 0.048473  [ 2664/ 3000]\n",
      "loss: 0.086749  [ 2672/ 3000]\n",
      "loss: 0.100877  [ 2680/ 3000]\n",
      "loss: 0.044259  [ 2688/ 3000]\n",
      "loss: 0.034131  [ 2696/ 3000]\n",
      "loss: 0.073590  [ 2704/ 3000]\n",
      "loss: 0.062072  [ 2712/ 3000]\n",
      "loss: 0.045031  [ 2720/ 3000]\n",
      "loss: 0.086763  [ 2728/ 3000]\n",
      "loss: 0.026389  [ 2736/ 3000]\n",
      "loss: 0.058066  [ 2744/ 3000]\n",
      "loss: 0.071406  [ 2752/ 3000]\n",
      "loss: 0.052850  [ 2760/ 3000]\n",
      "loss: 0.017162  [ 2768/ 3000]\n",
      "loss: 0.091239  [ 2776/ 3000]\n",
      "loss: 0.062144  [ 2784/ 3000]\n",
      "loss: 0.035414  [ 2792/ 3000]\n",
      "loss: 0.090520  [ 2800/ 3000]\n",
      "loss: 0.130753  [ 2808/ 3000]\n",
      "loss: 0.051505  [ 2816/ 3000]\n",
      "loss: 0.066951  [ 2824/ 3000]\n",
      "loss: 0.069421  [ 2832/ 3000]\n",
      "loss: 0.048109  [ 2840/ 3000]\n",
      "loss: 0.043737  [ 2848/ 3000]\n",
      "loss: 0.068395  [ 2856/ 3000]\n",
      "loss: 0.028021  [ 2864/ 3000]\n",
      "loss: 0.080822  [ 2872/ 3000]\n",
      "loss: 0.087236  [ 2880/ 3000]\n",
      "loss: 0.012092  [ 2888/ 3000]\n",
      "loss: 0.012609  [ 2896/ 3000]\n",
      "loss: 0.054188  [ 2904/ 3000]\n",
      "loss: 0.081477  [ 2912/ 3000]\n",
      "loss: 0.047741  [ 2920/ 3000]\n",
      "loss: 0.093752  [ 2928/ 3000]\n",
      "loss: 0.137407  [ 2936/ 3000]\n",
      "loss: 0.026204  [ 2944/ 3000]\n",
      "loss: 0.004671  [ 2952/ 3000]\n",
      "loss: 0.025460  [ 2960/ 3000]\n",
      "loss: 0.049354  [ 2968/ 3000]\n",
      "loss: 0.046594  [ 2976/ 3000]\n",
      "loss: 0.056606  [ 2984/ 3000]\n",
      "loss: 0.009317  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085441 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.025282  [    0/ 3000]\n",
      "loss: 0.062329  [    8/ 3000]\n",
      "loss: 0.018449  [   16/ 3000]\n",
      "loss: 0.025076  [   24/ 3000]\n",
      "loss: 0.089401  [   32/ 3000]\n",
      "loss: 0.014319  [   40/ 3000]\n",
      "loss: 0.019690  [   48/ 3000]\n",
      "loss: 0.067536  [   56/ 3000]\n",
      "loss: 0.127275  [   64/ 3000]\n",
      "loss: 0.020215  [   72/ 3000]\n",
      "loss: 0.130456  [   80/ 3000]\n",
      "loss: 0.065369  [   88/ 3000]\n",
      "loss: 0.088347  [   96/ 3000]\n",
      "loss: 0.036171  [  104/ 3000]\n",
      "loss: 0.144701  [  112/ 3000]\n",
      "loss: 0.031240  [  120/ 3000]\n",
      "loss: 0.032674  [  128/ 3000]\n",
      "loss: 0.068816  [  136/ 3000]\n",
      "loss: 0.067173  [  144/ 3000]\n",
      "loss: 0.036767  [  152/ 3000]\n",
      "loss: 0.018032  [  160/ 3000]\n",
      "loss: 0.011867  [  168/ 3000]\n",
      "loss: 0.024948  [  176/ 3000]\n",
      "loss: 0.076866  [  184/ 3000]\n",
      "loss: 0.045007  [  192/ 3000]\n",
      "loss: 0.033682  [  200/ 3000]\n",
      "loss: 0.141941  [  208/ 3000]\n",
      "loss: 0.034842  [  216/ 3000]\n",
      "loss: 0.046045  [  224/ 3000]\n",
      "loss: 0.112258  [  232/ 3000]\n",
      "loss: 0.052549  [  240/ 3000]\n",
      "loss: 0.034592  [  248/ 3000]\n",
      "loss: 0.025543  [  256/ 3000]\n",
      "loss: 0.069053  [  264/ 3000]\n",
      "loss: 0.046698  [  272/ 3000]\n",
      "loss: 0.152254  [  280/ 3000]\n",
      "loss: 0.022753  [  288/ 3000]\n",
      "loss: 0.050293  [  296/ 3000]\n",
      "loss: 0.033573  [  304/ 3000]\n",
      "loss: 0.093451  [  312/ 3000]\n",
      "loss: 0.037690  [  320/ 3000]\n",
      "loss: 0.104840  [  328/ 3000]\n",
      "loss: 0.034084  [  336/ 3000]\n",
      "loss: 0.079293  [  344/ 3000]\n",
      "loss: 0.018547  [  352/ 3000]\n",
      "loss: 0.028916  [  360/ 3000]\n",
      "loss: 0.107880  [  368/ 3000]\n",
      "loss: 0.018302  [  376/ 3000]\n",
      "loss: 0.086107  [  384/ 3000]\n",
      "loss: 0.046346  [  392/ 3000]\n",
      "loss: 0.075069  [  400/ 3000]\n",
      "loss: 0.030954  [  408/ 3000]\n",
      "loss: 0.083005  [  416/ 3000]\n",
      "loss: 0.039988  [  424/ 3000]\n",
      "loss: 0.147907  [  432/ 3000]\n",
      "loss: 0.033690  [  440/ 3000]\n",
      "loss: 0.066904  [  448/ 3000]\n",
      "loss: 0.039605  [  456/ 3000]\n",
      "loss: 0.097638  [  464/ 3000]\n",
      "loss: 0.057034  [  472/ 3000]\n",
      "loss: 0.015387  [  480/ 3000]\n",
      "loss: 0.113966  [  488/ 3000]\n",
      "loss: 0.087753  [  496/ 3000]\n",
      "loss: 0.035407  [  504/ 3000]\n",
      "loss: 0.062555  [  512/ 3000]\n",
      "loss: 0.039855  [  520/ 3000]\n",
      "loss: 0.177837  [  528/ 3000]\n",
      "loss: 0.084491  [  536/ 3000]\n",
      "loss: 0.074884  [  544/ 3000]\n",
      "loss: 0.044071  [  552/ 3000]\n",
      "loss: 0.034173  [  560/ 3000]\n",
      "loss: 0.079479  [  568/ 3000]\n",
      "loss: 0.048004  [  576/ 3000]\n",
      "loss: 0.054705  [  584/ 3000]\n",
      "loss: 0.029761  [  592/ 3000]\n",
      "loss: 0.119138  [  600/ 3000]\n",
      "loss: 0.033672  [  608/ 3000]\n",
      "loss: 0.079917  [  616/ 3000]\n",
      "loss: 0.054047  [  624/ 3000]\n",
      "loss: 0.162590  [  632/ 3000]\n",
      "loss: 0.015333  [  640/ 3000]\n",
      "loss: 0.125976  [  648/ 3000]\n",
      "loss: 0.169796  [  656/ 3000]\n",
      "loss: 0.144538  [  664/ 3000]\n",
      "loss: 0.061420  [  672/ 3000]\n",
      "loss: 0.073208  [  680/ 3000]\n",
      "loss: 0.048248  [  688/ 3000]\n",
      "loss: 0.148157  [  696/ 3000]\n",
      "loss: 0.062850  [  704/ 3000]\n",
      "loss: 0.041923  [  712/ 3000]\n",
      "loss: 0.052659  [  720/ 3000]\n",
      "loss: 0.029454  [  728/ 3000]\n",
      "loss: 0.056053  [  736/ 3000]\n",
      "loss: 0.025479  [  744/ 3000]\n",
      "loss: 0.078140  [  752/ 3000]\n",
      "loss: 0.057945  [  760/ 3000]\n",
      "loss: 0.112543  [  768/ 3000]\n",
      "loss: 0.057263  [  776/ 3000]\n",
      "loss: 0.133212  [  784/ 3000]\n",
      "loss: 0.063109  [  792/ 3000]\n",
      "loss: 0.155820  [  800/ 3000]\n",
      "loss: 0.055085  [  808/ 3000]\n",
      "loss: 0.028891  [  816/ 3000]\n",
      "loss: 0.046429  [  824/ 3000]\n",
      "loss: 0.050531  [  832/ 3000]\n",
      "loss: 0.020351  [  840/ 3000]\n",
      "loss: 0.017799  [  848/ 3000]\n",
      "loss: 0.023770  [  856/ 3000]\n",
      "loss: 0.076361  [  864/ 3000]\n",
      "loss: 0.011096  [  872/ 3000]\n",
      "loss: 0.072684  [  880/ 3000]\n",
      "loss: 0.083907  [  888/ 3000]\n",
      "loss: 0.065467  [  896/ 3000]\n",
      "loss: 0.166585  [  904/ 3000]\n",
      "loss: 0.053259  [  912/ 3000]\n",
      "loss: 0.056449  [  920/ 3000]\n",
      "loss: 0.064834  [  928/ 3000]\n",
      "loss: 0.038453  [  936/ 3000]\n",
      "loss: 0.147704  [  944/ 3000]\n",
      "loss: 0.027902  [  952/ 3000]\n",
      "loss: 0.046172  [  960/ 3000]\n",
      "loss: 0.022794  [  968/ 3000]\n",
      "loss: 0.011008  [  976/ 3000]\n",
      "loss: 0.012666  [  984/ 3000]\n",
      "loss: 0.109171  [  992/ 3000]\n",
      "loss: 0.064006  [ 1000/ 3000]\n",
      "loss: 0.056324  [ 1008/ 3000]\n",
      "loss: 0.102705  [ 1016/ 3000]\n",
      "loss: 0.054944  [ 1024/ 3000]\n",
      "loss: 0.089838  [ 1032/ 3000]\n",
      "loss: 0.014855  [ 1040/ 3000]\n",
      "loss: 0.037193  [ 1048/ 3000]\n",
      "loss: 0.019121  [ 1056/ 3000]\n",
      "loss: 0.065098  [ 1064/ 3000]\n",
      "loss: 0.038588  [ 1072/ 3000]\n",
      "loss: 0.045228  [ 1080/ 3000]\n",
      "loss: 0.091372  [ 1088/ 3000]\n",
      "loss: 0.080162  [ 1096/ 3000]\n",
      "loss: 0.017123  [ 1104/ 3000]\n",
      "loss: 0.087365  [ 1112/ 3000]\n",
      "loss: 0.026888  [ 1120/ 3000]\n",
      "loss: 0.045343  [ 1128/ 3000]\n",
      "loss: 0.040161  [ 1136/ 3000]\n",
      "loss: 0.105540  [ 1144/ 3000]\n",
      "loss: 0.034842  [ 1152/ 3000]\n",
      "loss: 0.025942  [ 1160/ 3000]\n",
      "loss: 0.028928  [ 1168/ 3000]\n",
      "loss: 0.023659  [ 1176/ 3000]\n",
      "loss: 0.148042  [ 1184/ 3000]\n",
      "loss: 0.052256  [ 1192/ 3000]\n",
      "loss: 0.035580  [ 1200/ 3000]\n",
      "loss: 0.035905  [ 1208/ 3000]\n",
      "loss: 0.038736  [ 1216/ 3000]\n",
      "loss: 0.068407  [ 1224/ 3000]\n",
      "loss: 0.078082  [ 1232/ 3000]\n",
      "loss: 0.070921  [ 1240/ 3000]\n",
      "loss: 0.074669  [ 1248/ 3000]\n",
      "loss: 0.009656  [ 1256/ 3000]\n",
      "loss: 0.046481  [ 1264/ 3000]\n",
      "loss: 0.022312  [ 1272/ 3000]\n",
      "loss: 0.026423  [ 1280/ 3000]\n",
      "loss: 0.056233  [ 1288/ 3000]\n",
      "loss: 0.020851  [ 1296/ 3000]\n",
      "loss: 0.003368  [ 1304/ 3000]\n",
      "loss: 0.083512  [ 1312/ 3000]\n",
      "loss: 0.214808  [ 1320/ 3000]\n",
      "loss: 0.085172  [ 1328/ 3000]\n",
      "loss: 0.066848  [ 1336/ 3000]\n",
      "loss: 0.111660  [ 1344/ 3000]\n",
      "loss: 0.073508  [ 1352/ 3000]\n",
      "loss: 0.026227  [ 1360/ 3000]\n",
      "loss: 0.104573  [ 1368/ 3000]\n",
      "loss: 0.121986  [ 1376/ 3000]\n",
      "loss: 0.054932  [ 1384/ 3000]\n",
      "loss: 0.032206  [ 1392/ 3000]\n",
      "loss: 0.076381  [ 1400/ 3000]\n",
      "loss: 0.072067  [ 1408/ 3000]\n",
      "loss: 0.074344  [ 1416/ 3000]\n",
      "loss: 0.113441  [ 1424/ 3000]\n",
      "loss: 0.053252  [ 1432/ 3000]\n",
      "loss: 0.032310  [ 1440/ 3000]\n",
      "loss: 0.029849  [ 1448/ 3000]\n",
      "loss: 0.052874  [ 1456/ 3000]\n",
      "loss: 0.007206  [ 1464/ 3000]\n",
      "loss: 0.042565  [ 1472/ 3000]\n",
      "loss: 0.021518  [ 1480/ 3000]\n",
      "loss: 0.117087  [ 1488/ 3000]\n",
      "loss: 0.025587  [ 1496/ 3000]\n",
      "loss: 0.043307  [ 1504/ 3000]\n",
      "loss: 0.075394  [ 1512/ 3000]\n",
      "loss: 0.065404  [ 1520/ 3000]\n",
      "loss: 0.023259  [ 1528/ 3000]\n",
      "loss: 0.070328  [ 1536/ 3000]\n",
      "loss: 0.025922  [ 1544/ 3000]\n",
      "loss: 0.095098  [ 1552/ 3000]\n",
      "loss: 0.037548  [ 1560/ 3000]\n",
      "loss: 0.033015  [ 1568/ 3000]\n",
      "loss: 0.020504  [ 1576/ 3000]\n",
      "loss: 0.089057  [ 1584/ 3000]\n",
      "loss: 0.049863  [ 1592/ 3000]\n",
      "loss: 0.076748  [ 1600/ 3000]\n",
      "loss: 0.033001  [ 1608/ 3000]\n",
      "loss: 0.119215  [ 1616/ 3000]\n",
      "loss: 0.094590  [ 1624/ 3000]\n",
      "loss: 0.037634  [ 1632/ 3000]\n",
      "loss: 0.039342  [ 1640/ 3000]\n",
      "loss: 0.103684  [ 1648/ 3000]\n",
      "loss: 0.032665  [ 1656/ 3000]\n",
      "loss: 0.091133  [ 1664/ 3000]\n",
      "loss: 0.016666  [ 1672/ 3000]\n",
      "loss: 0.043171  [ 1680/ 3000]\n",
      "loss: 0.050903  [ 1688/ 3000]\n",
      "loss: 0.078882  [ 1696/ 3000]\n",
      "loss: 0.041651  [ 1704/ 3000]\n",
      "loss: 0.020784  [ 1712/ 3000]\n",
      "loss: 0.027068  [ 1720/ 3000]\n",
      "loss: 0.049348  [ 1728/ 3000]\n",
      "loss: 0.073344  [ 1736/ 3000]\n",
      "loss: 0.065422  [ 1744/ 3000]\n",
      "loss: 0.016053  [ 1752/ 3000]\n",
      "loss: 0.007283  [ 1760/ 3000]\n",
      "loss: 0.085437  [ 1768/ 3000]\n",
      "loss: 0.049244  [ 1776/ 3000]\n",
      "loss: 0.023006  [ 1784/ 3000]\n",
      "loss: 0.038910  [ 1792/ 3000]\n",
      "loss: 0.076809  [ 1800/ 3000]\n",
      "loss: 0.108473  [ 1808/ 3000]\n",
      "loss: 0.029999  [ 1816/ 3000]\n",
      "loss: 0.102596  [ 1824/ 3000]\n",
      "loss: 0.004165  [ 1832/ 3000]\n",
      "loss: 0.008317  [ 1840/ 3000]\n",
      "loss: 0.042194  [ 1848/ 3000]\n",
      "loss: 0.065124  [ 1856/ 3000]\n",
      "loss: 0.061524  [ 1864/ 3000]\n",
      "loss: 0.058295  [ 1872/ 3000]\n",
      "loss: 0.008466  [ 1880/ 3000]\n",
      "loss: 0.014009  [ 1888/ 3000]\n",
      "loss: 0.052080  [ 1896/ 3000]\n",
      "loss: 0.029513  [ 1904/ 3000]\n",
      "loss: 0.029397  [ 1912/ 3000]\n",
      "loss: 0.089258  [ 1920/ 3000]\n",
      "loss: 0.065813  [ 1928/ 3000]\n",
      "loss: 0.105663  [ 1936/ 3000]\n",
      "loss: 0.011696  [ 1944/ 3000]\n",
      "loss: 0.078181  [ 1952/ 3000]\n",
      "loss: 0.024982  [ 1960/ 3000]\n",
      "loss: 0.090315  [ 1968/ 3000]\n",
      "loss: 0.026378  [ 1976/ 3000]\n",
      "loss: 0.100532  [ 1984/ 3000]\n",
      "loss: 0.106883  [ 1992/ 3000]\n",
      "loss: 0.052061  [ 2000/ 3000]\n",
      "loss: 0.079536  [ 2008/ 3000]\n",
      "loss: 0.042737  [ 2016/ 3000]\n",
      "loss: 0.049331  [ 2024/ 3000]\n",
      "loss: 0.082348  [ 2032/ 3000]\n",
      "loss: 0.069201  [ 2040/ 3000]\n",
      "loss: 0.031270  [ 2048/ 3000]\n",
      "loss: 0.030233  [ 2056/ 3000]\n",
      "loss: 0.020474  [ 2064/ 3000]\n",
      "loss: 0.093669  [ 2072/ 3000]\n",
      "loss: 0.038487  [ 2080/ 3000]\n",
      "loss: 0.082594  [ 2088/ 3000]\n",
      "loss: 0.062853  [ 2096/ 3000]\n",
      "loss: 0.040849  [ 2104/ 3000]\n",
      "loss: 0.028032  [ 2112/ 3000]\n",
      "loss: 0.012525  [ 2120/ 3000]\n",
      "loss: 0.060129  [ 2128/ 3000]\n",
      "loss: 0.055634  [ 2136/ 3000]\n",
      "loss: 0.086634  [ 2144/ 3000]\n",
      "loss: 0.118309  [ 2152/ 3000]\n",
      "loss: 0.019043  [ 2160/ 3000]\n",
      "loss: 0.052346  [ 2168/ 3000]\n",
      "loss: 0.021632  [ 2176/ 3000]\n",
      "loss: 0.074949  [ 2184/ 3000]\n",
      "loss: 0.049223  [ 2192/ 3000]\n",
      "loss: 0.027100  [ 2200/ 3000]\n",
      "loss: 0.013998  [ 2208/ 3000]\n",
      "loss: 0.030964  [ 2216/ 3000]\n",
      "loss: 0.080369  [ 2224/ 3000]\n",
      "loss: 0.058570  [ 2232/ 3000]\n",
      "loss: 0.101156  [ 2240/ 3000]\n",
      "loss: 0.010392  [ 2248/ 3000]\n",
      "loss: 0.041951  [ 2256/ 3000]\n",
      "loss: 0.015163  [ 2264/ 3000]\n",
      "loss: 0.108731  [ 2272/ 3000]\n",
      "loss: 0.036383  [ 2280/ 3000]\n",
      "loss: 0.089695  [ 2288/ 3000]\n",
      "loss: 0.053429  [ 2296/ 3000]\n",
      "loss: 0.041856  [ 2304/ 3000]\n",
      "loss: 0.022310  [ 2312/ 3000]\n",
      "loss: 0.016246  [ 2320/ 3000]\n",
      "loss: 0.062142  [ 2328/ 3000]\n",
      "loss: 0.011958  [ 2336/ 3000]\n",
      "loss: 0.094576  [ 2344/ 3000]\n",
      "loss: 0.085302  [ 2352/ 3000]\n",
      "loss: 0.085151  [ 2360/ 3000]\n",
      "loss: 0.036359  [ 2368/ 3000]\n",
      "loss: 0.022323  [ 2376/ 3000]\n",
      "loss: 0.045838  [ 2384/ 3000]\n",
      "loss: 0.042266  [ 2392/ 3000]\n",
      "loss: 0.007269  [ 2400/ 3000]\n",
      "loss: 0.105354  [ 2408/ 3000]\n",
      "loss: 0.069160  [ 2416/ 3000]\n",
      "loss: 0.061637  [ 2424/ 3000]\n",
      "loss: 0.078099  [ 2432/ 3000]\n",
      "loss: 0.043450  [ 2440/ 3000]\n",
      "loss: 0.085129  [ 2448/ 3000]\n",
      "loss: 0.096808  [ 2456/ 3000]\n",
      "loss: 0.038812  [ 2464/ 3000]\n",
      "loss: 0.203094  [ 2472/ 3000]\n",
      "loss: 0.024822  [ 2480/ 3000]\n",
      "loss: 0.044220  [ 2488/ 3000]\n",
      "loss: 0.011536  [ 2496/ 3000]\n",
      "loss: 0.027660  [ 2504/ 3000]\n",
      "loss: 0.097115  [ 2512/ 3000]\n",
      "loss: 0.185863  [ 2520/ 3000]\n",
      "loss: 0.024621  [ 2528/ 3000]\n",
      "loss: 0.052858  [ 2536/ 3000]\n",
      "loss: 0.014789  [ 2544/ 3000]\n",
      "loss: 0.073717  [ 2552/ 3000]\n",
      "loss: 0.073497  [ 2560/ 3000]\n",
      "loss: 0.119883  [ 2568/ 3000]\n",
      "loss: 0.086097  [ 2576/ 3000]\n",
      "loss: 0.049995  [ 2584/ 3000]\n",
      "loss: 0.040400  [ 2592/ 3000]\n",
      "loss: 0.064329  [ 2600/ 3000]\n",
      "loss: 0.071537  [ 2608/ 3000]\n",
      "loss: 0.024798  [ 2616/ 3000]\n",
      "loss: 0.024401  [ 2624/ 3000]\n",
      "loss: 0.091384  [ 2632/ 3000]\n",
      "loss: 0.106097  [ 2640/ 3000]\n",
      "loss: 0.067298  [ 2648/ 3000]\n",
      "loss: 0.069169  [ 2656/ 3000]\n",
      "loss: 0.047141  [ 2664/ 3000]\n",
      "loss: 0.083797  [ 2672/ 3000]\n",
      "loss: 0.098001  [ 2680/ 3000]\n",
      "loss: 0.042998  [ 2688/ 3000]\n",
      "loss: 0.033122  [ 2696/ 3000]\n",
      "loss: 0.071985  [ 2704/ 3000]\n",
      "loss: 0.059441  [ 2712/ 3000]\n",
      "loss: 0.043121  [ 2720/ 3000]\n",
      "loss: 0.083323  [ 2728/ 3000]\n",
      "loss: 0.025653  [ 2736/ 3000]\n",
      "loss: 0.056504  [ 2744/ 3000]\n",
      "loss: 0.069325  [ 2752/ 3000]\n",
      "loss: 0.051487  [ 2760/ 3000]\n",
      "loss: 0.016519  [ 2768/ 3000]\n",
      "loss: 0.087904  [ 2776/ 3000]\n",
      "loss: 0.060388  [ 2784/ 3000]\n",
      "loss: 0.034230  [ 2792/ 3000]\n",
      "loss: 0.088114  [ 2800/ 3000]\n",
      "loss: 0.127452  [ 2808/ 3000]\n",
      "loss: 0.049704  [ 2816/ 3000]\n",
      "loss: 0.064951  [ 2824/ 3000]\n",
      "loss: 0.067544  [ 2832/ 3000]\n",
      "loss: 0.046620  [ 2840/ 3000]\n",
      "loss: 0.041995  [ 2848/ 3000]\n",
      "loss: 0.066433  [ 2856/ 3000]\n",
      "loss: 0.027066  [ 2864/ 3000]\n",
      "loss: 0.079162  [ 2872/ 3000]\n",
      "loss: 0.084350  [ 2880/ 3000]\n",
      "loss: 0.011496  [ 2888/ 3000]\n",
      "loss: 0.012283  [ 2896/ 3000]\n",
      "loss: 0.052508  [ 2904/ 3000]\n",
      "loss: 0.079213  [ 2912/ 3000]\n",
      "loss: 0.045378  [ 2920/ 3000]\n",
      "loss: 0.091225  [ 2928/ 3000]\n",
      "loss: 0.132664  [ 2936/ 3000]\n",
      "loss: 0.025487  [ 2944/ 3000]\n",
      "loss: 0.004519  [ 2952/ 3000]\n",
      "loss: 0.024521  [ 2960/ 3000]\n",
      "loss: 0.047553  [ 2968/ 3000]\n",
      "loss: 0.045368  [ 2976/ 3000]\n",
      "loss: 0.055058  [ 2984/ 3000]\n",
      "loss: 0.008905  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085360 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.024730  [    0/ 3000]\n",
      "loss: 0.060883  [    8/ 3000]\n",
      "loss: 0.017699  [   16/ 3000]\n",
      "loss: 0.024068  [   24/ 3000]\n",
      "loss: 0.086520  [   32/ 3000]\n",
      "loss: 0.013698  [   40/ 3000]\n",
      "loss: 0.018990  [   48/ 3000]\n",
      "loss: 0.065935  [   56/ 3000]\n",
      "loss: 0.123267  [   64/ 3000]\n",
      "loss: 0.019770  [   72/ 3000]\n",
      "loss: 0.127285  [   80/ 3000]\n",
      "loss: 0.063030  [   88/ 3000]\n",
      "loss: 0.086340  [   96/ 3000]\n",
      "loss: 0.034129  [  104/ 3000]\n",
      "loss: 0.141366  [  112/ 3000]\n",
      "loss: 0.030341  [  120/ 3000]\n",
      "loss: 0.032431  [  128/ 3000]\n",
      "loss: 0.066300  [  136/ 3000]\n",
      "loss: 0.065130  [  144/ 3000]\n",
      "loss: 0.035476  [  152/ 3000]\n",
      "loss: 0.017485  [  160/ 3000]\n",
      "loss: 0.011492  [  168/ 3000]\n",
      "loss: 0.023815  [  176/ 3000]\n",
      "loss: 0.074556  [  184/ 3000]\n",
      "loss: 0.043043  [  192/ 3000]\n",
      "loss: 0.032690  [  200/ 3000]\n",
      "loss: 0.138482  [  208/ 3000]\n",
      "loss: 0.033358  [  216/ 3000]\n",
      "loss: 0.044435  [  224/ 3000]\n",
      "loss: 0.109812  [  232/ 3000]\n",
      "loss: 0.051344  [  240/ 3000]\n",
      "loss: 0.032931  [  248/ 3000]\n",
      "loss: 0.024719  [  256/ 3000]\n",
      "loss: 0.066310  [  264/ 3000]\n",
      "loss: 0.045953  [  272/ 3000]\n",
      "loss: 0.149355  [  280/ 3000]\n",
      "loss: 0.021958  [  288/ 3000]\n",
      "loss: 0.049208  [  296/ 3000]\n",
      "loss: 0.032547  [  304/ 3000]\n",
      "loss: 0.090529  [  312/ 3000]\n",
      "loss: 0.036162  [  320/ 3000]\n",
      "loss: 0.100654  [  328/ 3000]\n",
      "loss: 0.032823  [  336/ 3000]\n",
      "loss: 0.077375  [  344/ 3000]\n",
      "loss: 0.017916  [  352/ 3000]\n",
      "loss: 0.027871  [  360/ 3000]\n",
      "loss: 0.104874  [  368/ 3000]\n",
      "loss: 0.017377  [  376/ 3000]\n",
      "loss: 0.084703  [  384/ 3000]\n",
      "loss: 0.044707  [  392/ 3000]\n",
      "loss: 0.072863  [  400/ 3000]\n",
      "loss: 0.030325  [  408/ 3000]\n",
      "loss: 0.080746  [  416/ 3000]\n",
      "loss: 0.038580  [  424/ 3000]\n",
      "loss: 0.144179  [  432/ 3000]\n",
      "loss: 0.032410  [  440/ 3000]\n",
      "loss: 0.065173  [  448/ 3000]\n",
      "loss: 0.038350  [  456/ 3000]\n",
      "loss: 0.094000  [  464/ 3000]\n",
      "loss: 0.056038  [  472/ 3000]\n",
      "loss: 0.014921  [  480/ 3000]\n",
      "loss: 0.110725  [  488/ 3000]\n",
      "loss: 0.085888  [  496/ 3000]\n",
      "loss: 0.034251  [  504/ 3000]\n",
      "loss: 0.060982  [  512/ 3000]\n",
      "loss: 0.038930  [  520/ 3000]\n",
      "loss: 0.172978  [  528/ 3000]\n",
      "loss: 0.082105  [  536/ 3000]\n",
      "loss: 0.072556  [  544/ 3000]\n",
      "loss: 0.042551  [  552/ 3000]\n",
      "loss: 0.033064  [  560/ 3000]\n",
      "loss: 0.077144  [  568/ 3000]\n",
      "loss: 0.046604  [  576/ 3000]\n",
      "loss: 0.052788  [  584/ 3000]\n",
      "loss: 0.028617  [  592/ 3000]\n",
      "loss: 0.116054  [  600/ 3000]\n",
      "loss: 0.032464  [  608/ 3000]\n",
      "loss: 0.077543  [  616/ 3000]\n",
      "loss: 0.052244  [  624/ 3000]\n",
      "loss: 0.158248  [  632/ 3000]\n",
      "loss: 0.014940  [  640/ 3000]\n",
      "loss: 0.122473  [  648/ 3000]\n",
      "loss: 0.165413  [  656/ 3000]\n",
      "loss: 0.141149  [  664/ 3000]\n",
      "loss: 0.059742  [  672/ 3000]\n",
      "loss: 0.071376  [  680/ 3000]\n",
      "loss: 0.046848  [  688/ 3000]\n",
      "loss: 0.144513  [  696/ 3000]\n",
      "loss: 0.061594  [  704/ 3000]\n",
      "loss: 0.040662  [  712/ 3000]\n",
      "loss: 0.051330  [  720/ 3000]\n",
      "loss: 0.028470  [  728/ 3000]\n",
      "loss: 0.054545  [  736/ 3000]\n",
      "loss: 0.024159  [  744/ 3000]\n",
      "loss: 0.075727  [  752/ 3000]\n",
      "loss: 0.056357  [  760/ 3000]\n",
      "loss: 0.110366  [  768/ 3000]\n",
      "loss: 0.056014  [  776/ 3000]\n",
      "loss: 0.129936  [  784/ 3000]\n",
      "loss: 0.060549  [  792/ 3000]\n",
      "loss: 0.153223  [  800/ 3000]\n",
      "loss: 0.053912  [  808/ 3000]\n",
      "loss: 0.028088  [  816/ 3000]\n",
      "loss: 0.045199  [  824/ 3000]\n",
      "loss: 0.049054  [  832/ 3000]\n",
      "loss: 0.019612  [  840/ 3000]\n",
      "loss: 0.017344  [  848/ 3000]\n",
      "loss: 0.022837  [  856/ 3000]\n",
      "loss: 0.074388  [  864/ 3000]\n",
      "loss: 0.010591  [  872/ 3000]\n",
      "loss: 0.070898  [  880/ 3000]\n",
      "loss: 0.081470  [  888/ 3000]\n",
      "loss: 0.064587  [  896/ 3000]\n",
      "loss: 0.162091  [  904/ 3000]\n",
      "loss: 0.052533  [  912/ 3000]\n",
      "loss: 0.055097  [  920/ 3000]\n",
      "loss: 0.063110  [  928/ 3000]\n",
      "loss: 0.036820  [  936/ 3000]\n",
      "loss: 0.143550  [  944/ 3000]\n",
      "loss: 0.026702  [  952/ 3000]\n",
      "loss: 0.045122  [  960/ 3000]\n",
      "loss: 0.021888  [  968/ 3000]\n",
      "loss: 0.010550  [  976/ 3000]\n",
      "loss: 0.012131  [  984/ 3000]\n",
      "loss: 0.106173  [  992/ 3000]\n",
      "loss: 0.061967  [ 1000/ 3000]\n",
      "loss: 0.054783  [ 1008/ 3000]\n",
      "loss: 0.099667  [ 1016/ 3000]\n",
      "loss: 0.053280  [ 1024/ 3000]\n",
      "loss: 0.087328  [ 1032/ 3000]\n",
      "loss: 0.014331  [ 1040/ 3000]\n",
      "loss: 0.035861  [ 1048/ 3000]\n",
      "loss: 0.018407  [ 1056/ 3000]\n",
      "loss: 0.063055  [ 1064/ 3000]\n",
      "loss: 0.037251  [ 1072/ 3000]\n",
      "loss: 0.043719  [ 1080/ 3000]\n",
      "loss: 0.088838  [ 1088/ 3000]\n",
      "loss: 0.077379  [ 1096/ 3000]\n",
      "loss: 0.016479  [ 1104/ 3000]\n",
      "loss: 0.084449  [ 1112/ 3000]\n",
      "loss: 0.025954  [ 1120/ 3000]\n",
      "loss: 0.044442  [ 1128/ 3000]\n",
      "loss: 0.038753  [ 1136/ 3000]\n",
      "loss: 0.101320  [ 1144/ 3000]\n",
      "loss: 0.033788  [ 1152/ 3000]\n",
      "loss: 0.025075  [ 1160/ 3000]\n",
      "loss: 0.027980  [ 1168/ 3000]\n",
      "loss: 0.022797  [ 1176/ 3000]\n",
      "loss: 0.143491  [ 1184/ 3000]\n",
      "loss: 0.050940  [ 1192/ 3000]\n",
      "loss: 0.034011  [ 1200/ 3000]\n",
      "loss: 0.035182  [ 1208/ 3000]\n",
      "loss: 0.037024  [ 1216/ 3000]\n",
      "loss: 0.066369  [ 1224/ 3000]\n",
      "loss: 0.075741  [ 1232/ 3000]\n",
      "loss: 0.068749  [ 1240/ 3000]\n",
      "loss: 0.071614  [ 1248/ 3000]\n",
      "loss: 0.009136  [ 1256/ 3000]\n",
      "loss: 0.045687  [ 1264/ 3000]\n",
      "loss: 0.021506  [ 1272/ 3000]\n",
      "loss: 0.025235  [ 1280/ 3000]\n",
      "loss: 0.054070  [ 1288/ 3000]\n",
      "loss: 0.019807  [ 1296/ 3000]\n",
      "loss: 0.003203  [ 1304/ 3000]\n",
      "loss: 0.080781  [ 1312/ 3000]\n",
      "loss: 0.207983  [ 1320/ 3000]\n",
      "loss: 0.082794  [ 1328/ 3000]\n",
      "loss: 0.065642  [ 1336/ 3000]\n",
      "loss: 0.108422  [ 1344/ 3000]\n",
      "loss: 0.071955  [ 1352/ 3000]\n",
      "loss: 0.025023  [ 1360/ 3000]\n",
      "loss: 0.102429  [ 1368/ 3000]\n",
      "loss: 0.119378  [ 1376/ 3000]\n",
      "loss: 0.052690  [ 1384/ 3000]\n",
      "loss: 0.030750  [ 1392/ 3000]\n",
      "loss: 0.074260  [ 1400/ 3000]\n",
      "loss: 0.070119  [ 1408/ 3000]\n",
      "loss: 0.072251  [ 1416/ 3000]\n",
      "loss: 0.111110  [ 1424/ 3000]\n",
      "loss: 0.051269  [ 1432/ 3000]\n",
      "loss: 0.031208  [ 1440/ 3000]\n",
      "loss: 0.028637  [ 1448/ 3000]\n",
      "loss: 0.051285  [ 1456/ 3000]\n",
      "loss: 0.006955  [ 1464/ 3000]\n",
      "loss: 0.041660  [ 1472/ 3000]\n",
      "loss: 0.021169  [ 1480/ 3000]\n",
      "loss: 0.113892  [ 1488/ 3000]\n",
      "loss: 0.024750  [ 1496/ 3000]\n",
      "loss: 0.041856  [ 1504/ 3000]\n",
      "loss: 0.073091  [ 1512/ 3000]\n",
      "loss: 0.063331  [ 1520/ 3000]\n",
      "loss: 0.022343  [ 1528/ 3000]\n",
      "loss: 0.068426  [ 1536/ 3000]\n",
      "loss: 0.024480  [ 1544/ 3000]\n",
      "loss: 0.092241  [ 1552/ 3000]\n",
      "loss: 0.036307  [ 1560/ 3000]\n",
      "loss: 0.031813  [ 1568/ 3000]\n",
      "loss: 0.019751  [ 1576/ 3000]\n",
      "loss: 0.087028  [ 1584/ 3000]\n",
      "loss: 0.048758  [ 1592/ 3000]\n",
      "loss: 0.074494  [ 1600/ 3000]\n",
      "loss: 0.031938  [ 1608/ 3000]\n",
      "loss: 0.116541  [ 1616/ 3000]\n",
      "loss: 0.092199  [ 1624/ 3000]\n",
      "loss: 0.036118  [ 1632/ 3000]\n",
      "loss: 0.037799  [ 1640/ 3000]\n",
      "loss: 0.100866  [ 1648/ 3000]\n",
      "loss: 0.031686  [ 1656/ 3000]\n",
      "loss: 0.087140  [ 1664/ 3000]\n",
      "loss: 0.015824  [ 1672/ 3000]\n",
      "loss: 0.042229  [ 1680/ 3000]\n",
      "loss: 0.049288  [ 1688/ 3000]\n",
      "loss: 0.076985  [ 1696/ 3000]\n",
      "loss: 0.039953  [ 1704/ 3000]\n",
      "loss: 0.020069  [ 1712/ 3000]\n",
      "loss: 0.025868  [ 1720/ 3000]\n",
      "loss: 0.047864  [ 1728/ 3000]\n",
      "loss: 0.071141  [ 1736/ 3000]\n",
      "loss: 0.063656  [ 1744/ 3000]\n",
      "loss: 0.015654  [ 1752/ 3000]\n",
      "loss: 0.006997  [ 1760/ 3000]\n",
      "loss: 0.082255  [ 1768/ 3000]\n",
      "loss: 0.047254  [ 1776/ 3000]\n",
      "loss: 0.022235  [ 1784/ 3000]\n",
      "loss: 0.037451  [ 1792/ 3000]\n",
      "loss: 0.074462  [ 1800/ 3000]\n",
      "loss: 0.105410  [ 1808/ 3000]\n",
      "loss: 0.028895  [ 1816/ 3000]\n",
      "loss: 0.099307  [ 1824/ 3000]\n",
      "loss: 0.003917  [ 1832/ 3000]\n",
      "loss: 0.008021  [ 1840/ 3000]\n",
      "loss: 0.040652  [ 1848/ 3000]\n",
      "loss: 0.063273  [ 1856/ 3000]\n",
      "loss: 0.059462  [ 1864/ 3000]\n",
      "loss: 0.056722  [ 1872/ 3000]\n",
      "loss: 0.007933  [ 1880/ 3000]\n",
      "loss: 0.013277  [ 1888/ 3000]\n",
      "loss: 0.050076  [ 1896/ 3000]\n",
      "loss: 0.028983  [ 1904/ 3000]\n",
      "loss: 0.028125  [ 1912/ 3000]\n",
      "loss: 0.087392  [ 1920/ 3000]\n",
      "loss: 0.063797  [ 1928/ 3000]\n",
      "loss: 0.102611  [ 1936/ 3000]\n",
      "loss: 0.011195  [ 1944/ 3000]\n",
      "loss: 0.076202  [ 1952/ 3000]\n",
      "loss: 0.024098  [ 1960/ 3000]\n",
      "loss: 0.088146  [ 1968/ 3000]\n",
      "loss: 0.025493  [ 1976/ 3000]\n",
      "loss: 0.097844  [ 1984/ 3000]\n",
      "loss: 0.104232  [ 1992/ 3000]\n",
      "loss: 0.050073  [ 2000/ 3000]\n",
      "loss: 0.077056  [ 2008/ 3000]\n",
      "loss: 0.041004  [ 2016/ 3000]\n",
      "loss: 0.048095  [ 2024/ 3000]\n",
      "loss: 0.080338  [ 2032/ 3000]\n",
      "loss: 0.067383  [ 2040/ 3000]\n",
      "loss: 0.030379  [ 2048/ 3000]\n",
      "loss: 0.028945  [ 2056/ 3000]\n",
      "loss: 0.019534  [ 2064/ 3000]\n",
      "loss: 0.091253  [ 2072/ 3000]\n",
      "loss: 0.037139  [ 2080/ 3000]\n",
      "loss: 0.079873  [ 2088/ 3000]\n",
      "loss: 0.061285  [ 2096/ 3000]\n",
      "loss: 0.039789  [ 2104/ 3000]\n",
      "loss: 0.027485  [ 2112/ 3000]\n",
      "loss: 0.012024  [ 2120/ 3000]\n",
      "loss: 0.058990  [ 2128/ 3000]\n",
      "loss: 0.054193  [ 2136/ 3000]\n",
      "loss: 0.084142  [ 2144/ 3000]\n",
      "loss: 0.115973  [ 2152/ 3000]\n",
      "loss: 0.018326  [ 2160/ 3000]\n",
      "loss: 0.050797  [ 2168/ 3000]\n",
      "loss: 0.021163  [ 2176/ 3000]\n",
      "loss: 0.072553  [ 2184/ 3000]\n",
      "loss: 0.046625  [ 2192/ 3000]\n",
      "loss: 0.026192  [ 2200/ 3000]\n",
      "loss: 0.013294  [ 2208/ 3000]\n",
      "loss: 0.030034  [ 2216/ 3000]\n",
      "loss: 0.077590  [ 2224/ 3000]\n",
      "loss: 0.056636  [ 2232/ 3000]\n",
      "loss: 0.098685  [ 2240/ 3000]\n",
      "loss: 0.010004  [ 2248/ 3000]\n",
      "loss: 0.040225  [ 2256/ 3000]\n",
      "loss: 0.014447  [ 2264/ 3000]\n",
      "loss: 0.105664  [ 2272/ 3000]\n",
      "loss: 0.035382  [ 2280/ 3000]\n",
      "loss: 0.086521  [ 2288/ 3000]\n",
      "loss: 0.051742  [ 2296/ 3000]\n",
      "loss: 0.040532  [ 2304/ 3000]\n",
      "loss: 0.021521  [ 2312/ 3000]\n",
      "loss: 0.015421  [ 2320/ 3000]\n",
      "loss: 0.060167  [ 2328/ 3000]\n",
      "loss: 0.011534  [ 2336/ 3000]\n",
      "loss: 0.092278  [ 2344/ 3000]\n",
      "loss: 0.082363  [ 2352/ 3000]\n",
      "loss: 0.082554  [ 2360/ 3000]\n",
      "loss: 0.035426  [ 2368/ 3000]\n",
      "loss: 0.021524  [ 2376/ 3000]\n",
      "loss: 0.044585  [ 2384/ 3000]\n",
      "loss: 0.040548  [ 2392/ 3000]\n",
      "loss: 0.006976  [ 2400/ 3000]\n",
      "loss: 0.103149  [ 2408/ 3000]\n",
      "loss: 0.067527  [ 2416/ 3000]\n",
      "loss: 0.059341  [ 2424/ 3000]\n",
      "loss: 0.076229  [ 2432/ 3000]\n",
      "loss: 0.042310  [ 2440/ 3000]\n",
      "loss: 0.081906  [ 2448/ 3000]\n",
      "loss: 0.094433  [ 2456/ 3000]\n",
      "loss: 0.037492  [ 2464/ 3000]\n",
      "loss: 0.198440  [ 2472/ 3000]\n",
      "loss: 0.024475  [ 2480/ 3000]\n",
      "loss: 0.042860  [ 2488/ 3000]\n",
      "loss: 0.011008  [ 2496/ 3000]\n",
      "loss: 0.026650  [ 2504/ 3000]\n",
      "loss: 0.094596  [ 2512/ 3000]\n",
      "loss: 0.181899  [ 2520/ 3000]\n",
      "loss: 0.023570  [ 2528/ 3000]\n",
      "loss: 0.051507  [ 2536/ 3000]\n",
      "loss: 0.014279  [ 2544/ 3000]\n",
      "loss: 0.071296  [ 2552/ 3000]\n",
      "loss: 0.071277  [ 2560/ 3000]\n",
      "loss: 0.117880  [ 2568/ 3000]\n",
      "loss: 0.082679  [ 2576/ 3000]\n",
      "loss: 0.048323  [ 2584/ 3000]\n",
      "loss: 0.039367  [ 2592/ 3000]\n",
      "loss: 0.063334  [ 2600/ 3000]\n",
      "loss: 0.069790  [ 2608/ 3000]\n",
      "loss: 0.024061  [ 2616/ 3000]\n",
      "loss: 0.023423  [ 2624/ 3000]\n",
      "loss: 0.088923  [ 2632/ 3000]\n",
      "loss: 0.103867  [ 2640/ 3000]\n",
      "loss: 0.065471  [ 2648/ 3000]\n",
      "loss: 0.067296  [ 2656/ 3000]\n",
      "loss: 0.045862  [ 2664/ 3000]\n",
      "loss: 0.080970  [ 2672/ 3000]\n",
      "loss: 0.095227  [ 2680/ 3000]\n",
      "loss: 0.041719  [ 2688/ 3000]\n",
      "loss: 0.032113  [ 2696/ 3000]\n",
      "loss: 0.070378  [ 2704/ 3000]\n",
      "loss: 0.056869  [ 2712/ 3000]\n",
      "loss: 0.041231  [ 2720/ 3000]\n",
      "loss: 0.079996  [ 2728/ 3000]\n",
      "loss: 0.024996  [ 2736/ 3000]\n",
      "loss: 0.055023  [ 2744/ 3000]\n",
      "loss: 0.067330  [ 2752/ 3000]\n",
      "loss: 0.050076  [ 2760/ 3000]\n",
      "loss: 0.015960  [ 2768/ 3000]\n",
      "loss: 0.084612  [ 2776/ 3000]\n",
      "loss: 0.058586  [ 2784/ 3000]\n",
      "loss: 0.033027  [ 2792/ 3000]\n",
      "loss: 0.085798  [ 2800/ 3000]\n",
      "loss: 0.124153  [ 2808/ 3000]\n",
      "loss: 0.048009  [ 2816/ 3000]\n",
      "loss: 0.062900  [ 2824/ 3000]\n",
      "loss: 0.065706  [ 2832/ 3000]\n",
      "loss: 0.045148  [ 2840/ 3000]\n",
      "loss: 0.040240  [ 2848/ 3000]\n",
      "loss: 0.064481  [ 2856/ 3000]\n",
      "loss: 0.026174  [ 2864/ 3000]\n",
      "loss: 0.077579  [ 2872/ 3000]\n",
      "loss: 0.081504  [ 2880/ 3000]\n",
      "loss: 0.010989  [ 2888/ 3000]\n",
      "loss: 0.011966  [ 2896/ 3000]\n",
      "loss: 0.050898  [ 2904/ 3000]\n",
      "loss: 0.076927  [ 2912/ 3000]\n",
      "loss: 0.043100  [ 2920/ 3000]\n",
      "loss: 0.088703  [ 2928/ 3000]\n",
      "loss: 0.127922  [ 2936/ 3000]\n",
      "loss: 0.024807  [ 2944/ 3000]\n",
      "loss: 0.004369  [ 2952/ 3000]\n",
      "loss: 0.023545  [ 2960/ 3000]\n",
      "loss: 0.045720  [ 2968/ 3000]\n",
      "loss: 0.044105  [ 2976/ 3000]\n",
      "loss: 0.053567  [ 2984/ 3000]\n",
      "loss: 0.008506  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085322 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.024187  [    0/ 3000]\n",
      "loss: 0.059481  [    8/ 3000]\n",
      "loss: 0.016991  [   16/ 3000]\n",
      "loss: 0.023057  [   24/ 3000]\n",
      "loss: 0.083836  [   32/ 3000]\n",
      "loss: 0.013099  [   40/ 3000]\n",
      "loss: 0.018324  [   48/ 3000]\n",
      "loss: 0.064217  [   56/ 3000]\n",
      "loss: 0.119249  [   64/ 3000]\n",
      "loss: 0.019298  [   72/ 3000]\n",
      "loss: 0.124107  [   80/ 3000]\n",
      "loss: 0.060804  [   88/ 3000]\n",
      "loss: 0.084403  [   96/ 3000]\n",
      "loss: 0.032240  [  104/ 3000]\n",
      "loss: 0.138095  [  112/ 3000]\n",
      "loss: 0.029330  [  120/ 3000]\n",
      "loss: 0.032253  [  128/ 3000]\n",
      "loss: 0.063846  [  136/ 3000]\n",
      "loss: 0.062930  [  144/ 3000]\n",
      "loss: 0.034296  [  152/ 3000]\n",
      "loss: 0.016952  [  160/ 3000]\n",
      "loss: 0.011117  [  168/ 3000]\n",
      "loss: 0.022696  [  176/ 3000]\n",
      "loss: 0.072209  [  184/ 3000]\n",
      "loss: 0.041178  [  192/ 3000]\n",
      "loss: 0.031724  [  200/ 3000]\n",
      "loss: 0.134991  [  208/ 3000]\n",
      "loss: 0.031906  [  216/ 3000]\n",
      "loss: 0.042732  [  224/ 3000]\n",
      "loss: 0.107530  [  232/ 3000]\n",
      "loss: 0.050124  [  240/ 3000]\n",
      "loss: 0.031293  [  248/ 3000]\n",
      "loss: 0.023971  [  256/ 3000]\n",
      "loss: 0.063587  [  264/ 3000]\n",
      "loss: 0.045226  [  272/ 3000]\n",
      "loss: 0.146244  [  280/ 3000]\n",
      "loss: 0.021135  [  288/ 3000]\n",
      "loss: 0.048222  [  296/ 3000]\n",
      "loss: 0.031544  [  304/ 3000]\n",
      "loss: 0.087455  [  312/ 3000]\n",
      "loss: 0.034734  [  320/ 3000]\n",
      "loss: 0.096626  [  328/ 3000]\n",
      "loss: 0.031568  [  336/ 3000]\n",
      "loss: 0.075322  [  344/ 3000]\n",
      "loss: 0.017318  [  352/ 3000]\n",
      "loss: 0.026778  [  360/ 3000]\n",
      "loss: 0.101936  [  368/ 3000]\n",
      "loss: 0.016526  [  376/ 3000]\n",
      "loss: 0.083278  [  384/ 3000]\n",
      "loss: 0.043024  [  392/ 3000]\n",
      "loss: 0.070793  [  400/ 3000]\n",
      "loss: 0.029665  [  408/ 3000]\n",
      "loss: 0.078524  [  416/ 3000]\n",
      "loss: 0.037198  [  424/ 3000]\n",
      "loss: 0.140440  [  432/ 3000]\n",
      "loss: 0.031163  [  440/ 3000]\n",
      "loss: 0.063446  [  448/ 3000]\n",
      "loss: 0.037216  [  456/ 3000]\n",
      "loss: 0.090360  [  464/ 3000]\n",
      "loss: 0.055017  [  472/ 3000]\n",
      "loss: 0.014503  [  480/ 3000]\n",
      "loss: 0.107495  [  488/ 3000]\n",
      "loss: 0.083987  [  496/ 3000]\n",
      "loss: 0.033225  [  504/ 3000]\n",
      "loss: 0.059392  [  512/ 3000]\n",
      "loss: 0.038009  [  520/ 3000]\n",
      "loss: 0.168221  [  528/ 3000]\n",
      "loss: 0.079771  [  536/ 3000]\n",
      "loss: 0.070356  [  544/ 3000]\n",
      "loss: 0.041008  [  552/ 3000]\n",
      "loss: 0.031936  [  560/ 3000]\n",
      "loss: 0.074832  [  568/ 3000]\n",
      "loss: 0.045251  [  576/ 3000]\n",
      "loss: 0.050949  [  584/ 3000]\n",
      "loss: 0.027544  [  592/ 3000]\n",
      "loss: 0.112940  [  600/ 3000]\n",
      "loss: 0.031221  [  608/ 3000]\n",
      "loss: 0.075169  [  616/ 3000]\n",
      "loss: 0.050444  [  624/ 3000]\n",
      "loss: 0.153952  [  632/ 3000]\n",
      "loss: 0.014588  [  640/ 3000]\n",
      "loss: 0.119025  [  648/ 3000]\n",
      "loss: 0.161103  [  656/ 3000]\n",
      "loss: 0.137788  [  664/ 3000]\n",
      "loss: 0.058005  [  672/ 3000]\n",
      "loss: 0.069530  [  680/ 3000]\n",
      "loss: 0.045492  [  688/ 3000]\n",
      "loss: 0.140900  [  696/ 3000]\n",
      "loss: 0.060390  [  704/ 3000]\n",
      "loss: 0.039353  [  712/ 3000]\n",
      "loss: 0.050021  [  720/ 3000]\n",
      "loss: 0.027539  [  728/ 3000]\n",
      "loss: 0.053016  [  736/ 3000]\n",
      "loss: 0.022970  [  744/ 3000]\n",
      "loss: 0.073414  [  752/ 3000]\n",
      "loss: 0.054755  [  760/ 3000]\n",
      "loss: 0.108039  [  768/ 3000]\n",
      "loss: 0.054822  [  776/ 3000]\n",
      "loss: 0.126715  [  784/ 3000]\n",
      "loss: 0.058025  [  792/ 3000]\n",
      "loss: 0.150437  [  800/ 3000]\n",
      "loss: 0.052665  [  808/ 3000]\n",
      "loss: 0.027315  [  816/ 3000]\n",
      "loss: 0.043963  [  824/ 3000]\n",
      "loss: 0.047659  [  832/ 3000]\n",
      "loss: 0.018871  [  840/ 3000]\n",
      "loss: 0.016923  [  848/ 3000]\n",
      "loss: 0.021992  [  856/ 3000]\n",
      "loss: 0.072470  [  864/ 3000]\n",
      "loss: 0.010116  [  872/ 3000]\n",
      "loss: 0.068928  [  880/ 3000]\n",
      "loss: 0.078948  [  888/ 3000]\n",
      "loss: 0.063644  [  896/ 3000]\n",
      "loss: 0.157900  [  904/ 3000]\n",
      "loss: 0.051849  [  912/ 3000]\n",
      "loss: 0.053767  [  920/ 3000]\n",
      "loss: 0.061515  [  928/ 3000]\n",
      "loss: 0.035222  [  936/ 3000]\n",
      "loss: 0.139237  [  944/ 3000]\n",
      "loss: 0.025613  [  952/ 3000]\n",
      "loss: 0.044175  [  960/ 3000]\n",
      "loss: 0.020972  [  968/ 3000]\n",
      "loss: 0.010128  [  976/ 3000]\n",
      "loss: 0.011605  [  984/ 3000]\n",
      "loss: 0.103417  [  992/ 3000]\n",
      "loss: 0.059871  [ 1000/ 3000]\n",
      "loss: 0.053230  [ 1008/ 3000]\n",
      "loss: 0.096749  [ 1016/ 3000]\n",
      "loss: 0.051592  [ 1024/ 3000]\n",
      "loss: 0.084847  [ 1032/ 3000]\n",
      "loss: 0.013834  [ 1040/ 3000]\n",
      "loss: 0.034565  [ 1048/ 3000]\n",
      "loss: 0.017633  [ 1056/ 3000]\n",
      "loss: 0.060826  [ 1064/ 3000]\n",
      "loss: 0.035980  [ 1072/ 3000]\n",
      "loss: 0.042229  [ 1080/ 3000]\n",
      "loss: 0.086213  [ 1088/ 3000]\n",
      "loss: 0.074629  [ 1096/ 3000]\n",
      "loss: 0.015864  [ 1104/ 3000]\n",
      "loss: 0.081574  [ 1112/ 3000]\n",
      "loss: 0.025017  [ 1120/ 3000]\n",
      "loss: 0.043462  [ 1128/ 3000]\n",
      "loss: 0.037365  [ 1136/ 3000]\n",
      "loss: 0.097031  [ 1144/ 3000]\n",
      "loss: 0.032672  [ 1152/ 3000]\n",
      "loss: 0.024204  [ 1160/ 3000]\n",
      "loss: 0.027045  [ 1168/ 3000]\n",
      "loss: 0.021998  [ 1176/ 3000]\n",
      "loss: 0.139036  [ 1184/ 3000]\n",
      "loss: 0.049514  [ 1192/ 3000]\n",
      "loss: 0.032454  [ 1200/ 3000]\n",
      "loss: 0.034481  [ 1208/ 3000]\n",
      "loss: 0.035476  [ 1216/ 3000]\n",
      "loss: 0.064365  [ 1224/ 3000]\n",
      "loss: 0.073404  [ 1232/ 3000]\n",
      "loss: 0.066575  [ 1240/ 3000]\n",
      "loss: 0.068555  [ 1248/ 3000]\n",
      "loss: 0.008639  [ 1256/ 3000]\n",
      "loss: 0.044822  [ 1264/ 3000]\n",
      "loss: 0.020763  [ 1272/ 3000]\n",
      "loss: 0.024155  [ 1280/ 3000]\n",
      "loss: 0.051956  [ 1288/ 3000]\n",
      "loss: 0.018779  [ 1296/ 3000]\n",
      "loss: 0.003047  [ 1304/ 3000]\n",
      "loss: 0.078024  [ 1312/ 3000]\n",
      "loss: 0.201391  [ 1320/ 3000]\n",
      "loss: 0.080488  [ 1328/ 3000]\n",
      "loss: 0.064373  [ 1336/ 3000]\n",
      "loss: 0.105231  [ 1344/ 3000]\n",
      "loss: 0.070421  [ 1352/ 3000]\n",
      "loss: 0.023775  [ 1360/ 3000]\n",
      "loss: 0.100247  [ 1368/ 3000]\n",
      "loss: 0.116803  [ 1376/ 3000]\n",
      "loss: 0.050450  [ 1384/ 3000]\n",
      "loss: 0.029371  [ 1392/ 3000]\n",
      "loss: 0.072081  [ 1400/ 3000]\n",
      "loss: 0.068254  [ 1408/ 3000]\n",
      "loss: 0.070140  [ 1416/ 3000]\n",
      "loss: 0.108609  [ 1424/ 3000]\n",
      "loss: 0.049246  [ 1432/ 3000]\n",
      "loss: 0.030154  [ 1440/ 3000]\n",
      "loss: 0.027420  [ 1448/ 3000]\n",
      "loss: 0.049666  [ 1456/ 3000]\n",
      "loss: 0.006723  [ 1464/ 3000]\n",
      "loss: 0.040694  [ 1472/ 3000]\n",
      "loss: 0.020849  [ 1480/ 3000]\n",
      "loss: 0.110620  [ 1488/ 3000]\n",
      "loss: 0.023960  [ 1496/ 3000]\n",
      "loss: 0.040415  [ 1504/ 3000]\n",
      "loss: 0.070876  [ 1512/ 3000]\n",
      "loss: 0.061387  [ 1520/ 3000]\n",
      "loss: 0.021477  [ 1528/ 3000]\n",
      "loss: 0.066493  [ 1536/ 3000]\n",
      "loss: 0.023060  [ 1544/ 3000]\n",
      "loss: 0.089397  [ 1552/ 3000]\n",
      "loss: 0.035119  [ 1560/ 3000]\n",
      "loss: 0.030697  [ 1568/ 3000]\n",
      "loss: 0.019029  [ 1576/ 3000]\n",
      "loss: 0.085031  [ 1584/ 3000]\n",
      "loss: 0.047756  [ 1592/ 3000]\n",
      "loss: 0.072299  [ 1600/ 3000]\n",
      "loss: 0.030786  [ 1608/ 3000]\n",
      "loss: 0.113923  [ 1616/ 3000]\n",
      "loss: 0.089794  [ 1624/ 3000]\n",
      "loss: 0.034695  [ 1632/ 3000]\n",
      "loss: 0.036240  [ 1640/ 3000]\n",
      "loss: 0.097872  [ 1648/ 3000]\n",
      "loss: 0.030710  [ 1656/ 3000]\n",
      "loss: 0.083435  [ 1664/ 3000]\n",
      "loss: 0.015014  [ 1672/ 3000]\n",
      "loss: 0.041246  [ 1680/ 3000]\n",
      "loss: 0.047774  [ 1688/ 3000]\n",
      "loss: 0.075127  [ 1696/ 3000]\n",
      "loss: 0.038273  [ 1704/ 3000]\n",
      "loss: 0.019405  [ 1712/ 3000]\n",
      "loss: 0.024729  [ 1720/ 3000]\n",
      "loss: 0.046486  [ 1728/ 3000]\n",
      "loss: 0.068842  [ 1736/ 3000]\n",
      "loss: 0.061955  [ 1744/ 3000]\n",
      "loss: 0.015286  [ 1752/ 3000]\n",
      "loss: 0.006728  [ 1760/ 3000]\n",
      "loss: 0.079102  [ 1768/ 3000]\n",
      "loss: 0.045326  [ 1776/ 3000]\n",
      "loss: 0.021454  [ 1784/ 3000]\n",
      "loss: 0.036070  [ 1792/ 3000]\n",
      "loss: 0.072237  [ 1800/ 3000]\n",
      "loss: 0.102416  [ 1808/ 3000]\n",
      "loss: 0.028054  [ 1816/ 3000]\n",
      "loss: 0.095929  [ 1824/ 3000]\n",
      "loss: 0.003685  [ 1832/ 3000]\n",
      "loss: 0.007739  [ 1840/ 3000]\n",
      "loss: 0.039124  [ 1848/ 3000]\n",
      "loss: 0.061489  [ 1856/ 3000]\n",
      "loss: 0.057493  [ 1864/ 3000]\n",
      "loss: 0.055081  [ 1872/ 3000]\n",
      "loss: 0.007449  [ 1880/ 3000]\n",
      "loss: 0.012589  [ 1888/ 3000]\n",
      "loss: 0.048099  [ 1896/ 3000]\n",
      "loss: 0.028407  [ 1904/ 3000]\n",
      "loss: 0.026924  [ 1912/ 3000]\n",
      "loss: 0.085588  [ 1920/ 3000]\n",
      "loss: 0.061746  [ 1928/ 3000]\n",
      "loss: 0.099695  [ 1936/ 3000]\n",
      "loss: 0.010713  [ 1944/ 3000]\n",
      "loss: 0.074311  [ 1952/ 3000]\n",
      "loss: 0.023242  [ 1960/ 3000]\n",
      "loss: 0.086096  [ 1968/ 3000]\n",
      "loss: 0.024683  [ 1976/ 3000]\n",
      "loss: 0.095212  [ 1984/ 3000]\n",
      "loss: 0.101406  [ 1992/ 3000]\n",
      "loss: 0.048138  [ 2000/ 3000]\n",
      "loss: 0.074693  [ 2008/ 3000]\n",
      "loss: 0.039367  [ 2016/ 3000]\n",
      "loss: 0.046868  [ 2024/ 3000]\n",
      "loss: 0.078390  [ 2032/ 3000]\n",
      "loss: 0.065624  [ 2040/ 3000]\n",
      "loss: 0.029514  [ 2048/ 3000]\n",
      "loss: 0.027806  [ 2056/ 3000]\n",
      "loss: 0.018692  [ 2064/ 3000]\n",
      "loss: 0.088893  [ 2072/ 3000]\n",
      "loss: 0.035843  [ 2080/ 3000]\n",
      "loss: 0.077166  [ 2088/ 3000]\n",
      "loss: 0.059678  [ 2096/ 3000]\n",
      "loss: 0.038794  [ 2104/ 3000]\n",
      "loss: 0.026931  [ 2112/ 3000]\n",
      "loss: 0.011561  [ 2120/ 3000]\n",
      "loss: 0.057789  [ 2128/ 3000]\n",
      "loss: 0.052744  [ 2136/ 3000]\n",
      "loss: 0.081612  [ 2144/ 3000]\n",
      "loss: 0.113449  [ 2152/ 3000]\n",
      "loss: 0.017649  [ 2160/ 3000]\n",
      "loss: 0.049329  [ 2168/ 3000]\n",
      "loss: 0.020679  [ 2176/ 3000]\n",
      "loss: 0.070298  [ 2184/ 3000]\n",
      "loss: 0.044251  [ 2192/ 3000]\n",
      "loss: 0.025253  [ 2200/ 3000]\n",
      "loss: 0.012625  [ 2208/ 3000]\n",
      "loss: 0.029129  [ 2216/ 3000]\n",
      "loss: 0.074881  [ 2224/ 3000]\n",
      "loss: 0.054700  [ 2232/ 3000]\n",
      "loss: 0.096168  [ 2240/ 3000]\n",
      "loss: 0.009634  [ 2248/ 3000]\n",
      "loss: 0.038499  [ 2256/ 3000]\n",
      "loss: 0.013730  [ 2264/ 3000]\n",
      "loss: 0.102674  [ 2272/ 3000]\n",
      "loss: 0.034341  [ 2280/ 3000]\n",
      "loss: 0.083337  [ 2288/ 3000]\n",
      "loss: 0.050039  [ 2296/ 3000]\n",
      "loss: 0.039120  [ 2304/ 3000]\n",
      "loss: 0.020768  [ 2312/ 3000]\n",
      "loss: 0.014636  [ 2320/ 3000]\n",
      "loss: 0.058200  [ 2328/ 3000]\n",
      "loss: 0.011114  [ 2336/ 3000]\n",
      "loss: 0.089987  [ 2344/ 3000]\n",
      "loss: 0.079549  [ 2352/ 3000]\n",
      "loss: 0.080041  [ 2360/ 3000]\n",
      "loss: 0.034497  [ 2368/ 3000]\n",
      "loss: 0.020790  [ 2376/ 3000]\n",
      "loss: 0.043474  [ 2384/ 3000]\n",
      "loss: 0.038813  [ 2392/ 3000]\n",
      "loss: 0.006713  [ 2400/ 3000]\n",
      "loss: 0.101009  [ 2408/ 3000]\n",
      "loss: 0.065994  [ 2416/ 3000]\n",
      "loss: 0.056864  [ 2424/ 3000]\n",
      "loss: 0.074376  [ 2432/ 3000]\n",
      "loss: 0.041201  [ 2440/ 3000]\n",
      "loss: 0.078857  [ 2448/ 3000]\n",
      "loss: 0.092059  [ 2456/ 3000]\n",
      "loss: 0.036215  [ 2464/ 3000]\n",
      "loss: 0.193755  [ 2472/ 3000]\n",
      "loss: 0.024112  [ 2480/ 3000]\n",
      "loss: 0.041551  [ 2488/ 3000]\n",
      "loss: 0.010540  [ 2496/ 3000]\n",
      "loss: 0.025660  [ 2504/ 3000]\n",
      "loss: 0.092226  [ 2512/ 3000]\n",
      "loss: 0.177729  [ 2520/ 3000]\n",
      "loss: 0.022590  [ 2528/ 3000]\n",
      "loss: 0.050147  [ 2536/ 3000]\n",
      "loss: 0.013805  [ 2544/ 3000]\n",
      "loss: 0.069094  [ 2552/ 3000]\n",
      "loss: 0.068950  [ 2560/ 3000]\n",
      "loss: 0.115770  [ 2568/ 3000]\n",
      "loss: 0.079409  [ 2576/ 3000]\n",
      "loss: 0.046800  [ 2584/ 3000]\n",
      "loss: 0.038274  [ 2592/ 3000]\n",
      "loss: 0.062336  [ 2600/ 3000]\n",
      "loss: 0.068016  [ 2608/ 3000]\n",
      "loss: 0.023342  [ 2616/ 3000]\n",
      "loss: 0.022500  [ 2624/ 3000]\n",
      "loss: 0.086505  [ 2632/ 3000]\n",
      "loss: 0.101626  [ 2640/ 3000]\n",
      "loss: 0.063692  [ 2648/ 3000]\n",
      "loss: 0.065486  [ 2656/ 3000]\n",
      "loss: 0.044575  [ 2664/ 3000]\n",
      "loss: 0.078198  [ 2672/ 3000]\n",
      "loss: 0.092446  [ 2680/ 3000]\n",
      "loss: 0.040457  [ 2688/ 3000]\n",
      "loss: 0.031166  [ 2696/ 3000]\n",
      "loss: 0.068784  [ 2704/ 3000]\n",
      "loss: 0.054431  [ 2712/ 3000]\n",
      "loss: 0.039474  [ 2720/ 3000]\n",
      "loss: 0.076841  [ 2728/ 3000]\n",
      "loss: 0.024334  [ 2736/ 3000]\n",
      "loss: 0.053660  [ 2744/ 3000]\n",
      "loss: 0.065527  [ 2752/ 3000]\n",
      "loss: 0.048789  [ 2760/ 3000]\n",
      "loss: 0.015381  [ 2768/ 3000]\n",
      "loss: 0.081224  [ 2776/ 3000]\n",
      "loss: 0.056790  [ 2784/ 3000]\n",
      "loss: 0.031889  [ 2792/ 3000]\n",
      "loss: 0.083509  [ 2800/ 3000]\n",
      "loss: 0.120794  [ 2808/ 3000]\n",
      "loss: 0.046394  [ 2816/ 3000]\n",
      "loss: 0.060879  [ 2824/ 3000]\n",
      "loss: 0.063956  [ 2832/ 3000]\n",
      "loss: 0.043761  [ 2840/ 3000]\n",
      "loss: 0.038524  [ 2848/ 3000]\n",
      "loss: 0.062525  [ 2856/ 3000]\n",
      "loss: 0.025308  [ 2864/ 3000]\n",
      "loss: 0.075883  [ 2872/ 3000]\n",
      "loss: 0.078678  [ 2880/ 3000]\n",
      "loss: 0.010495  [ 2888/ 3000]\n",
      "loss: 0.011670  [ 2896/ 3000]\n",
      "loss: 0.049387  [ 2904/ 3000]\n",
      "loss: 0.074616  [ 2912/ 3000]\n",
      "loss: 0.040931  [ 2920/ 3000]\n",
      "loss: 0.086279  [ 2928/ 3000]\n",
      "loss: 0.123205  [ 2936/ 3000]\n",
      "loss: 0.024129  [ 2944/ 3000]\n",
      "loss: 0.004231  [ 2952/ 3000]\n",
      "loss: 0.022697  [ 2960/ 3000]\n",
      "loss: 0.043877  [ 2968/ 3000]\n",
      "loss: 0.042861  [ 2976/ 3000]\n",
      "loss: 0.051966  [ 2984/ 3000]\n",
      "loss: 0.008138  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085299 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.023631  [    0/ 3000]\n",
      "loss: 0.057955  [    8/ 3000]\n",
      "loss: 0.016320  [   16/ 3000]\n",
      "loss: 0.022048  [   24/ 3000]\n",
      "loss: 0.081128  [   32/ 3000]\n",
      "loss: 0.012536  [   40/ 3000]\n",
      "loss: 0.017636  [   48/ 3000]\n",
      "loss: 0.062496  [   56/ 3000]\n",
      "loss: 0.115266  [   64/ 3000]\n",
      "loss: 0.018773  [   72/ 3000]\n",
      "loss: 0.120813  [   80/ 3000]\n",
      "loss: 0.058506  [   88/ 3000]\n",
      "loss: 0.082522  [   96/ 3000]\n",
      "loss: 0.030489  [  104/ 3000]\n",
      "loss: 0.134768  [  112/ 3000]\n",
      "loss: 0.028380  [  120/ 3000]\n",
      "loss: 0.032055  [  128/ 3000]\n",
      "loss: 0.061376  [  136/ 3000]\n",
      "loss: 0.060885  [  144/ 3000]\n",
      "loss: 0.033095  [  152/ 3000]\n",
      "loss: 0.016438  [  160/ 3000]\n",
      "loss: 0.010730  [  168/ 3000]\n",
      "loss: 0.021585  [  176/ 3000]\n",
      "loss: 0.069890  [  184/ 3000]\n",
      "loss: 0.039291  [  192/ 3000]\n",
      "loss: 0.030803  [  200/ 3000]\n",
      "loss: 0.131480  [  208/ 3000]\n",
      "loss: 0.030511  [  216/ 3000]\n",
      "loss: 0.041002  [  224/ 3000]\n",
      "loss: 0.105259  [  232/ 3000]\n",
      "loss: 0.049051  [  240/ 3000]\n",
      "loss: 0.029702  [  248/ 3000]\n",
      "loss: 0.023275  [  256/ 3000]\n",
      "loss: 0.060927  [  264/ 3000]\n",
      "loss: 0.044510  [  272/ 3000]\n",
      "loss: 0.143143  [  280/ 3000]\n",
      "loss: 0.020369  [  288/ 3000]\n",
      "loss: 0.047146  [  296/ 3000]\n",
      "loss: 0.030541  [  304/ 3000]\n",
      "loss: 0.084392  [  312/ 3000]\n",
      "loss: 0.033263  [  320/ 3000]\n",
      "loss: 0.092686  [  328/ 3000]\n",
      "loss: 0.030445  [  336/ 3000]\n",
      "loss: 0.073191  [  344/ 3000]\n",
      "loss: 0.016732  [  352/ 3000]\n",
      "loss: 0.025725  [  360/ 3000]\n",
      "loss: 0.098947  [  368/ 3000]\n",
      "loss: 0.015647  [  376/ 3000]\n",
      "loss: 0.081863  [  384/ 3000]\n",
      "loss: 0.041392  [  392/ 3000]\n",
      "loss: 0.068647  [  400/ 3000]\n",
      "loss: 0.029101  [  408/ 3000]\n",
      "loss: 0.076343  [  416/ 3000]\n",
      "loss: 0.035889  [  424/ 3000]\n",
      "loss: 0.136611  [  432/ 3000]\n",
      "loss: 0.029971  [  440/ 3000]\n",
      "loss: 0.061603  [  448/ 3000]\n",
      "loss: 0.036108  [  456/ 3000]\n",
      "loss: 0.086870  [  464/ 3000]\n",
      "loss: 0.054002  [  472/ 3000]\n",
      "loss: 0.014092  [  480/ 3000]\n",
      "loss: 0.104278  [  488/ 3000]\n",
      "loss: 0.081969  [  496/ 3000]\n",
      "loss: 0.032140  [  504/ 3000]\n",
      "loss: 0.057753  [  512/ 3000]\n",
      "loss: 0.037190  [  520/ 3000]\n",
      "loss: 0.163277  [  528/ 3000]\n",
      "loss: 0.077373  [  536/ 3000]\n",
      "loss: 0.068156  [  544/ 3000]\n",
      "loss: 0.039561  [  552/ 3000]\n",
      "loss: 0.030855  [  560/ 3000]\n",
      "loss: 0.072501  [  568/ 3000]\n",
      "loss: 0.043967  [  576/ 3000]\n",
      "loss: 0.049097  [  584/ 3000]\n",
      "loss: 0.026405  [  592/ 3000]\n",
      "loss: 0.110058  [  600/ 3000]\n",
      "loss: 0.029983  [  608/ 3000]\n",
      "loss: 0.072795  [  616/ 3000]\n",
      "loss: 0.048674  [  624/ 3000]\n",
      "loss: 0.149524  [  632/ 3000]\n",
      "loss: 0.014260  [  640/ 3000]\n",
      "loss: 0.115620  [  648/ 3000]\n",
      "loss: 0.156799  [  656/ 3000]\n",
      "loss: 0.134231  [  664/ 3000]\n",
      "loss: 0.056266  [  672/ 3000]\n",
      "loss: 0.067675  [  680/ 3000]\n",
      "loss: 0.044133  [  688/ 3000]\n",
      "loss: 0.137286  [  696/ 3000]\n",
      "loss: 0.059173  [  704/ 3000]\n",
      "loss: 0.038169  [  712/ 3000]\n",
      "loss: 0.048684  [  720/ 3000]\n",
      "loss: 0.026659  [  728/ 3000]\n",
      "loss: 0.051428  [  736/ 3000]\n",
      "loss: 0.021870  [  744/ 3000]\n",
      "loss: 0.071230  [  752/ 3000]\n",
      "loss: 0.053212  [  760/ 3000]\n",
      "loss: 0.105730  [  768/ 3000]\n",
      "loss: 0.053620  [  776/ 3000]\n",
      "loss: 0.123401  [  784/ 3000]\n",
      "loss: 0.055643  [  792/ 3000]\n",
      "loss: 0.147723  [  800/ 3000]\n",
      "loss: 0.051515  [  808/ 3000]\n",
      "loss: 0.026513  [  816/ 3000]\n",
      "loss: 0.042643  [  824/ 3000]\n",
      "loss: 0.046144  [  832/ 3000]\n",
      "loss: 0.018184  [  840/ 3000]\n",
      "loss: 0.016514  [  848/ 3000]\n",
      "loss: 0.021143  [  856/ 3000]\n",
      "loss: 0.070640  [  864/ 3000]\n",
      "loss: 0.009683  [  872/ 3000]\n",
      "loss: 0.066981  [  880/ 3000]\n",
      "loss: 0.076419  [  888/ 3000]\n",
      "loss: 0.062651  [  896/ 3000]\n",
      "loss: 0.153633  [  904/ 3000]\n",
      "loss: 0.051142  [  912/ 3000]\n",
      "loss: 0.052278  [  920/ 3000]\n",
      "loss: 0.059937  [  928/ 3000]\n",
      "loss: 0.033658  [  936/ 3000]\n",
      "loss: 0.135025  [  944/ 3000]\n",
      "loss: 0.024525  [  952/ 3000]\n",
      "loss: 0.043110  [  960/ 3000]\n",
      "loss: 0.020114  [  968/ 3000]\n",
      "loss: 0.009714  [  976/ 3000]\n",
      "loss: 0.011122  [  984/ 3000]\n",
      "loss: 0.100627  [  992/ 3000]\n",
      "loss: 0.057795  [ 1000/ 3000]\n",
      "loss: 0.051677  [ 1008/ 3000]\n",
      "loss: 0.093828  [ 1016/ 3000]\n",
      "loss: 0.049863  [ 1024/ 3000]\n",
      "loss: 0.082565  [ 1032/ 3000]\n",
      "loss: 0.013346  [ 1040/ 3000]\n",
      "loss: 0.033229  [ 1048/ 3000]\n",
      "loss: 0.016948  [ 1056/ 3000]\n",
      "loss: 0.058589  [ 1064/ 3000]\n",
      "loss: 0.034629  [ 1072/ 3000]\n",
      "loss: 0.040725  [ 1080/ 3000]\n",
      "loss: 0.083795  [ 1088/ 3000]\n",
      "loss: 0.071847  [ 1096/ 3000]\n",
      "loss: 0.015284  [ 1104/ 3000]\n",
      "loss: 0.078749  [ 1112/ 3000]\n",
      "loss: 0.024125  [ 1120/ 3000]\n",
      "loss: 0.042468  [ 1128/ 3000]\n",
      "loss: 0.036038  [ 1136/ 3000]\n",
      "loss: 0.092778  [ 1144/ 3000]\n",
      "loss: 0.031539  [ 1152/ 3000]\n",
      "loss: 0.023315  [ 1160/ 3000]\n",
      "loss: 0.026094  [ 1168/ 3000]\n",
      "loss: 0.021151  [ 1176/ 3000]\n",
      "loss: 0.134543  [ 1184/ 3000]\n",
      "loss: 0.048108  [ 1192/ 3000]\n",
      "loss: 0.030932  [ 1200/ 3000]\n",
      "loss: 0.033807  [ 1208/ 3000]\n",
      "loss: 0.034020  [ 1216/ 3000]\n",
      "loss: 0.062457  [ 1224/ 3000]\n",
      "loss: 0.071120  [ 1232/ 3000]\n",
      "loss: 0.064454  [ 1240/ 3000]\n",
      "loss: 0.065543  [ 1248/ 3000]\n",
      "loss: 0.008197  [ 1256/ 3000]\n",
      "loss: 0.044003  [ 1264/ 3000]\n",
      "loss: 0.019971  [ 1272/ 3000]\n",
      "loss: 0.023158  [ 1280/ 3000]\n",
      "loss: 0.049957  [ 1288/ 3000]\n",
      "loss: 0.017783  [ 1296/ 3000]\n",
      "loss: 0.002903  [ 1304/ 3000]\n",
      "loss: 0.075279  [ 1312/ 3000]\n",
      "loss: 0.194937  [ 1320/ 3000]\n",
      "loss: 0.078224  [ 1328/ 3000]\n",
      "loss: 0.063065  [ 1336/ 3000]\n",
      "loss: 0.102044  [ 1344/ 3000]\n",
      "loss: 0.068847  [ 1352/ 3000]\n",
      "loss: 0.022604  [ 1360/ 3000]\n",
      "loss: 0.098032  [ 1368/ 3000]\n",
      "loss: 0.114200  [ 1376/ 3000]\n",
      "loss: 0.048465  [ 1384/ 3000]\n",
      "loss: 0.028060  [ 1392/ 3000]\n",
      "loss: 0.070134  [ 1400/ 3000]\n",
      "loss: 0.066297  [ 1408/ 3000]\n",
      "loss: 0.068063  [ 1416/ 3000]\n",
      "loss: 0.106092  [ 1424/ 3000]\n",
      "loss: 0.047377  [ 1432/ 3000]\n",
      "loss: 0.029132  [ 1440/ 3000]\n",
      "loss: 0.026308  [ 1448/ 3000]\n",
      "loss: 0.048095  [ 1456/ 3000]\n",
      "loss: 0.006500  [ 1464/ 3000]\n",
      "loss: 0.039841  [ 1472/ 3000]\n",
      "loss: 0.020480  [ 1480/ 3000]\n",
      "loss: 0.107314  [ 1488/ 3000]\n",
      "loss: 0.023213  [ 1496/ 3000]\n",
      "loss: 0.039116  [ 1504/ 3000]\n",
      "loss: 0.068659  [ 1512/ 3000]\n",
      "loss: 0.059513  [ 1520/ 3000]\n",
      "loss: 0.020620  [ 1528/ 3000]\n",
      "loss: 0.064511  [ 1536/ 3000]\n",
      "loss: 0.021774  [ 1544/ 3000]\n",
      "loss: 0.086573  [ 1552/ 3000]\n",
      "loss: 0.034006  [ 1560/ 3000]\n",
      "loss: 0.029568  [ 1568/ 3000]\n",
      "loss: 0.018325  [ 1576/ 3000]\n",
      "loss: 0.082958  [ 1584/ 3000]\n",
      "loss: 0.046694  [ 1592/ 3000]\n",
      "loss: 0.070132  [ 1600/ 3000]\n",
      "loss: 0.029665  [ 1608/ 3000]\n",
      "loss: 0.111230  [ 1616/ 3000]\n",
      "loss: 0.087394  [ 1624/ 3000]\n",
      "loss: 0.033283  [ 1632/ 3000]\n",
      "loss: 0.034715  [ 1640/ 3000]\n",
      "loss: 0.094974  [ 1648/ 3000]\n",
      "loss: 0.029647  [ 1656/ 3000]\n",
      "loss: 0.079823  [ 1664/ 3000]\n",
      "loss: 0.014236  [ 1672/ 3000]\n",
      "loss: 0.040326  [ 1680/ 3000]\n",
      "loss: 0.046296  [ 1688/ 3000]\n",
      "loss: 0.073163  [ 1696/ 3000]\n",
      "loss: 0.036668  [ 1704/ 3000]\n",
      "loss: 0.018711  [ 1712/ 3000]\n",
      "loss: 0.023766  [ 1720/ 3000]\n",
      "loss: 0.045031  [ 1728/ 3000]\n",
      "loss: 0.066631  [ 1736/ 3000]\n",
      "loss: 0.060113  [ 1744/ 3000]\n",
      "loss: 0.014903  [ 1752/ 3000]\n",
      "loss: 0.006477  [ 1760/ 3000]\n",
      "loss: 0.076132  [ 1768/ 3000]\n",
      "loss: 0.043478  [ 1776/ 3000]\n",
      "loss: 0.020687  [ 1784/ 3000]\n",
      "loss: 0.034734  [ 1792/ 3000]\n",
      "loss: 0.069979  [ 1800/ 3000]\n",
      "loss: 0.099452  [ 1808/ 3000]\n",
      "loss: 0.027117  [ 1816/ 3000]\n",
      "loss: 0.092484  [ 1824/ 3000]\n",
      "loss: 0.003457  [ 1832/ 3000]\n",
      "loss: 0.007457  [ 1840/ 3000]\n",
      "loss: 0.037626  [ 1848/ 3000]\n",
      "loss: 0.059641  [ 1856/ 3000]\n",
      "loss: 0.055610  [ 1864/ 3000]\n",
      "loss: 0.053564  [ 1872/ 3000]\n",
      "loss: 0.007027  [ 1880/ 3000]\n",
      "loss: 0.011976  [ 1888/ 3000]\n",
      "loss: 0.046167  [ 1896/ 3000]\n",
      "loss: 0.027834  [ 1904/ 3000]\n",
      "loss: 0.025754  [ 1912/ 3000]\n",
      "loss: 0.083770  [ 1920/ 3000]\n",
      "loss: 0.059764  [ 1928/ 3000]\n",
      "loss: 0.096794  [ 1936/ 3000]\n",
      "loss: 0.010230  [ 1944/ 3000]\n",
      "loss: 0.072405  [ 1952/ 3000]\n",
      "loss: 0.022382  [ 1960/ 3000]\n",
      "loss: 0.084035  [ 1968/ 3000]\n",
      "loss: 0.023912  [ 1976/ 3000]\n",
      "loss: 0.092524  [ 1984/ 3000]\n",
      "loss: 0.098594  [ 1992/ 3000]\n",
      "loss: 0.046262  [ 2000/ 3000]\n",
      "loss: 0.072254  [ 2008/ 3000]\n",
      "loss: 0.037840  [ 2016/ 3000]\n",
      "loss: 0.045639  [ 2024/ 3000]\n",
      "loss: 0.076414  [ 2032/ 3000]\n",
      "loss: 0.063766  [ 2040/ 3000]\n",
      "loss: 0.028680  [ 2048/ 3000]\n",
      "loss: 0.026653  [ 2056/ 3000]\n",
      "loss: 0.017824  [ 2064/ 3000]\n",
      "loss: 0.086560  [ 2072/ 3000]\n",
      "loss: 0.034547  [ 2080/ 3000]\n",
      "loss: 0.074455  [ 2088/ 3000]\n",
      "loss: 0.058129  [ 2096/ 3000]\n",
      "loss: 0.037789  [ 2104/ 3000]\n",
      "loss: 0.026355  [ 2112/ 3000]\n",
      "loss: 0.011118  [ 2120/ 3000]\n",
      "loss: 0.056610  [ 2128/ 3000]\n",
      "loss: 0.051261  [ 2136/ 3000]\n",
      "loss: 0.079144  [ 2144/ 3000]\n",
      "loss: 0.110938  [ 2152/ 3000]\n",
      "loss: 0.016981  [ 2160/ 3000]\n",
      "loss: 0.047910  [ 2168/ 3000]\n",
      "loss: 0.020268  [ 2176/ 3000]\n",
      "loss: 0.068011  [ 2184/ 3000]\n",
      "loss: 0.041944  [ 2192/ 3000]\n",
      "loss: 0.024312  [ 2200/ 3000]\n",
      "loss: 0.012015  [ 2208/ 3000]\n",
      "loss: 0.028310  [ 2216/ 3000]\n",
      "loss: 0.072195  [ 2224/ 3000]\n",
      "loss: 0.052881  [ 2232/ 3000]\n",
      "loss: 0.093762  [ 2240/ 3000]\n",
      "loss: 0.009276  [ 2248/ 3000]\n",
      "loss: 0.036951  [ 2256/ 3000]\n",
      "loss: 0.013122  [ 2264/ 3000]\n",
      "loss: 0.099703  [ 2272/ 3000]\n",
      "loss: 0.033385  [ 2280/ 3000]\n",
      "loss: 0.080347  [ 2288/ 3000]\n",
      "loss: 0.048396  [ 2296/ 3000]\n",
      "loss: 0.037767  [ 2304/ 3000]\n",
      "loss: 0.020013  [ 2312/ 3000]\n",
      "loss: 0.013912  [ 2320/ 3000]\n",
      "loss: 0.056199  [ 2328/ 3000]\n",
      "loss: 0.010705  [ 2336/ 3000]\n",
      "loss: 0.087730  [ 2344/ 3000]\n",
      "loss: 0.076963  [ 2352/ 3000]\n",
      "loss: 0.077443  [ 2360/ 3000]\n",
      "loss: 0.033573  [ 2368/ 3000]\n",
      "loss: 0.020111  [ 2376/ 3000]\n",
      "loss: 0.042282  [ 2384/ 3000]\n",
      "loss: 0.037115  [ 2392/ 3000]\n",
      "loss: 0.006448  [ 2400/ 3000]\n",
      "loss: 0.098803  [ 2408/ 3000]\n",
      "loss: 0.064337  [ 2416/ 3000]\n",
      "loss: 0.054555  [ 2424/ 3000]\n",
      "loss: 0.072632  [ 2432/ 3000]\n",
      "loss: 0.040168  [ 2440/ 3000]\n",
      "loss: 0.075796  [ 2448/ 3000]\n",
      "loss: 0.089644  [ 2456/ 3000]\n",
      "loss: 0.034957  [ 2464/ 3000]\n",
      "loss: 0.189041  [ 2472/ 3000]\n",
      "loss: 0.023732  [ 2480/ 3000]\n",
      "loss: 0.040218  [ 2488/ 3000]\n",
      "loss: 0.010068  [ 2496/ 3000]\n",
      "loss: 0.024684  [ 2504/ 3000]\n",
      "loss: 0.089827  [ 2512/ 3000]\n",
      "loss: 0.173366  [ 2520/ 3000]\n",
      "loss: 0.021611  [ 2528/ 3000]\n",
      "loss: 0.048743  [ 2536/ 3000]\n",
      "loss: 0.013317  [ 2544/ 3000]\n",
      "loss: 0.066848  [ 2552/ 3000]\n",
      "loss: 0.066761  [ 2560/ 3000]\n",
      "loss: 0.113723  [ 2568/ 3000]\n",
      "loss: 0.076155  [ 2576/ 3000]\n",
      "loss: 0.045195  [ 2584/ 3000]\n",
      "loss: 0.037219  [ 2592/ 3000]\n",
      "loss: 0.061214  [ 2600/ 3000]\n",
      "loss: 0.066289  [ 2608/ 3000]\n",
      "loss: 0.022624  [ 2616/ 3000]\n",
      "loss: 0.021579  [ 2624/ 3000]\n",
      "loss: 0.083986  [ 2632/ 3000]\n",
      "loss: 0.099370  [ 2640/ 3000]\n",
      "loss: 0.062038  [ 2648/ 3000]\n",
      "loss: 0.063603  [ 2656/ 3000]\n",
      "loss: 0.043193  [ 2664/ 3000]\n",
      "loss: 0.075312  [ 2672/ 3000]\n",
      "loss: 0.089683  [ 2680/ 3000]\n",
      "loss: 0.039184  [ 2688/ 3000]\n",
      "loss: 0.030079  [ 2696/ 3000]\n",
      "loss: 0.067161  [ 2704/ 3000]\n",
      "loss: 0.052151  [ 2712/ 3000]\n",
      "loss: 0.037665  [ 2720/ 3000]\n",
      "loss: 0.073874  [ 2728/ 3000]\n",
      "loss: 0.023725  [ 2736/ 3000]\n",
      "loss: 0.052322  [ 2744/ 3000]\n",
      "loss: 0.063605  [ 2752/ 3000]\n",
      "loss: 0.047454  [ 2760/ 3000]\n",
      "loss: 0.014802  [ 2768/ 3000]\n",
      "loss: 0.077948  [ 2776/ 3000]\n",
      "loss: 0.055108  [ 2784/ 3000]\n",
      "loss: 0.030705  [ 2792/ 3000]\n",
      "loss: 0.081242  [ 2800/ 3000]\n",
      "loss: 0.117481  [ 2808/ 3000]\n",
      "loss: 0.044793  [ 2816/ 3000]\n",
      "loss: 0.058818  [ 2824/ 3000]\n",
      "loss: 0.062136  [ 2832/ 3000]\n",
      "loss: 0.042344  [ 2840/ 3000]\n",
      "loss: 0.036955  [ 2848/ 3000]\n",
      "loss: 0.060581  [ 2856/ 3000]\n",
      "loss: 0.024449  [ 2864/ 3000]\n",
      "loss: 0.074328  [ 2872/ 3000]\n",
      "loss: 0.075931  [ 2880/ 3000]\n",
      "loss: 0.010032  [ 2888/ 3000]\n",
      "loss: 0.011345  [ 2896/ 3000]\n",
      "loss: 0.047887  [ 2904/ 3000]\n",
      "loss: 0.072323  [ 2912/ 3000]\n",
      "loss: 0.038738  [ 2920/ 3000]\n",
      "loss: 0.083827  [ 2928/ 3000]\n",
      "loss: 0.118524  [ 2936/ 3000]\n",
      "loss: 0.023437  [ 2944/ 3000]\n",
      "loss: 0.004104  [ 2952/ 3000]\n",
      "loss: 0.021841  [ 2960/ 3000]\n",
      "loss: 0.042049  [ 2968/ 3000]\n",
      "loss: 0.041618  [ 2976/ 3000]\n",
      "loss: 0.050333  [ 2984/ 3000]\n",
      "loss: 0.007790  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085320 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.023075  [    0/ 3000]\n",
      "loss: 0.056529  [    8/ 3000]\n",
      "loss: 0.015690  [   16/ 3000]\n",
      "loss: 0.021149  [   24/ 3000]\n",
      "loss: 0.078542  [   32/ 3000]\n",
      "loss: 0.012014  [   40/ 3000]\n",
      "loss: 0.016942  [   48/ 3000]\n",
      "loss: 0.060659  [   56/ 3000]\n",
      "loss: 0.111344  [   64/ 3000]\n",
      "loss: 0.018316  [   72/ 3000]\n",
      "loss: 0.117496  [   80/ 3000]\n",
      "loss: 0.056169  [   88/ 3000]\n",
      "loss: 0.080676  [   96/ 3000]\n",
      "loss: 0.028811  [  104/ 3000]\n",
      "loss: 0.131422  [  112/ 3000]\n",
      "loss: 0.027372  [  120/ 3000]\n",
      "loss: 0.031872  [  128/ 3000]\n",
      "loss: 0.058948  [  136/ 3000]\n",
      "loss: 0.058830  [  144/ 3000]\n",
      "loss: 0.031876  [  152/ 3000]\n",
      "loss: 0.015935  [  160/ 3000]\n",
      "loss: 0.010374  [  168/ 3000]\n",
      "loss: 0.020563  [  176/ 3000]\n",
      "loss: 0.067588  [  184/ 3000]\n",
      "loss: 0.037689  [  192/ 3000]\n",
      "loss: 0.029964  [  200/ 3000]\n",
      "loss: 0.127753  [  208/ 3000]\n",
      "loss: 0.029146  [  216/ 3000]\n",
      "loss: 0.039304  [  224/ 3000]\n",
      "loss: 0.103042  [  232/ 3000]\n",
      "loss: 0.047942  [  240/ 3000]\n",
      "loss: 0.028197  [  248/ 3000]\n",
      "loss: 0.022570  [  256/ 3000]\n",
      "loss: 0.058426  [  264/ 3000]\n",
      "loss: 0.043764  [  272/ 3000]\n",
      "loss: 0.140029  [  280/ 3000]\n",
      "loss: 0.019610  [  288/ 3000]\n",
      "loss: 0.046140  [  296/ 3000]\n",
      "loss: 0.029623  [  304/ 3000]\n",
      "loss: 0.081373  [  312/ 3000]\n",
      "loss: 0.031925  [  320/ 3000]\n",
      "loss: 0.088884  [  328/ 3000]\n",
      "loss: 0.029389  [  336/ 3000]\n",
      "loss: 0.071107  [  344/ 3000]\n",
      "loss: 0.016207  [  352/ 3000]\n",
      "loss: 0.024644  [  360/ 3000]\n",
      "loss: 0.095986  [  368/ 3000]\n",
      "loss: 0.014866  [  376/ 3000]\n",
      "loss: 0.080446  [  384/ 3000]\n",
      "loss: 0.040025  [  392/ 3000]\n",
      "loss: 0.066588  [  400/ 3000]\n",
      "loss: 0.028516  [  408/ 3000]\n",
      "loss: 0.074212  [  416/ 3000]\n",
      "loss: 0.034548  [  424/ 3000]\n",
      "loss: 0.132865  [  432/ 3000]\n",
      "loss: 0.028845  [  440/ 3000]\n",
      "loss: 0.059930  [  448/ 3000]\n",
      "loss: 0.035000  [  456/ 3000]\n",
      "loss: 0.083447  [  464/ 3000]\n",
      "loss: 0.053047  [  472/ 3000]\n",
      "loss: 0.013635  [  480/ 3000]\n",
      "loss: 0.101068  [  488/ 3000]\n",
      "loss: 0.079996  [  496/ 3000]\n",
      "loss: 0.031162  [  504/ 3000]\n",
      "loss: 0.056109  [  512/ 3000]\n",
      "loss: 0.036383  [  520/ 3000]\n",
      "loss: 0.158639  [  528/ 3000]\n",
      "loss: 0.074951  [  536/ 3000]\n",
      "loss: 0.066074  [  544/ 3000]\n",
      "loss: 0.038055  [  552/ 3000]\n",
      "loss: 0.029817  [  560/ 3000]\n",
      "loss: 0.070136  [  568/ 3000]\n",
      "loss: 0.042670  [  576/ 3000]\n",
      "loss: 0.047369  [  584/ 3000]\n",
      "loss: 0.025383  [  592/ 3000]\n",
      "loss: 0.107193  [  600/ 3000]\n",
      "loss: 0.028746  [  608/ 3000]\n",
      "loss: 0.070425  [  616/ 3000]\n",
      "loss: 0.046906  [  624/ 3000]\n",
      "loss: 0.145000  [  632/ 3000]\n",
      "loss: 0.013911  [  640/ 3000]\n",
      "loss: 0.112329  [  648/ 3000]\n",
      "loss: 0.152636  [  656/ 3000]\n",
      "loss: 0.130751  [  664/ 3000]\n",
      "loss: 0.054636  [  672/ 3000]\n",
      "loss: 0.065737  [  680/ 3000]\n",
      "loss: 0.042710  [  688/ 3000]\n",
      "loss: 0.133777  [  696/ 3000]\n",
      "loss: 0.057930  [  704/ 3000]\n",
      "loss: 0.036939  [  712/ 3000]\n",
      "loss: 0.047313  [  720/ 3000]\n",
      "loss: 0.025741  [  728/ 3000]\n",
      "loss: 0.049914  [  736/ 3000]\n",
      "loss: 0.020817  [  744/ 3000]\n",
      "loss: 0.069182  [  752/ 3000]\n",
      "loss: 0.051691  [  760/ 3000]\n",
      "loss: 0.103409  [  768/ 3000]\n",
      "loss: 0.052393  [  776/ 3000]\n",
      "loss: 0.120195  [  784/ 3000]\n",
      "loss: 0.053296  [  792/ 3000]\n",
      "loss: 0.144991  [  800/ 3000]\n",
      "loss: 0.050335  [  808/ 3000]\n",
      "loss: 0.025731  [  816/ 3000]\n",
      "loss: 0.041375  [  824/ 3000]\n",
      "loss: 0.044629  [  832/ 3000]\n",
      "loss: 0.017540  [  840/ 3000]\n",
      "loss: 0.016151  [  848/ 3000]\n",
      "loss: 0.020280  [  856/ 3000]\n",
      "loss: 0.068756  [  864/ 3000]\n",
      "loss: 0.009281  [  872/ 3000]\n",
      "loss: 0.065060  [  880/ 3000]\n",
      "loss: 0.074091  [  888/ 3000]\n",
      "loss: 0.061679  [  896/ 3000]\n",
      "loss: 0.149327  [  904/ 3000]\n",
      "loss: 0.050431  [  912/ 3000]\n",
      "loss: 0.050889  [  920/ 3000]\n",
      "loss: 0.058340  [  928/ 3000]\n",
      "loss: 0.032111  [  936/ 3000]\n",
      "loss: 0.130877  [  944/ 3000]\n",
      "loss: 0.023489  [  952/ 3000]\n",
      "loss: 0.042036  [  960/ 3000]\n",
      "loss: 0.019241  [  968/ 3000]\n",
      "loss: 0.009335  [  976/ 3000]\n",
      "loss: 0.010659  [  984/ 3000]\n",
      "loss: 0.097834  [  992/ 3000]\n",
      "loss: 0.055768  [ 1000/ 3000]\n",
      "loss: 0.050129  [ 1008/ 3000]\n",
      "loss: 0.090972  [ 1016/ 3000]\n",
      "loss: 0.048115  [ 1024/ 3000]\n",
      "loss: 0.080209  [ 1032/ 3000]\n",
      "loss: 0.012902  [ 1040/ 3000]\n",
      "loss: 0.032000  [ 1048/ 3000]\n",
      "loss: 0.016291  [ 1056/ 3000]\n",
      "loss: 0.056426  [ 1064/ 3000]\n",
      "loss: 0.033386  [ 1072/ 3000]\n",
      "loss: 0.039306  [ 1080/ 3000]\n",
      "loss: 0.081394  [ 1088/ 3000]\n",
      "loss: 0.069135  [ 1096/ 3000]\n",
      "loss: 0.014702  [ 1104/ 3000]\n",
      "loss: 0.076005  [ 1112/ 3000]\n",
      "loss: 0.023300  [ 1120/ 3000]\n",
      "loss: 0.041463  [ 1128/ 3000]\n",
      "loss: 0.034674  [ 1136/ 3000]\n",
      "loss: 0.088637  [ 1144/ 3000]\n",
      "loss: 0.030479  [ 1152/ 3000]\n",
      "loss: 0.022379  [ 1160/ 3000]\n",
      "loss: 0.025258  [ 1168/ 3000]\n",
      "loss: 0.020377  [ 1176/ 3000]\n",
      "loss: 0.130116  [ 1184/ 3000]\n",
      "loss: 0.046706  [ 1192/ 3000]\n",
      "loss: 0.029490  [ 1200/ 3000]\n",
      "loss: 0.033120  [ 1208/ 3000]\n",
      "loss: 0.032616  [ 1216/ 3000]\n",
      "loss: 0.060591  [ 1224/ 3000]\n",
      "loss: 0.068911  [ 1232/ 3000]\n",
      "loss: 0.062413  [ 1240/ 3000]\n",
      "loss: 0.062625  [ 1248/ 3000]\n",
      "loss: 0.007765  [ 1256/ 3000]\n",
      "loss: 0.043154  [ 1264/ 3000]\n",
      "loss: 0.019255  [ 1272/ 3000]\n",
      "loss: 0.022201  [ 1280/ 3000]\n",
      "loss: 0.047947  [ 1288/ 3000]\n",
      "loss: 0.016875  [ 1296/ 3000]\n",
      "loss: 0.002758  [ 1304/ 3000]\n",
      "loss: 0.072646  [ 1312/ 3000]\n",
      "loss: 0.188508  [ 1320/ 3000]\n",
      "loss: 0.076019  [ 1328/ 3000]\n",
      "loss: 0.061847  [ 1336/ 3000]\n",
      "loss: 0.098820  [ 1344/ 3000]\n",
      "loss: 0.067305  [ 1352/ 3000]\n",
      "loss: 0.021523  [ 1360/ 3000]\n",
      "loss: 0.095759  [ 1368/ 3000]\n",
      "loss: 0.111445  [ 1376/ 3000]\n",
      "loss: 0.046465  [ 1384/ 3000]\n",
      "loss: 0.026797  [ 1392/ 3000]\n",
      "loss: 0.068118  [ 1400/ 3000]\n",
      "loss: 0.064316  [ 1408/ 3000]\n",
      "loss: 0.066045  [ 1416/ 3000]\n",
      "loss: 0.103385  [ 1424/ 3000]\n",
      "loss: 0.045446  [ 1432/ 3000]\n",
      "loss: 0.028113  [ 1440/ 3000]\n",
      "loss: 0.025233  [ 1448/ 3000]\n",
      "loss: 0.046668  [ 1456/ 3000]\n",
      "loss: 0.006281  [ 1464/ 3000]\n",
      "loss: 0.038982  [ 1472/ 3000]\n",
      "loss: 0.020157  [ 1480/ 3000]\n",
      "loss: 0.104049  [ 1488/ 3000]\n",
      "loss: 0.022487  [ 1496/ 3000]\n",
      "loss: 0.037855  [ 1504/ 3000]\n",
      "loss: 0.066482  [ 1512/ 3000]\n",
      "loss: 0.057690  [ 1520/ 3000]\n",
      "loss: 0.019806  [ 1528/ 3000]\n",
      "loss: 0.062588  [ 1536/ 3000]\n",
      "loss: 0.020454  [ 1544/ 3000]\n",
      "loss: 0.083896  [ 1552/ 3000]\n",
      "loss: 0.032912  [ 1560/ 3000]\n",
      "loss: 0.028468  [ 1568/ 3000]\n",
      "loss: 0.017663  [ 1576/ 3000]\n",
      "loss: 0.080954  [ 1584/ 3000]\n",
      "loss: 0.045692  [ 1592/ 3000]\n",
      "loss: 0.068003  [ 1600/ 3000]\n",
      "loss: 0.028582  [ 1608/ 3000]\n",
      "loss: 0.108642  [ 1616/ 3000]\n",
      "loss: 0.085076  [ 1624/ 3000]\n",
      "loss: 0.031890  [ 1632/ 3000]\n",
      "loss: 0.033219  [ 1640/ 3000]\n",
      "loss: 0.092238  [ 1648/ 3000]\n",
      "loss: 0.028577  [ 1656/ 3000]\n",
      "loss: 0.076334  [ 1664/ 3000]\n",
      "loss: 0.013546  [ 1672/ 3000]\n",
      "loss: 0.039378  [ 1680/ 3000]\n",
      "loss: 0.044836  [ 1688/ 3000]\n",
      "loss: 0.071285  [ 1696/ 3000]\n",
      "loss: 0.035016  [ 1704/ 3000]\n",
      "loss: 0.017992  [ 1712/ 3000]\n",
      "loss: 0.022877  [ 1720/ 3000]\n",
      "loss: 0.043620  [ 1728/ 3000]\n",
      "loss: 0.064525  [ 1736/ 3000]\n",
      "loss: 0.058393  [ 1744/ 3000]\n",
      "loss: 0.014513  [ 1752/ 3000]\n",
      "loss: 0.006207  [ 1760/ 3000]\n",
      "loss: 0.073210  [ 1768/ 3000]\n",
      "loss: 0.041633  [ 1776/ 3000]\n",
      "loss: 0.019981  [ 1784/ 3000]\n",
      "loss: 0.033390  [ 1792/ 3000]\n",
      "loss: 0.067885  [ 1800/ 3000]\n",
      "loss: 0.096691  [ 1808/ 3000]\n",
      "loss: 0.026184  [ 1816/ 3000]\n",
      "loss: 0.089108  [ 1824/ 3000]\n",
      "loss: 0.003232  [ 1832/ 3000]\n",
      "loss: 0.007194  [ 1840/ 3000]\n",
      "loss: 0.036205  [ 1848/ 3000]\n",
      "loss: 0.057891  [ 1856/ 3000]\n",
      "loss: 0.053699  [ 1864/ 3000]\n",
      "loss: 0.051987  [ 1872/ 3000]\n",
      "loss: 0.006617  [ 1880/ 3000]\n",
      "loss: 0.011396  [ 1888/ 3000]\n",
      "loss: 0.044341  [ 1896/ 3000]\n",
      "loss: 0.027261  [ 1904/ 3000]\n",
      "loss: 0.024632  [ 1912/ 3000]\n",
      "loss: 0.081929  [ 1920/ 3000]\n",
      "loss: 0.057700  [ 1928/ 3000]\n",
      "loss: 0.093934  [ 1936/ 3000]\n",
      "loss: 0.009794  [ 1944/ 3000]\n",
      "loss: 0.070499  [ 1952/ 3000]\n",
      "loss: 0.021610  [ 1960/ 3000]\n",
      "loss: 0.081941  [ 1968/ 3000]\n",
      "loss: 0.023121  [ 1976/ 3000]\n",
      "loss: 0.089899  [ 1984/ 3000]\n",
      "loss: 0.095874  [ 1992/ 3000]\n",
      "loss: 0.044443  [ 2000/ 3000]\n",
      "loss: 0.069875  [ 2008/ 3000]\n",
      "loss: 0.036402  [ 2016/ 3000]\n",
      "loss: 0.044401  [ 2024/ 3000]\n",
      "loss: 0.074539  [ 2032/ 3000]\n",
      "loss: 0.062015  [ 2040/ 3000]\n",
      "loss: 0.027813  [ 2048/ 3000]\n",
      "loss: 0.025420  [ 2056/ 3000]\n",
      "loss: 0.017044  [ 2064/ 3000]\n",
      "loss: 0.084363  [ 2072/ 3000]\n",
      "loss: 0.033327  [ 2080/ 3000]\n",
      "loss: 0.071857  [ 2088/ 3000]\n",
      "loss: 0.056602  [ 2096/ 3000]\n",
      "loss: 0.036773  [ 2104/ 3000]\n",
      "loss: 0.025794  [ 2112/ 3000]\n",
      "loss: 0.010708  [ 2120/ 3000]\n",
      "loss: 0.055257  [ 2128/ 3000]\n",
      "loss: 0.049755  [ 2136/ 3000]\n",
      "loss: 0.076632  [ 2144/ 3000]\n",
      "loss: 0.108466  [ 2152/ 3000]\n",
      "loss: 0.016337  [ 2160/ 3000]\n",
      "loss: 0.046543  [ 2168/ 3000]\n",
      "loss: 0.019854  [ 2176/ 3000]\n",
      "loss: 0.065777  [ 2184/ 3000]\n",
      "loss: 0.039715  [ 2192/ 3000]\n",
      "loss: 0.023397  [ 2200/ 3000]\n",
      "loss: 0.011450  [ 2208/ 3000]\n",
      "loss: 0.027454  [ 2216/ 3000]\n",
      "loss: 0.069515  [ 2224/ 3000]\n",
      "loss: 0.051127  [ 2232/ 3000]\n",
      "loss: 0.091324  [ 2240/ 3000]\n",
      "loss: 0.008941  [ 2248/ 3000]\n",
      "loss: 0.035299  [ 2256/ 3000]\n",
      "loss: 0.012519  [ 2264/ 3000]\n",
      "loss: 0.096766  [ 2272/ 3000]\n",
      "loss: 0.032413  [ 2280/ 3000]\n",
      "loss: 0.077461  [ 2288/ 3000]\n",
      "loss: 0.046758  [ 2296/ 3000]\n",
      "loss: 0.036394  [ 2304/ 3000]\n",
      "loss: 0.019252  [ 2312/ 3000]\n",
      "loss: 0.013225  [ 2320/ 3000]\n",
      "loss: 0.054372  [ 2328/ 3000]\n",
      "loss: 0.010294  [ 2336/ 3000]\n",
      "loss: 0.085382  [ 2344/ 3000]\n",
      "loss: 0.074434  [ 2352/ 3000]\n",
      "loss: 0.074844  [ 2360/ 3000]\n",
      "loss: 0.032640  [ 2368/ 3000]\n",
      "loss: 0.019433  [ 2376/ 3000]\n",
      "loss: 0.041078  [ 2384/ 3000]\n",
      "loss: 0.035453  [ 2392/ 3000]\n",
      "loss: 0.006216  [ 2400/ 3000]\n",
      "loss: 0.096530  [ 2408/ 3000]\n",
      "loss: 0.062725  [ 2416/ 3000]\n",
      "loss: 0.052288  [ 2424/ 3000]\n",
      "loss: 0.070890  [ 2432/ 3000]\n",
      "loss: 0.038999  [ 2440/ 3000]\n",
      "loss: 0.072714  [ 2448/ 3000]\n",
      "loss: 0.087050  [ 2456/ 3000]\n",
      "loss: 0.033755  [ 2464/ 3000]\n",
      "loss: 0.184235  [ 2472/ 3000]\n",
      "loss: 0.023398  [ 2480/ 3000]\n",
      "loss: 0.038999  [ 2488/ 3000]\n",
      "loss: 0.009616  [ 2496/ 3000]\n",
      "loss: 0.023765  [ 2504/ 3000]\n",
      "loss: 0.087395  [ 2512/ 3000]\n",
      "loss: 0.169078  [ 2520/ 3000]\n",
      "loss: 0.020633  [ 2528/ 3000]\n",
      "loss: 0.047322  [ 2536/ 3000]\n",
      "loss: 0.012893  [ 2544/ 3000]\n",
      "loss: 0.064628  [ 2552/ 3000]\n",
      "loss: 0.064553  [ 2560/ 3000]\n",
      "loss: 0.111617  [ 2568/ 3000]\n",
      "loss: 0.073113  [ 2576/ 3000]\n",
      "loss: 0.043669  [ 2584/ 3000]\n",
      "loss: 0.036215  [ 2592/ 3000]\n",
      "loss: 0.060198  [ 2600/ 3000]\n",
      "loss: 0.064531  [ 2608/ 3000]\n",
      "loss: 0.021948  [ 2616/ 3000]\n",
      "loss: 0.020731  [ 2624/ 3000]\n",
      "loss: 0.081448  [ 2632/ 3000]\n",
      "loss: 0.097131  [ 2640/ 3000]\n",
      "loss: 0.060322  [ 2648/ 3000]\n",
      "loss: 0.061786  [ 2656/ 3000]\n",
      "loss: 0.041882  [ 2664/ 3000]\n",
      "loss: 0.072667  [ 2672/ 3000]\n",
      "loss: 0.087025  [ 2680/ 3000]\n",
      "loss: 0.037846  [ 2688/ 3000]\n",
      "loss: 0.029137  [ 2696/ 3000]\n",
      "loss: 0.065530  [ 2704/ 3000]\n",
      "loss: 0.049886  [ 2712/ 3000]\n",
      "loss: 0.036010  [ 2720/ 3000]\n",
      "loss: 0.070979  [ 2728/ 3000]\n",
      "loss: 0.023088  [ 2736/ 3000]\n",
      "loss: 0.050979  [ 2744/ 3000]\n",
      "loss: 0.061853  [ 2752/ 3000]\n",
      "loss: 0.046167  [ 2760/ 3000]\n",
      "loss: 0.014193  [ 2768/ 3000]\n",
      "loss: 0.074683  [ 2776/ 3000]\n",
      "loss: 0.053278  [ 2784/ 3000]\n",
      "loss: 0.029566  [ 2792/ 3000]\n",
      "loss: 0.079038  [ 2800/ 3000]\n",
      "loss: 0.114291  [ 2808/ 3000]\n",
      "loss: 0.043290  [ 2816/ 3000]\n",
      "loss: 0.056774  [ 2824/ 3000]\n",
      "loss: 0.060450  [ 2832/ 3000]\n",
      "loss: 0.040960  [ 2840/ 3000]\n",
      "loss: 0.035400  [ 2848/ 3000]\n",
      "loss: 0.058683  [ 2856/ 3000]\n",
      "loss: 0.023626  [ 2864/ 3000]\n",
      "loss: 0.072641  [ 2872/ 3000]\n",
      "loss: 0.073209  [ 2880/ 3000]\n",
      "loss: 0.009612  [ 2888/ 3000]\n",
      "loss: 0.011005  [ 2896/ 3000]\n",
      "loss: 0.046446  [ 2904/ 3000]\n",
      "loss: 0.069912  [ 2912/ 3000]\n",
      "loss: 0.036690  [ 2920/ 3000]\n",
      "loss: 0.081519  [ 2928/ 3000]\n",
      "loss: 0.113829  [ 2936/ 3000]\n",
      "loss: 0.022782  [ 2944/ 3000]\n",
      "loss: 0.003971  [ 2952/ 3000]\n",
      "loss: 0.021066  [ 2960/ 3000]\n",
      "loss: 0.040293  [ 2968/ 3000]\n",
      "loss: 0.040412  [ 2976/ 3000]\n",
      "loss: 0.048667  [ 2984/ 3000]\n",
      "loss: 0.007457  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085364 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.022494  [    0/ 3000]\n",
      "loss: 0.055049  [    8/ 3000]\n",
      "loss: 0.015110  [   16/ 3000]\n",
      "loss: 0.020202  [   24/ 3000]\n",
      "loss: 0.076016  [   32/ 3000]\n",
      "loss: 0.011521  [   40/ 3000]\n",
      "loss: 0.016200  [   48/ 3000]\n",
      "loss: 0.058938  [   56/ 3000]\n",
      "loss: 0.107440  [   64/ 3000]\n",
      "loss: 0.017825  [   72/ 3000]\n",
      "loss: 0.114065  [   80/ 3000]\n",
      "loss: 0.053945  [   88/ 3000]\n",
      "loss: 0.078847  [   96/ 3000]\n",
      "loss: 0.027226  [  104/ 3000]\n",
      "loss: 0.128058  [  112/ 3000]\n",
      "loss: 0.026381  [  120/ 3000]\n",
      "loss: 0.031740  [  128/ 3000]\n",
      "loss: 0.056608  [  136/ 3000]\n",
      "loss: 0.056777  [  144/ 3000]\n",
      "loss: 0.030703  [  152/ 3000]\n",
      "loss: 0.015477  [  160/ 3000]\n",
      "loss: 0.009984  [  168/ 3000]\n",
      "loss: 0.019505  [  176/ 3000]\n",
      "loss: 0.065298  [  184/ 3000]\n",
      "loss: 0.036062  [  192/ 3000]\n",
      "loss: 0.029095  [  200/ 3000]\n",
      "loss: 0.124073  [  208/ 3000]\n",
      "loss: 0.027910  [  216/ 3000]\n",
      "loss: 0.037545  [  224/ 3000]\n",
      "loss: 0.100747  [  232/ 3000]\n",
      "loss: 0.046904  [  240/ 3000]\n",
      "loss: 0.026682  [  248/ 3000]\n",
      "loss: 0.021876  [  256/ 3000]\n",
      "loss: 0.055922  [  264/ 3000]\n",
      "loss: 0.043043  [  272/ 3000]\n",
      "loss: 0.136879  [  280/ 3000]\n",
      "loss: 0.018884  [  288/ 3000]\n",
      "loss: 0.045113  [  296/ 3000]\n",
      "loss: 0.028677  [  304/ 3000]\n",
      "loss: 0.078336  [  312/ 3000]\n",
      "loss: 0.030629  [  320/ 3000]\n",
      "loss: 0.085412  [  328/ 3000]\n",
      "loss: 0.028333  [  336/ 3000]\n",
      "loss: 0.068971  [  344/ 3000]\n",
      "loss: 0.015638  [  352/ 3000]\n",
      "loss: 0.023545  [  360/ 3000]\n",
      "loss: 0.093035  [  368/ 3000]\n",
      "loss: 0.014083  [  376/ 3000]\n",
      "loss: 0.079046  [  384/ 3000]\n",
      "loss: 0.038604  [  392/ 3000]\n",
      "loss: 0.064554  [  400/ 3000]\n",
      "loss: 0.028021  [  408/ 3000]\n",
      "loss: 0.072193  [  416/ 3000]\n",
      "loss: 0.033218  [  424/ 3000]\n",
      "loss: 0.129116  [  432/ 3000]\n",
      "loss: 0.027806  [  440/ 3000]\n",
      "loss: 0.058252  [  448/ 3000]\n",
      "loss: 0.034034  [  456/ 3000]\n",
      "loss: 0.079961  [  464/ 3000]\n",
      "loss: 0.052049  [  472/ 3000]\n",
      "loss: 0.013216  [  480/ 3000]\n",
      "loss: 0.097944  [  488/ 3000]\n",
      "loss: 0.078029  [  496/ 3000]\n",
      "loss: 0.030158  [  504/ 3000]\n",
      "loss: 0.054498  [  512/ 3000]\n",
      "loss: 0.035571  [  520/ 3000]\n",
      "loss: 0.153947  [  528/ 3000]\n",
      "loss: 0.072524  [  536/ 3000]\n",
      "loss: 0.063981  [  544/ 3000]\n",
      "loss: 0.036586  [  552/ 3000]\n",
      "loss: 0.028800  [  560/ 3000]\n",
      "loss: 0.067825  [  568/ 3000]\n",
      "loss: 0.041481  [  576/ 3000]\n",
      "loss: 0.045688  [  584/ 3000]\n",
      "loss: 0.024373  [  592/ 3000]\n",
      "loss: 0.104330  [  600/ 3000]\n",
      "loss: 0.027458  [  608/ 3000]\n",
      "loss: 0.068075  [  616/ 3000]\n",
      "loss: 0.045155  [  624/ 3000]\n",
      "loss: 0.140538  [  632/ 3000]\n",
      "loss: 0.013604  [  640/ 3000]\n",
      "loss: 0.109053  [  648/ 3000]\n",
      "loss: 0.148453  [  656/ 3000]\n",
      "loss: 0.127099  [  664/ 3000]\n",
      "loss: 0.053078  [  672/ 3000]\n",
      "loss: 0.063926  [  680/ 3000]\n",
      "loss: 0.041413  [  688/ 3000]\n",
      "loss: 0.130332  [  696/ 3000]\n",
      "loss: 0.056615  [  704/ 3000]\n",
      "loss: 0.035719  [  712/ 3000]\n",
      "loss: 0.045888  [  720/ 3000]\n",
      "loss: 0.024871  [  728/ 3000]\n",
      "loss: 0.048403  [  736/ 3000]\n",
      "loss: 0.019840  [  744/ 3000]\n",
      "loss: 0.067104  [  752/ 3000]\n",
      "loss: 0.050257  [  760/ 3000]\n",
      "loss: 0.100927  [  768/ 3000]\n",
      "loss: 0.051267  [  776/ 3000]\n",
      "loss: 0.117011  [  784/ 3000]\n",
      "loss: 0.051062  [  792/ 3000]\n",
      "loss: 0.142126  [  800/ 3000]\n",
      "loss: 0.049161  [  808/ 3000]\n",
      "loss: 0.024932  [  816/ 3000]\n",
      "loss: 0.040141  [  824/ 3000]\n",
      "loss: 0.043124  [  832/ 3000]\n",
      "loss: 0.016940  [  840/ 3000]\n",
      "loss: 0.015741  [  848/ 3000]\n",
      "loss: 0.019439  [  856/ 3000]\n",
      "loss: 0.066826  [  864/ 3000]\n",
      "loss: 0.008862  [  872/ 3000]\n",
      "loss: 0.063035  [  880/ 3000]\n",
      "loss: 0.071667  [  888/ 3000]\n",
      "loss: 0.060730  [  896/ 3000]\n",
      "loss: 0.145057  [  904/ 3000]\n",
      "loss: 0.049833  [  912/ 3000]\n",
      "loss: 0.049483  [  920/ 3000]\n",
      "loss: 0.056803  [  928/ 3000]\n",
      "loss: 0.030718  [  936/ 3000]\n",
      "loss: 0.126670  [  944/ 3000]\n",
      "loss: 0.022501  [  952/ 3000]\n",
      "loss: 0.041069  [  960/ 3000]\n",
      "loss: 0.018408  [  968/ 3000]\n",
      "loss: 0.008963  [  976/ 3000]\n",
      "loss: 0.010215  [  984/ 3000]\n",
      "loss: 0.095165  [  992/ 3000]\n",
      "loss: 0.053761  [ 1000/ 3000]\n",
      "loss: 0.048598  [ 1008/ 3000]\n",
      "loss: 0.088202  [ 1016/ 3000]\n",
      "loss: 0.046307  [ 1024/ 3000]\n",
      "loss: 0.077955  [ 1032/ 3000]\n",
      "loss: 0.012461  [ 1040/ 3000]\n",
      "loss: 0.030762  [ 1048/ 3000]\n",
      "loss: 0.015645  [ 1056/ 3000]\n",
      "loss: 0.054357  [ 1064/ 3000]\n",
      "loss: 0.032182  [ 1072/ 3000]\n",
      "loss: 0.037918  [ 1080/ 3000]\n",
      "loss: 0.078927  [ 1088/ 3000]\n",
      "loss: 0.066373  [ 1096/ 3000]\n",
      "loss: 0.014166  [ 1104/ 3000]\n",
      "loss: 0.073327  [ 1112/ 3000]\n",
      "loss: 0.022503  [ 1120/ 3000]\n",
      "loss: 0.040428  [ 1128/ 3000]\n",
      "loss: 0.033429  [ 1136/ 3000]\n",
      "loss: 0.084652  [ 1144/ 3000]\n",
      "loss: 0.029415  [ 1152/ 3000]\n",
      "loss: 0.021459  [ 1160/ 3000]\n",
      "loss: 0.024446  [ 1168/ 3000]\n",
      "loss: 0.019675  [ 1176/ 3000]\n",
      "loss: 0.125722  [ 1184/ 3000]\n",
      "loss: 0.045348  [ 1192/ 3000]\n",
      "loss: 0.028061  [ 1200/ 3000]\n",
      "loss: 0.032443  [ 1208/ 3000]\n",
      "loss: 0.031227  [ 1216/ 3000]\n",
      "loss: 0.058797  [ 1224/ 3000]\n",
      "loss: 0.066740  [ 1232/ 3000]\n",
      "loss: 0.060435  [ 1240/ 3000]\n",
      "loss: 0.059709  [ 1248/ 3000]\n",
      "loss: 0.007361  [ 1256/ 3000]\n",
      "loss: 0.042313  [ 1264/ 3000]\n",
      "loss: 0.018570  [ 1272/ 3000]\n",
      "loss: 0.021332  [ 1280/ 3000]\n",
      "loss: 0.046066  [ 1288/ 3000]\n",
      "loss: 0.016015  [ 1296/ 3000]\n",
      "loss: 0.002620  [ 1304/ 3000]\n",
      "loss: 0.070082  [ 1312/ 3000]\n",
      "loss: 0.182138  [ 1320/ 3000]\n",
      "loss: 0.073873  [ 1328/ 3000]\n",
      "loss: 0.060563  [ 1336/ 3000]\n",
      "loss: 0.095642  [ 1344/ 3000]\n",
      "loss: 0.065826  [ 1352/ 3000]\n",
      "loss: 0.020422  [ 1360/ 3000]\n",
      "loss: 0.093447  [ 1368/ 3000]\n",
      "loss: 0.108650  [ 1376/ 3000]\n",
      "loss: 0.044553  [ 1384/ 3000]\n",
      "loss: 0.025586  [ 1392/ 3000]\n",
      "loss: 0.066176  [ 1400/ 3000]\n",
      "loss: 0.062439  [ 1408/ 3000]\n",
      "loss: 0.064003  [ 1416/ 3000]\n",
      "loss: 0.100757  [ 1424/ 3000]\n",
      "loss: 0.043456  [ 1432/ 3000]\n",
      "loss: 0.027111  [ 1440/ 3000]\n",
      "loss: 0.024157  [ 1448/ 3000]\n",
      "loss: 0.045201  [ 1456/ 3000]\n",
      "loss: 0.006077  [ 1464/ 3000]\n",
      "loss: 0.038091  [ 1472/ 3000]\n",
      "loss: 0.019809  [ 1480/ 3000]\n",
      "loss: 0.100742  [ 1488/ 3000]\n",
      "loss: 0.021790  [ 1496/ 3000]\n",
      "loss: 0.036676  [ 1504/ 3000]\n",
      "loss: 0.064372  [ 1512/ 3000]\n",
      "loss: 0.055835  [ 1520/ 3000]\n",
      "loss: 0.019002  [ 1528/ 3000]\n",
      "loss: 0.060646  [ 1536/ 3000]\n",
      "loss: 0.019277  [ 1544/ 3000]\n",
      "loss: 0.081224  [ 1552/ 3000]\n",
      "loss: 0.031864  [ 1560/ 3000]\n",
      "loss: 0.027441  [ 1568/ 3000]\n",
      "loss: 0.017043  [ 1576/ 3000]\n",
      "loss: 0.078942  [ 1584/ 3000]\n",
      "loss: 0.044666  [ 1592/ 3000]\n",
      "loss: 0.065940  [ 1600/ 3000]\n",
      "loss: 0.027531  [ 1608/ 3000]\n",
      "loss: 0.105936  [ 1616/ 3000]\n",
      "loss: 0.082702  [ 1624/ 3000]\n",
      "loss: 0.030542  [ 1632/ 3000]\n",
      "loss: 0.031613  [ 1640/ 3000]\n",
      "loss: 0.089248  [ 1648/ 3000]\n",
      "loss: 0.027581  [ 1656/ 3000]\n",
      "loss: 0.073055  [ 1664/ 3000]\n",
      "loss: 0.012852  [ 1672/ 3000]\n",
      "loss: 0.038473  [ 1680/ 3000]\n",
      "loss: 0.043414  [ 1688/ 3000]\n",
      "loss: 0.069387  [ 1696/ 3000]\n",
      "loss: 0.033410  [ 1704/ 3000]\n",
      "loss: 0.017316  [ 1712/ 3000]\n",
      "loss: 0.022015  [ 1720/ 3000]\n",
      "loss: 0.042271  [ 1728/ 3000]\n",
      "loss: 0.062303  [ 1736/ 3000]\n",
      "loss: 0.056636  [ 1744/ 3000]\n",
      "loss: 0.014124  [ 1752/ 3000]\n",
      "loss: 0.005959  [ 1760/ 3000]\n",
      "loss: 0.070444  [ 1768/ 3000]\n",
      "loss: 0.039809  [ 1776/ 3000]\n",
      "loss: 0.019306  [ 1784/ 3000]\n",
      "loss: 0.032134  [ 1792/ 3000]\n",
      "loss: 0.065878  [ 1800/ 3000]\n",
      "loss: 0.093955  [ 1808/ 3000]\n",
      "loss: 0.025354  [ 1816/ 3000]\n",
      "loss: 0.085732  [ 1824/ 3000]\n",
      "loss: 0.003025  [ 1832/ 3000]\n",
      "loss: 0.006912  [ 1840/ 3000]\n",
      "loss: 0.034841  [ 1848/ 3000]\n",
      "loss: 0.056091  [ 1856/ 3000]\n",
      "loss: 0.051892  [ 1864/ 3000]\n",
      "loss: 0.050473  [ 1872/ 3000]\n",
      "loss: 0.006226  [ 1880/ 3000]\n",
      "loss: 0.010843  [ 1888/ 3000]\n",
      "loss: 0.042641  [ 1896/ 3000]\n",
      "loss: 0.026626  [ 1904/ 3000]\n",
      "loss: 0.023560  [ 1912/ 3000]\n",
      "loss: 0.080149  [ 1920/ 3000]\n",
      "loss: 0.055758  [ 1928/ 3000]\n",
      "loss: 0.091026  [ 1936/ 3000]\n",
      "loss: 0.009351  [ 1944/ 3000]\n",
      "loss: 0.068523  [ 1952/ 3000]\n",
      "loss: 0.020817  [ 1960/ 3000]\n",
      "loss: 0.079840  [ 1968/ 3000]\n",
      "loss: 0.022353  [ 1976/ 3000]\n",
      "loss: 0.087325  [ 1984/ 3000]\n",
      "loss: 0.093086  [ 1992/ 3000]\n",
      "loss: 0.042620  [ 2000/ 3000]\n",
      "loss: 0.067539  [ 2008/ 3000]\n",
      "loss: 0.034957  [ 2016/ 3000]\n",
      "loss: 0.043154  [ 2024/ 3000]\n",
      "loss: 0.072662  [ 2032/ 3000]\n",
      "loss: 0.060193  [ 2040/ 3000]\n",
      "loss: 0.026951  [ 2048/ 3000]\n",
      "loss: 0.024346  [ 2056/ 3000]\n",
      "loss: 0.016295  [ 2064/ 3000]\n",
      "loss: 0.082015  [ 2072/ 3000]\n",
      "loss: 0.032083  [ 2080/ 3000]\n",
      "loss: 0.069321  [ 2088/ 3000]\n",
      "loss: 0.055155  [ 2096/ 3000]\n",
      "loss: 0.035763  [ 2104/ 3000]\n",
      "loss: 0.025235  [ 2112/ 3000]\n",
      "loss: 0.010314  [ 2120/ 3000]\n",
      "loss: 0.053934  [ 2128/ 3000]\n",
      "loss: 0.048230  [ 2136/ 3000]\n",
      "loss: 0.074130  [ 2144/ 3000]\n",
      "loss: 0.105852  [ 2152/ 3000]\n",
      "loss: 0.015729  [ 2160/ 3000]\n",
      "loss: 0.045124  [ 2168/ 3000]\n",
      "loss: 0.019521  [ 2176/ 3000]\n",
      "loss: 0.063436  [ 2184/ 3000]\n",
      "loss: 0.037608  [ 2192/ 3000]\n",
      "loss: 0.022471  [ 2200/ 3000]\n",
      "loss: 0.010938  [ 2208/ 3000]\n",
      "loss: 0.026592  [ 2216/ 3000]\n",
      "loss: 0.066929  [ 2224/ 3000]\n",
      "loss: 0.049342  [ 2232/ 3000]\n",
      "loss: 0.088911  [ 2240/ 3000]\n",
      "loss: 0.008642  [ 2248/ 3000]\n",
      "loss: 0.033853  [ 2256/ 3000]\n",
      "loss: 0.011929  [ 2264/ 3000]\n",
      "loss: 0.093759  [ 2272/ 3000]\n",
      "loss: 0.031520  [ 2280/ 3000]\n",
      "loss: 0.074515  [ 2288/ 3000]\n",
      "loss: 0.045153  [ 2296/ 3000]\n",
      "loss: 0.035053  [ 2304/ 3000]\n",
      "loss: 0.018554  [ 2312/ 3000]\n",
      "loss: 0.012613  [ 2320/ 3000]\n",
      "loss: 0.052455  [ 2328/ 3000]\n",
      "loss: 0.009873  [ 2336/ 3000]\n",
      "loss: 0.083170  [ 2344/ 3000]\n",
      "loss: 0.071867  [ 2352/ 3000]\n",
      "loss: 0.072274  [ 2360/ 3000]\n",
      "loss: 0.031828  [ 2368/ 3000]\n",
      "loss: 0.018780  [ 2376/ 3000]\n",
      "loss: 0.039933  [ 2384/ 3000]\n",
      "loss: 0.033795  [ 2392/ 3000]\n",
      "loss: 0.005990  [ 2400/ 3000]\n",
      "loss: 0.094322  [ 2408/ 3000]\n",
      "loss: 0.061110  [ 2416/ 3000]\n",
      "loss: 0.050048  [ 2424/ 3000]\n",
      "loss: 0.069193  [ 2432/ 3000]\n",
      "loss: 0.037949  [ 2440/ 3000]\n",
      "loss: 0.069790  [ 2448/ 3000]\n",
      "loss: 0.084456  [ 2456/ 3000]\n",
      "loss: 0.032564  [ 2464/ 3000]\n",
      "loss: 0.179303  [ 2472/ 3000]\n",
      "loss: 0.023027  [ 2480/ 3000]\n",
      "loss: 0.037710  [ 2488/ 3000]\n",
      "loss: 0.009197  [ 2496/ 3000]\n",
      "loss: 0.022821  [ 2504/ 3000]\n",
      "loss: 0.085110  [ 2512/ 3000]\n",
      "loss: 0.164512  [ 2520/ 3000]\n",
      "loss: 0.019652  [ 2528/ 3000]\n",
      "loss: 0.045899  [ 2536/ 3000]\n",
      "loss: 0.012458  [ 2544/ 3000]\n",
      "loss: 0.062510  [ 2552/ 3000]\n",
      "loss: 0.062408  [ 2560/ 3000]\n",
      "loss: 0.109473  [ 2568/ 3000]\n",
      "loss: 0.070158  [ 2576/ 3000]\n",
      "loss: 0.042146  [ 2584/ 3000]\n",
      "loss: 0.035198  [ 2592/ 3000]\n",
      "loss: 0.059070  [ 2600/ 3000]\n",
      "loss: 0.062836  [ 2608/ 3000]\n",
      "loss: 0.021287  [ 2616/ 3000]\n",
      "loss: 0.019925  [ 2624/ 3000]\n",
      "loss: 0.079041  [ 2632/ 3000]\n",
      "loss: 0.094876  [ 2640/ 3000]\n",
      "loss: 0.058697  [ 2648/ 3000]\n",
      "loss: 0.059939  [ 2656/ 3000]\n",
      "loss: 0.040603  [ 2664/ 3000]\n",
      "loss: 0.069971  [ 2672/ 3000]\n",
      "loss: 0.084599  [ 2680/ 3000]\n",
      "loss: 0.036594  [ 2688/ 3000]\n",
      "loss: 0.028172  [ 2696/ 3000]\n",
      "loss: 0.063927  [ 2704/ 3000]\n",
      "loss: 0.047643  [ 2712/ 3000]\n",
      "loss: 0.034325  [ 2720/ 3000]\n",
      "loss: 0.068164  [ 2728/ 3000]\n",
      "loss: 0.022397  [ 2736/ 3000]\n",
      "loss: 0.049736  [ 2744/ 3000]\n",
      "loss: 0.060137  [ 2752/ 3000]\n",
      "loss: 0.044899  [ 2760/ 3000]\n",
      "loss: 0.013669  [ 2768/ 3000]\n",
      "loss: 0.071547  [ 2776/ 3000]\n",
      "loss: 0.051596  [ 2784/ 3000]\n",
      "loss: 0.028486  [ 2792/ 3000]\n",
      "loss: 0.076829  [ 2800/ 3000]\n",
      "loss: 0.111045  [ 2808/ 3000]\n",
      "loss: 0.041855  [ 2816/ 3000]\n",
      "loss: 0.054787  [ 2824/ 3000]\n",
      "loss: 0.058745  [ 2832/ 3000]\n",
      "loss: 0.039554  [ 2840/ 3000]\n",
      "loss: 0.033913  [ 2848/ 3000]\n",
      "loss: 0.056868  [ 2856/ 3000]\n",
      "loss: 0.022836  [ 2864/ 3000]\n",
      "loss: 0.070929  [ 2872/ 3000]\n",
      "loss: 0.070652  [ 2880/ 3000]\n",
      "loss: 0.009210  [ 2888/ 3000]\n",
      "loss: 0.010662  [ 2896/ 3000]\n",
      "loss: 0.045119  [ 2904/ 3000]\n",
      "loss: 0.067541  [ 2912/ 3000]\n",
      "loss: 0.034706  [ 2920/ 3000]\n",
      "loss: 0.079173  [ 2928/ 3000]\n",
      "loss: 0.109283  [ 2936/ 3000]\n",
      "loss: 0.022121  [ 2944/ 3000]\n",
      "loss: 0.003861  [ 2952/ 3000]\n",
      "loss: 0.020213  [ 2960/ 3000]\n",
      "loss: 0.038542  [ 2968/ 3000]\n",
      "loss: 0.039181  [ 2976/ 3000]\n",
      "loss: 0.047023  [ 2984/ 3000]\n",
      "loss: 0.007160  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085434 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.022015  [    0/ 3000]\n",
      "loss: 0.053554  [    8/ 3000]\n",
      "loss: 0.014528  [   16/ 3000]\n",
      "loss: 0.019359  [   24/ 3000]\n",
      "loss: 0.073603  [   32/ 3000]\n",
      "loss: 0.011025  [   40/ 3000]\n",
      "loss: 0.015490  [   48/ 3000]\n",
      "loss: 0.057086  [   56/ 3000]\n",
      "loss: 0.103681  [   64/ 3000]\n",
      "loss: 0.017358  [   72/ 3000]\n",
      "loss: 0.110762  [   80/ 3000]\n",
      "loss: 0.051700  [   88/ 3000]\n",
      "loss: 0.076930  [   96/ 3000]\n",
      "loss: 0.025794  [  104/ 3000]\n",
      "loss: 0.124875  [  112/ 3000]\n",
      "loss: 0.025355  [  120/ 3000]\n",
      "loss: 0.031691  [  128/ 3000]\n",
      "loss: 0.054202  [  136/ 3000]\n",
      "loss: 0.054737  [  144/ 3000]\n",
      "loss: 0.029593  [  152/ 3000]\n",
      "loss: 0.015034  [  160/ 3000]\n",
      "loss: 0.009615  [  168/ 3000]\n",
      "loss: 0.018591  [  176/ 3000]\n",
      "loss: 0.063087  [  184/ 3000]\n",
      "loss: 0.034485  [  192/ 3000]\n",
      "loss: 0.028223  [  200/ 3000]\n",
      "loss: 0.120350  [  208/ 3000]\n",
      "loss: 0.026719  [  216/ 3000]\n",
      "loss: 0.035807  [  224/ 3000]\n",
      "loss: 0.098636  [  232/ 3000]\n",
      "loss: 0.045829  [  240/ 3000]\n",
      "loss: 0.025068  [  248/ 3000]\n",
      "loss: 0.021216  [  256/ 3000]\n",
      "loss: 0.053471  [  264/ 3000]\n",
      "loss: 0.042284  [  272/ 3000]\n",
      "loss: 0.133756  [  280/ 3000]\n",
      "loss: 0.018149  [  288/ 3000]\n",
      "loss: 0.044064  [  296/ 3000]\n",
      "loss: 0.027787  [  304/ 3000]\n",
      "loss: 0.075259  [  312/ 3000]\n",
      "loss: 0.029404  [  320/ 3000]\n",
      "loss: 0.081973  [  328/ 3000]\n",
      "loss: 0.027382  [  336/ 3000]\n",
      "loss: 0.066893  [  344/ 3000]\n",
      "loss: 0.015086  [  352/ 3000]\n",
      "loss: 0.022473  [  360/ 3000]\n",
      "loss: 0.090194  [  368/ 3000]\n",
      "loss: 0.013329  [  376/ 3000]\n",
      "loss: 0.077632  [  384/ 3000]\n",
      "loss: 0.037297  [  392/ 3000]\n",
      "loss: 0.062695  [  400/ 3000]\n",
      "loss: 0.027493  [  408/ 3000]\n",
      "loss: 0.070167  [  416/ 3000]\n",
      "loss: 0.031962  [  424/ 3000]\n",
      "loss: 0.125254  [  432/ 3000]\n",
      "loss: 0.026816  [  440/ 3000]\n",
      "loss: 0.056666  [  448/ 3000]\n",
      "loss: 0.033030  [  456/ 3000]\n",
      "loss: 0.076725  [  464/ 3000]\n",
      "loss: 0.051064  [  472/ 3000]\n",
      "loss: 0.012821  [  480/ 3000]\n",
      "loss: 0.094895  [  488/ 3000]\n",
      "loss: 0.075988  [  496/ 3000]\n",
      "loss: 0.029194  [  504/ 3000]\n",
      "loss: 0.052908  [  512/ 3000]\n",
      "loss: 0.034794  [  520/ 3000]\n",
      "loss: 0.149190  [  528/ 3000]\n",
      "loss: 0.070108  [  536/ 3000]\n",
      "loss: 0.061979  [  544/ 3000]\n",
      "loss: 0.035135  [  552/ 3000]\n",
      "loss: 0.027825  [  560/ 3000]\n",
      "loss: 0.065535  [  568/ 3000]\n",
      "loss: 0.040289  [  576/ 3000]\n",
      "loss: 0.044115  [  584/ 3000]\n",
      "loss: 0.023454  [  592/ 3000]\n",
      "loss: 0.101541  [  600/ 3000]\n",
      "loss: 0.026262  [  608/ 3000]\n",
      "loss: 0.065863  [  616/ 3000]\n",
      "loss: 0.043380  [  624/ 3000]\n",
      "loss: 0.136019  [  632/ 3000]\n",
      "loss: 0.013310  [  640/ 3000]\n",
      "loss: 0.105753  [  648/ 3000]\n",
      "loss: 0.144524  [  656/ 3000]\n",
      "loss: 0.123611  [  664/ 3000]\n",
      "loss: 0.051541  [  672/ 3000]\n",
      "loss: 0.062257  [  680/ 3000]\n",
      "loss: 0.040031  [  688/ 3000]\n",
      "loss: 0.126790  [  696/ 3000]\n",
      "loss: 0.055264  [  704/ 3000]\n",
      "loss: 0.034594  [  712/ 3000]\n",
      "loss: 0.044479  [  720/ 3000]\n",
      "loss: 0.024029  [  728/ 3000]\n",
      "loss: 0.046918  [  736/ 3000]\n",
      "loss: 0.018955  [  744/ 3000]\n",
      "loss: 0.065043  [  752/ 3000]\n",
      "loss: 0.048849  [  760/ 3000]\n",
      "loss: 0.098473  [  768/ 3000]\n",
      "loss: 0.050149  [  776/ 3000]\n",
      "loss: 0.113761  [  784/ 3000]\n",
      "loss: 0.048867  [  792/ 3000]\n",
      "loss: 0.139195  [  800/ 3000]\n",
      "loss: 0.048139  [  808/ 3000]\n",
      "loss: 0.024226  [  816/ 3000]\n",
      "loss: 0.038909  [  824/ 3000]\n",
      "loss: 0.041663  [  832/ 3000]\n",
      "loss: 0.016380  [  840/ 3000]\n",
      "loss: 0.015368  [  848/ 3000]\n",
      "loss: 0.018558  [  856/ 3000]\n",
      "loss: 0.065020  [  864/ 3000]\n",
      "loss: 0.008498  [  872/ 3000]\n",
      "loss: 0.061025  [  880/ 3000]\n",
      "loss: 0.069396  [  888/ 3000]\n",
      "loss: 0.059673  [  896/ 3000]\n",
      "loss: 0.140995  [  904/ 3000]\n",
      "loss: 0.049176  [  912/ 3000]\n",
      "loss: 0.048043  [  920/ 3000]\n",
      "loss: 0.055262  [  928/ 3000]\n",
      "loss: 0.029279  [  936/ 3000]\n",
      "loss: 0.122507  [  944/ 3000]\n",
      "loss: 0.021470  [  952/ 3000]\n",
      "loss: 0.040024  [  960/ 3000]\n",
      "loss: 0.017609  [  968/ 3000]\n",
      "loss: 0.008637  [  976/ 3000]\n",
      "loss: 0.009824  [  984/ 3000]\n",
      "loss: 0.092535  [  992/ 3000]\n",
      "loss: 0.051872  [ 1000/ 3000]\n",
      "loss: 0.047178  [ 1008/ 3000]\n",
      "loss: 0.085518  [ 1016/ 3000]\n",
      "loss: 0.044477  [ 1024/ 3000]\n",
      "loss: 0.075588  [ 1032/ 3000]\n",
      "loss: 0.012001  [ 1040/ 3000]\n",
      "loss: 0.029504  [ 1048/ 3000]\n",
      "loss: 0.015036  [ 1056/ 3000]\n",
      "loss: 0.052221  [ 1064/ 3000]\n",
      "loss: 0.030967  [ 1072/ 3000]\n",
      "loss: 0.036529  [ 1080/ 3000]\n",
      "loss: 0.076729  [ 1088/ 3000]\n",
      "loss: 0.063704  [ 1096/ 3000]\n",
      "loss: 0.013666  [ 1104/ 3000]\n",
      "loss: 0.070784  [ 1112/ 3000]\n",
      "loss: 0.021737  [ 1120/ 3000]\n",
      "loss: 0.039419  [ 1128/ 3000]\n",
      "loss: 0.032207  [ 1136/ 3000]\n",
      "loss: 0.080741  [ 1144/ 3000]\n",
      "loss: 0.028403  [ 1152/ 3000]\n",
      "loss: 0.020535  [ 1160/ 3000]\n",
      "loss: 0.023604  [ 1168/ 3000]\n",
      "loss: 0.018946  [ 1176/ 3000]\n",
      "loss: 0.121404  [ 1184/ 3000]\n",
      "loss: 0.043972  [ 1192/ 3000]\n",
      "loss: 0.026663  [ 1200/ 3000]\n",
      "loss: 0.031744  [ 1208/ 3000]\n",
      "loss: 0.029982  [ 1216/ 3000]\n",
      "loss: 0.057053  [ 1224/ 3000]\n",
      "loss: 0.064627  [ 1232/ 3000]\n",
      "loss: 0.058484  [ 1240/ 3000]\n",
      "loss: 0.056850  [ 1248/ 3000]\n",
      "loss: 0.006969  [ 1256/ 3000]\n",
      "loss: 0.041480  [ 1264/ 3000]\n",
      "loss: 0.017896  [ 1272/ 3000]\n",
      "loss: 0.020430  [ 1280/ 3000]\n",
      "loss: 0.044222  [ 1288/ 3000]\n",
      "loss: 0.015165  [ 1296/ 3000]\n",
      "loss: 0.002498  [ 1304/ 3000]\n",
      "loss: 0.067584  [ 1312/ 3000]\n",
      "loss: 0.175987  [ 1320/ 3000]\n",
      "loss: 0.071816  [ 1328/ 3000]\n",
      "loss: 0.059326  [ 1336/ 3000]\n",
      "loss: 0.092456  [ 1344/ 3000]\n",
      "loss: 0.064336  [ 1352/ 3000]\n",
      "loss: 0.019335  [ 1360/ 3000]\n",
      "loss: 0.091166  [ 1368/ 3000]\n",
      "loss: 0.105871  [ 1376/ 3000]\n",
      "loss: 0.042686  [ 1384/ 3000]\n",
      "loss: 0.024453  [ 1392/ 3000]\n",
      "loss: 0.064365  [ 1400/ 3000]\n",
      "loss: 0.060569  [ 1408/ 3000]\n",
      "loss: 0.062000  [ 1416/ 3000]\n",
      "loss: 0.097803  [ 1424/ 3000]\n",
      "loss: 0.041624  [ 1432/ 3000]\n",
      "loss: 0.026144  [ 1440/ 3000]\n",
      "loss: 0.023141  [ 1448/ 3000]\n",
      "loss: 0.043804  [ 1456/ 3000]\n",
      "loss: 0.005879  [ 1464/ 3000]\n",
      "loss: 0.037265  [ 1472/ 3000]\n",
      "loss: 0.019504  [ 1480/ 3000]\n",
      "loss: 0.097455  [ 1488/ 3000]\n",
      "loss: 0.021092  [ 1496/ 3000]\n",
      "loss: 0.035574  [ 1504/ 3000]\n",
      "loss: 0.062295  [ 1512/ 3000]\n",
      "loss: 0.054000  [ 1520/ 3000]\n",
      "loss: 0.018222  [ 1528/ 3000]\n",
      "loss: 0.058677  [ 1536/ 3000]\n",
      "loss: 0.018192  [ 1544/ 3000]\n",
      "loss: 0.078637  [ 1552/ 3000]\n",
      "loss: 0.030853  [ 1560/ 3000]\n",
      "loss: 0.026411  [ 1568/ 3000]\n",
      "loss: 0.016450  [ 1576/ 3000]\n",
      "loss: 0.076900  [ 1584/ 3000]\n",
      "loss: 0.043704  [ 1592/ 3000]\n",
      "loss: 0.063898  [ 1600/ 3000]\n",
      "loss: 0.026426  [ 1608/ 3000]\n",
      "loss: 0.103356  [ 1616/ 3000]\n",
      "loss: 0.080439  [ 1624/ 3000]\n",
      "loss: 0.029236  [ 1632/ 3000]\n",
      "loss: 0.030040  [ 1640/ 3000]\n",
      "loss: 0.086516  [ 1648/ 3000]\n",
      "loss: 0.026582  [ 1656/ 3000]\n",
      "loss: 0.069910  [ 1664/ 3000]\n",
      "loss: 0.012239  [ 1672/ 3000]\n",
      "loss: 0.037431  [ 1680/ 3000]\n",
      "loss: 0.041982  [ 1688/ 3000]\n",
      "loss: 0.067548  [ 1696/ 3000]\n",
      "loss: 0.031897  [ 1704/ 3000]\n",
      "loss: 0.016680  [ 1712/ 3000]\n",
      "loss: 0.021193  [ 1720/ 3000]\n",
      "loss: 0.040796  [ 1728/ 3000]\n",
      "loss: 0.060091  [ 1736/ 3000]\n",
      "loss: 0.054835  [ 1744/ 3000]\n",
      "loss: 0.013742  [ 1752/ 3000]\n",
      "loss: 0.005735  [ 1760/ 3000]\n",
      "loss: 0.067676  [ 1768/ 3000]\n",
      "loss: 0.038053  [ 1776/ 3000]\n",
      "loss: 0.018620  [ 1784/ 3000]\n",
      "loss: 0.030890  [ 1792/ 3000]\n",
      "loss: 0.063809  [ 1800/ 3000]\n",
      "loss: 0.091187  [ 1808/ 3000]\n",
      "loss: 0.024546  [ 1816/ 3000]\n",
      "loss: 0.082387  [ 1824/ 3000]\n",
      "loss: 0.002845  [ 1832/ 3000]\n",
      "loss: 0.006649  [ 1840/ 3000]\n",
      "loss: 0.033569  [ 1848/ 3000]\n",
      "loss: 0.054415  [ 1856/ 3000]\n",
      "loss: 0.050113  [ 1864/ 3000]\n",
      "loss: 0.048982  [ 1872/ 3000]\n",
      "loss: 0.005866  [ 1880/ 3000]\n",
      "loss: 0.010367  [ 1888/ 3000]\n",
      "loss: 0.040861  [ 1896/ 3000]\n",
      "loss: 0.025994  [ 1904/ 3000]\n",
      "loss: 0.022542  [ 1912/ 3000]\n",
      "loss: 0.078290  [ 1920/ 3000]\n",
      "loss: 0.053838  [ 1928/ 3000]\n",
      "loss: 0.088318  [ 1936/ 3000]\n",
      "loss: 0.008926  [ 1944/ 3000]\n",
      "loss: 0.066635  [ 1952/ 3000]\n",
      "loss: 0.020013  [ 1960/ 3000]\n",
      "loss: 0.077749  [ 1968/ 3000]\n",
      "loss: 0.021546  [ 1976/ 3000]\n",
      "loss: 0.084656  [ 1984/ 3000]\n",
      "loss: 0.090408  [ 1992/ 3000]\n",
      "loss: 0.040848  [ 2000/ 3000]\n",
      "loss: 0.065185  [ 2008/ 3000]\n",
      "loss: 0.033647  [ 2016/ 3000]\n",
      "loss: 0.041947  [ 2024/ 3000]\n",
      "loss: 0.070802  [ 2032/ 3000]\n",
      "loss: 0.058378  [ 2040/ 3000]\n",
      "loss: 0.026091  [ 2048/ 3000]\n",
      "loss: 0.023235  [ 2056/ 3000]\n",
      "loss: 0.015528  [ 2064/ 3000]\n",
      "loss: 0.079825  [ 2072/ 3000]\n",
      "loss: 0.030829  [ 2080/ 3000]\n",
      "loss: 0.066796  [ 2088/ 3000]\n",
      "loss: 0.053669  [ 2096/ 3000]\n",
      "loss: 0.034743  [ 2104/ 3000]\n",
      "loss: 0.024650  [ 2112/ 3000]\n",
      "loss: 0.009906  [ 2120/ 3000]\n",
      "loss: 0.052588  [ 2128/ 3000]\n",
      "loss: 0.046718  [ 2136/ 3000]\n",
      "loss: 0.071779  [ 2144/ 3000]\n",
      "loss: 0.103046  [ 2152/ 3000]\n",
      "loss: 0.015132  [ 2160/ 3000]\n",
      "loss: 0.043761  [ 2168/ 3000]\n",
      "loss: 0.019190  [ 2176/ 3000]\n",
      "loss: 0.061114  [ 2184/ 3000]\n",
      "loss: 0.035691  [ 2192/ 3000]\n",
      "loss: 0.021570  [ 2200/ 3000]\n",
      "loss: 0.010444  [ 2208/ 3000]\n",
      "loss: 0.025767  [ 2216/ 3000]\n",
      "loss: 0.064417  [ 2224/ 3000]\n",
      "loss: 0.047647  [ 2232/ 3000]\n",
      "loss: 0.086416  [ 2240/ 3000]\n",
      "loss: 0.008327  [ 2248/ 3000]\n",
      "loss: 0.032437  [ 2256/ 3000]\n",
      "loss: 0.011359  [ 2264/ 3000]\n",
      "loss: 0.090804  [ 2272/ 3000]\n",
      "loss: 0.030588  [ 2280/ 3000]\n",
      "loss: 0.071748  [ 2288/ 3000]\n",
      "loss: 0.043562  [ 2296/ 3000]\n",
      "loss: 0.033744  [ 2304/ 3000]\n",
      "loss: 0.017814  [ 2312/ 3000]\n",
      "loss: 0.011981  [ 2320/ 3000]\n",
      "loss: 0.050439  [ 2328/ 3000]\n",
      "loss: 0.009448  [ 2336/ 3000]\n",
      "loss: 0.080832  [ 2344/ 3000]\n",
      "loss: 0.069612  [ 2352/ 3000]\n",
      "loss: 0.069729  [ 2360/ 3000]\n",
      "loss: 0.030949  [ 2368/ 3000]\n",
      "loss: 0.018148  [ 2376/ 3000]\n",
      "loss: 0.038831  [ 2384/ 3000]\n",
      "loss: 0.032109  [ 2392/ 3000]\n",
      "loss: 0.005783  [ 2400/ 3000]\n",
      "loss: 0.091926  [ 2408/ 3000]\n",
      "loss: 0.059487  [ 2416/ 3000]\n",
      "loss: 0.047859  [ 2424/ 3000]\n",
      "loss: 0.067548  [ 2432/ 3000]\n",
      "loss: 0.036826  [ 2440/ 3000]\n",
      "loss: 0.066891  [ 2448/ 3000]\n",
      "loss: 0.081929  [ 2456/ 3000]\n",
      "loss: 0.031341  [ 2464/ 3000]\n",
      "loss: 0.174363  [ 2472/ 3000]\n",
      "loss: 0.022606  [ 2480/ 3000]\n",
      "loss: 0.036481  [ 2488/ 3000]\n",
      "loss: 0.008804  [ 2496/ 3000]\n",
      "loss: 0.021944  [ 2504/ 3000]\n",
      "loss: 0.082876  [ 2512/ 3000]\n",
      "loss: 0.159952  [ 2520/ 3000]\n",
      "loss: 0.018733  [ 2528/ 3000]\n",
      "loss: 0.044435  [ 2536/ 3000]\n",
      "loss: 0.012075  [ 2544/ 3000]\n",
      "loss: 0.060455  [ 2552/ 3000]\n",
      "loss: 0.060180  [ 2560/ 3000]\n",
      "loss: 0.107306  [ 2568/ 3000]\n",
      "loss: 0.067357  [ 2576/ 3000]\n",
      "loss: 0.040660  [ 2584/ 3000]\n",
      "loss: 0.034191  [ 2592/ 3000]\n",
      "loss: 0.057881  [ 2600/ 3000]\n",
      "loss: 0.061114  [ 2608/ 3000]\n",
      "loss: 0.020659  [ 2616/ 3000]\n",
      "loss: 0.019142  [ 2624/ 3000]\n",
      "loss: 0.076650  [ 2632/ 3000]\n",
      "loss: 0.092588  [ 2640/ 3000]\n",
      "loss: 0.057049  [ 2648/ 3000]\n",
      "loss: 0.058138  [ 2656/ 3000]\n",
      "loss: 0.039321  [ 2664/ 3000]\n",
      "loss: 0.067422  [ 2672/ 3000]\n",
      "loss: 0.082054  [ 2680/ 3000]\n",
      "loss: 0.035370  [ 2688/ 3000]\n",
      "loss: 0.027331  [ 2696/ 3000]\n",
      "loss: 0.062416  [ 2704/ 3000]\n",
      "loss: 0.045597  [ 2712/ 3000]\n",
      "loss: 0.032712  [ 2720/ 3000]\n",
      "loss: 0.065382  [ 2728/ 3000]\n",
      "loss: 0.021745  [ 2736/ 3000]\n",
      "loss: 0.048492  [ 2744/ 3000]\n",
      "loss: 0.058377  [ 2752/ 3000]\n",
      "loss: 0.043648  [ 2760/ 3000]\n",
      "loss: 0.013137  [ 2768/ 3000]\n",
      "loss: 0.068558  [ 2776/ 3000]\n",
      "loss: 0.049876  [ 2784/ 3000]\n",
      "loss: 0.027408  [ 2792/ 3000]\n",
      "loss: 0.074622  [ 2800/ 3000]\n",
      "loss: 0.107964  [ 2808/ 3000]\n",
      "loss: 0.040510  [ 2816/ 3000]\n",
      "loss: 0.052750  [ 2824/ 3000]\n",
      "loss: 0.057063  [ 2832/ 3000]\n",
      "loss: 0.038175  [ 2840/ 3000]\n",
      "loss: 0.032491  [ 2848/ 3000]\n",
      "loss: 0.055144  [ 2856/ 3000]\n",
      "loss: 0.022008  [ 2864/ 3000]\n",
      "loss: 0.069279  [ 2872/ 3000]\n",
      "loss: 0.068126  [ 2880/ 3000]\n",
      "loss: 0.008809  [ 2888/ 3000]\n",
      "loss: 0.010334  [ 2896/ 3000]\n",
      "loss: 0.043861  [ 2904/ 3000]\n",
      "loss: 0.065274  [ 2912/ 3000]\n",
      "loss: 0.032732  [ 2920/ 3000]\n",
      "loss: 0.076969  [ 2928/ 3000]\n",
      "loss: 0.104874  [ 2936/ 3000]\n",
      "loss: 0.021518  [ 2944/ 3000]\n",
      "loss: 0.003731  [ 2952/ 3000]\n",
      "loss: 0.019425  [ 2960/ 3000]\n",
      "loss: 0.036861  [ 2968/ 3000]\n",
      "loss: 0.038011  [ 2976/ 3000]\n",
      "loss: 0.045325  [ 2984/ 3000]\n",
      "loss: 0.006857  [ 2992/ 3000]\n",
      "Test Error: \n",
      " Avg loss: 0.085534 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.021458  [    0/ 3000]\n",
      "loss: 0.052239  [    8/ 3000]\n",
      "loss: 0.014025  [   16/ 3000]\n",
      "loss: 0.018518  [   24/ 3000]\n",
      "loss: 0.071167  [   32/ 3000]\n",
      "loss: 0.010579  [   40/ 3000]\n",
      "loss: 0.014806  [   48/ 3000]\n",
      "loss: 0.055173  [   56/ 3000]\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "patience = 5\n",
    "epoch_no_improve = 0\n",
    "early_stop = False\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, train_data, model, loss_fn, optimizer)\n",
    "    val_loss = test(dev_dataloader, model)\n",
    "    if val_loss < min_val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = val_loss\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve == patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cb52f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(dev_dataloader):\n",
    "        current_te_label_dict = dev_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = dev_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_sentences = dev_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        \n",
    "        X_tokenized = X.to(device)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        X_encoded = base_encoder(X_tokenized)\n",
    "        X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer = model(X_spans, span_ranges)\n",
    "        \n",
    "        for idx in range(CURRENT_BATCH_SIZE):\n",
    "            prediction = logits_term_scorer[idx].argmax(-1).tolist()\n",
    "            y_pred.append(te_prediction_to_iob(prediction, current_sentences[idx]))\n",
    "            y_true.append(te_label_to_iob(current_te_label_dict[idx], current_sentences[idx]))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(train_dataloader):\n",
    "        current_te_label_dict = train_data.te_label_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_relation_dict = train_data.relation_dict[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        current_sentences = train_data.texts[(batch)*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        CURRENT_BATCH_SIZE = min(len(current_te_label_dict), BATCH_SIZE)\n",
    "        \n",
    "        X_tokenized = X.to(device)\n",
    "        X_tokenized = X_tokenized.reshape(CURRENT_BATCH_SIZE, X_tokenized.shape[-1])\n",
    "        X_encoded = base_encoder(X_tokenized)\n",
    "        X_spans, span_ranges = span_generator(X_encoded)\n",
    "        \n",
    "        logits_term_scorer = model(X_spans, span_ranges)\n",
    "        \n",
    "        for idx in range(CURRENT_BATCH_SIZE):\n",
    "            prediction = logits_term_scorer[idx].argmax(-1).tolist()\n",
    "            y_pred.append(te_prediction_to_iob(prediction, current_sentences[idx]))\n",
    "            y_true.append(te_label_to_iob(current_te_label_dict[idx], current_sentences[idx]))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2169e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
